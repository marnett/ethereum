@inproceedings{dvanhorn:Strub2012Selfcertification,
    author = {Strub, Pierre Y. and Swamy, Nikhil and Fournet, Cedric and Chen, Juan},
    booktitle = {Proceedings of the 39th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {10847180},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2103723},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2103621.2103723},
    date-added = {2014-11-19 15:30:59},
    location = {Philadelphia, PA, USA},
    priority = {2},
    publisher = {ACM},
    title = {Self-certification: Bootstrapping Certified Typecheckers in F* with Coq},
    x-abstract = {Well-established dependently-typed languages like Agda and Coq provide reliable ways to build and check formal proofs. Several other dependently-typed languages such as Aura, {ATS}, Cayenne, Epigram, F*, F7, Fine, Guru, {PCML5}, and Ur also explore reliable ways to develop and verify programs. All these languages shine in their own regard, but their implementations do not themselves enjoy the degree of safety provided by machine-checked verification. We propose a general technique called self-certification that allows a typechecker for a suitably expressive language to be certified for correctness. We have implemented this technique for F*, a dependently typed language on the .{NET} platform. Self-certification involves implementing a typechecker for F* in F*, while using all the conveniences F* provides for the compiler-writer (e.g., partiality, effects, implicit conversions, proof automation, libraries). This typechecker is given a specification ({in\~{}F}*) strong enough to ensure that it computes valid typing derivations. We obtain a typing derivation for the core typechecker by running it on itself, and we export it to Coq as a type-derivation certificate. By typechecking this derivation (in Coq) and applying the F* metatheory (also mechanized in Coq), we conclude that our type checker is correct. Once certified in this manner, the F* typechecker is emancipated from Coq. Self-certification leads to an efficient certification scheme---we no longer depend on verifying certificates in Coq---as well as a more broadly applicable one. For instance, the self-certified F* checker is suitable for use in adversarial settings where Coq is not intended for use, such as run-time certification of mobile code.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2103621.2103723},
    x-isbn = {978-1-4503-1083-3},
    x-issn = {0362-1340},
    x-month = jan,
    x-series = {POPL '12},
    x-url = {http://dx.doi.org/10.1145/2103621.2103723},
    xpages = {571--584},
    year = {2012}
}

@incollection{dvanhorn:Almeida2010Certifying,
    author = {Almeida, Jos\'{e}Bacelar and Bangerter, Endre and Barbosa, Manuel and Krenn, Stephan and Sadeghi, Ahmad-Reza and Schneider, Thomas},
    booktitle = {Computer Security – ESORICS 2010},
    citeulike-article-id = {13433818},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-15497-3\_10},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-15497-3\_10},
    date-added = {2014-11-19 15:15:16},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {A Certifying Compiler for {Zero-Knowledge} Proofs of Knowledge Based on {Σ-Protocols}},
    x-abstract = {Zero-knowledge proofs of knowledge ({ZK}-{PoK}) are important building blocks for numerous cryptographic applications. Although {ZK}-{PoK} have a high potential impact, their real world deployment is typically hindered by their significant complexity compared to other (non-interactive) crypto primitives. Moreover, their design and implementation are time-consuming and error-prone. We contribute to overcoming these challenges as follows: We present a comprehensive specification language and a compiler for {ZK}-{PoK} protocols based on Σ-protocols. The compiler allows the fully automatic translation of an abstract description of a proof goal into an executable implementation. Moreover, the compiler overcomes various restrictions of previous approaches, e.g., it supports the important class of exponentiation homomorphisms with hidden-order co-domain, needed for privacypreserving applications such as {DAA}. Finally, our compiler is certifying, in the sense that it automatically produces a formal proof of the soundness of the compiled protocol for a large class of protocols using the {Isabelle/HOL} theorem prover.},
    x-doi = {10.1007/978-3-642-15497-3\_10},
    x-editor = {Gritzalis, Dimitris and Preneel, Bart and Theoharidou, Marianthi},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-15497-3\_10},
    x-volume = {6345},
    xpages = {151--167},
    year = {2010}
}

@misc{dvanhorn:Seidel2014Type,
    archivePrefix = {arXiv},
    author = {Seidel, Eric L. and Vazou, Niki and Jhala, Ranjit},
    citeulike-article-id = {13427911},
    citeulike-linkout-0 = {http://arxiv.org/abs/1410.5370},
    citeulike-linkout-1 = {http://arxiv.org/pdf/1410.5370},
    date-added = {2014-11-13 21:40:22},
    day = {20},
    eprint = {1410.5370},
    priority = {2},
    title = {Type Targeted Testing},
    x-abstract = {We present a new technique called type targeted testing, which translates
precise refinement types into comprehensive test-suites. The key insight behind
our approach is that through the lens of {SMT} solvers, refinement types can also
be viewed as a high-level, declarative, test generation technique, wherein
types are converted to {SMT} queries whose models can be decoded into concrete
program inputs. Our approach enables the systematic and exhaustive testing of
implementations from high-level declarative specifications, and furthermore,
provides a gradual path from testing to full verification. We have implemented
our approach as a Haskell testing tool called {TARGET}, and present an evaluation
that shows how {TARGET} can be used to test a wide variety of properties and how
it compares against state-of-the-art testing approaches.},
    x-month = oct,
    x-url = {http://arxiv.org/abs/1410.5370},
    year = {2014}
}

@article{dvanhorn:Kobayashi2013Model,
    author = {Kobayashi, Naoki},
    citeulike-article-id = {12905860},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2487246},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2487241.2487246},
    date-added = {2014-11-13 20:51:10},
    journal = {J. ACM},
    priority = {2},
    publisher = {ACM},
    title = {Model Checking {Higher-Order} Programs},
    x-abstract = {We propose a novel verification method for higher-order functional programs based on higher-order model checking, or more precisely, model checking of higher-order recursion schemes (recursion schemes, for short). The most distinguishing feature of our verification method for higher-order programs is that it is sound, complete, and automatic for the simply typed λ-calculus with recursion and finite base types, and for various program verification problems such as reachability, flow analysis, and resource usage verification. We first show that a variety of program verification problems can be reduced to model checking problems for recursion schemes, by transforming a program into a recursion scheme that generates a tree representing all the interesting possible event sequences of the program. We then develop a new type-based model-checking algorithm for recursion schemes and implement a prototype recursion scheme model checker. To our knowledge, this is the first implementation of a recursion scheme model checker. Experiments show that our model checker is reasonably fast, despite the worst-case time complexity of recursion scheme model checking being hyperexponential in general. Altogether, the results provide a new, promising approach to verification of higher-order functional programs.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2487241.2487246},
    x-issn = {0004-5411},
    x-month = jun,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1145/2487241.2487246},
    x-volume = {60},
    year = {2013}
}

@inproceedings{dvanhorn:yang:modelcheck,
    author = {Yang, Junfeng and Twohey, Paul and Engler, Dawson and Musuvathi, Madanlal},
    booktitle = {Sixth Symposium on Operating Systems Design and Implementation},
    citeulike-article-id = {638267},
    citeulike-linkout-0 = {https://db.usenix.org/events/osdi04/tech/yang/yang.pdf},
    date-added = {2014-11-13 20:44:35},
    keywords = {838-remzi, filesystems, folder40, reliability},
    organization = {USENIX},
    priority = {2},
    title = {Using Model Checking to Find Serious File System Errors},
    x-abstract = {This paper shows how to use model checking to find serious errors in file systems. Model checking is a formal verification technique tuned for finding corner-case errors by comprehensively exploring the state spaces defined by a system. File systems have two dynamics that make them attractive for such an approach. First, their errors are some of the most serious, since they can destroy persistent data and lead to unrecoverable corruption. Second, traditional testing needs an impractical, exponential number of test cases to check that the system will recover if it crashes at any point during execution. Model checking employs a variety of state-reducing techniques that allow it to explore such vast state spaces efficiently. We built a system, {FiSC}, for model checking file systems. We applied it to three widely-used, heavily-tested file systems: ext3, {JFS}, and {ReiserFS}. We found serious bugs in all of them, 32 in total. Most have led to patches within a day of diagnosis. For each file system, {FiSC} found demonstrable events leading to the unrecoverable destruction of metadata and entire directories, including the file system root directory  ” /”.},
    x-url = {https://db.usenix.org/events/osdi04/tech/yang/yang.pdf},
    xpages = {273--288}
}

@inproceedings{dvanhorn:Xie2005Scalable,
    author = {Xie, Yichen and Aiken, Alex},
    booktitle = {Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {952635},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1047659.1040334},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1047659.1040334},
    date-added = {2014-11-13 20:40:26},
    priority = {2},
    publisher = {ACM},
    title = {Scalable Error Detection Using Boolean Satisfiability},
    x-abstract = {We describe a software error-detection tool that exploits recent advances in boolean satisfiability ({SAT}) solvers. Our analysis is path sensitive, precise down to the bit level, and models pointers and heap data. Our approach is also highly scalable, which we achieve using two techniques. First, for each program function, several optimizations compress the size of the boolean formulas that model the control- and data-flow and the heap locations accessed by a function. Second, summaries in the spirit of type signatures are computed for each function, allowing inter-procedural analysis without a dramatic increase in the size of the boolean constraints to be {solved.We} demonstrate the effectiveness of our approach by constructing a lock interface inference and checking tool. In an interprocedural analysis of more than 23,000 lock related functions in the latest Linux kernel, the checker generated 300 warnings, of which 179 were unique locking errors, a false positive rate of only 40\%.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1047659.1040334},
    x-issn = {0362-1340},
    x-month = jan,
    x-url = {http://dx.doi.org/10.1145/1047659.1040334},
    xpages = {351--363},
    year = {2005}
}

@inproceedings{dvanhorn:Foster2002Flowsensitive,
    author = {Foster, Jeffrey S. and Terauchi, Tachio and Aiken, Alex},
    booktitle = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13427882},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=512529.512531},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/543552.512531},
    date-added = {2014-11-13 20:36:07},
    priority = {2},
    publisher = {ACM},
    title = {Flow-sensitive Type Qualifiers},
    x-abstract = {We present a system for extending standard type systems with flow-sensitive type qualifiers. Users annotate their programs with type qualifiers, and inference checks that the annotations are correct. In our system only the type qualifiers are modeled flow-sensitively---the underlying standard types are unchanged, which allows us to obtain an efficient constraint-based inference algorithm that integrates flow-insensitive alias analysis, effect inference, and ideas from linear type systems to support strong updates. We demonstrate the usefulness of flow-sensitive type qualifiers by finding a number of new locking bugs in the Linux kernel.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/543552.512531},
    x-issn = {0362-1340},
    x-month = may,
    x-url = {http://dx.doi.org/10.1145/543552.512531},
    xpages = {1--12},
    year = {2002}
}

@article{dvanhorn:Godefroid2005DART,
    author = {Godefroid, Patrice and Klarlund, Nils and Sen, Koushik},
    citeulike-article-id = {2343518},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1064978.1065036},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1064978.1065036},
    date-added = {2014-11-13 20:32:16},
    journal = {SIGPLAN Not.},
    priority = {2},
    publisher = {ACM},
    title = {{DART}: Directed Automated Random Testing},
    x-abstract = {We present a new tool, named {DART}, for automatically testing software that combines three main techniques: (1) automated extraction of the interface of a program with its external environment using static source-code parsing; (2) automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in; and (3) dynamic analysis of how the program behaves under random testing and automatic generation of new test inputs to direct systematically the execution along alternative program paths. Together, these three techniques constitute Directed Automated Random Testing, or {DART} for short. The main strength of {DART} is thus that testing can be performed completely automatically on any program that compiles -- there is no need to write any test driver or harness code. During testing, {DART} detects standard errors such as program crashes, assertion violations, and non-termination. Preliminary experiments to unit test several examples of C programs are very encouraging.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1064978.1065036},
    x-issn = {0362-1340},
    x-month = jun,
    x-number = {6},
    x-url = {http://dx.doi.org/10.1145/1064978.1065036},
    x-volume = {40},
    xpages = {213--223},
    year = {2005}
}

@inproceedings{dvanhorn:Cook1978Soundness,
    author = {Cook, Stephen A.},
    booktitle = {SIAM Journal of Computing},
    citeulike-article-id = {13427842},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.258.4890},
    date-added = {2014-11-13 19:23:32},
    priority = {2},
    title = {Soundness and completeness of an axiom system for program verification},
    x-abstract = {K. R. Apt pointed out to me that Theorem 3 (completeness) is technically false, because of a problem with initializing newly declared variables. For example, the formula true {begin begin new x; x:= 1 end; begin new x; y: = x end end} y 1 is valid according to the semantics given (because the second declaration of x assigns the same register to x as the first), but it is not provable in Perhaps the simplest way to fix this is to require all newly declared variables to be initialized to some distinguished value 0 e D. This would involve changing the first case (that of variable declaration) in the definition of Comp (A, s, 3, 7r) on p. 74, so that the computation proceeds with a new state s\^{a}. Here s \^{a} is the same as s except for s\^{a}(X,/x) 0. To make Y ( complete we would slightly modify Rule 1 (Rule of variable declarations) of the system Y to read x 0 \& P--Y {begin D*; A * end}O-y X},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.258.4890},
    year = {1978}
}

@article{dvanhorn:Scott1993Typetheoretical,
    author = {Scott, Dana S.},
    citeulike-article-id = {5444731},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=170034},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/0304-3975(93)90095-b},
    date-added = {2014-11-13 19:16:32},
    journal = {Theoretical Computer Science},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {A type-theoretical alternative to {ISWIM}, {CUCH}, {OWHY}},
    x-address = {Essex, UK},
    x-doi = {10.1016/0304-3975(93)90095-b},
    x-issn = {03043975},
    x-month = dec,
    x-number = {1-2},
    x-url = {http://dx.doi.org/10.1016/0304-3975(93)90095-b},
    x-volume = {121},
    xpages = {411--440},
    year = {1993}
}

@inproceedings{dvanhorn:Sergey2013Monadic,
    author = {Sergey, Ilya and Devriese, Dominique and Might, Matthew and Midtgaard, Jan and Darais, David and Clarke, Dave and Piessens, Frank},
    booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13136834},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2491979},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2499370.2491979},
    date-added = {2014-11-13 17:27:50},
    priority = {2},
    publisher = {ACM},
    title = {Monadic Abstract Interpreters},
    x-abstract = {Recent developments in the systematic construction of abstract interpreters hinted at the possibility of a broad unification of concepts in static analysis. We deliver that unification by showing context-sensitivity, polyvariance, flow-sensitivity, reachability-pruning, heap-cloning and cardinality-bounding to be independent of any particular semantics. Monads become the unifying agent between these concepts and between semantics. For instance, by plugging the same "context-insensitivity monad" into a monadically-parameterized semantics for Java or for the lambda calculus, it yields the expected context-insensitive analysis. To achieve this unification, we develop a systematic method for transforming a concrete semantics into a monadically-parameterized abstract machine. Changing the monad changes the behavior of the machine. By changing the monad, we recover a spectrum of machines---from the original concrete semantics to a monovariant, flow- and context-insensitive static analysis with a singly-threaded heap and weak updates. The monadic parameterization also suggests an abstraction over the ubiquitous monotone fixed-point computation found in static analysis. This abstraction makes it straightforward to instrument an analysis with high-level strategies for improving precision and performance, such as abstract garbage collection and widening. While the paper itself runs the development for continuation-passing style, our generic implementation replays it for direct-style lambda-calculus and Featherweight Java to support generality.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2499370.2491979},
    x-issn = {0362-1340},
    x-month = jun,
    x-url = {http://dx.doi.org/10.1145/2499370.2491979},
    xpages = {399--410},
    year = {2013}
}

@inproceedings{dvanhorn:Wadler1992Essence,
    author = {Wadler, Philip},
    booktitle = {Proceedings of the 19th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {1360},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=143169},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/143165.143169},
    date-added = {2014-11-13 17:01:02},
    location = {Albuquerque, New Mexico, USA},
    priority = {2},
    publisher = {ACM},
    title = {The Essence of Functional Programming},
    x-abstract = {This paper explores the use monads to structure functional
programs. No prior knowledge of monads or category theory is
required.

Monads increase the ease with which programs may be modified.
They can mimic the effect of impure features such as exceptions,
state, and continuations; and also provide effects not easily
achieved with such features. The types of a program reflect which
effects occur.

The first section is an extended example of the use of monads. A
simple interpreter is modified to support various extra features:
error messages, state, output, and non-deterministic choice. The
second section describes the relation between monads and the
continuation-passing style. The third section sketches how monads
are used in a compiler for Haskell that is written in Haskell.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/143165.143169},
    x-isbn = {0-89791-453-8},
    x-series = {POPL '92},
    x-url = {http://dx.doi.org/10.1145/143165.143169},
    xpages = {1--14},
    year = {1992}
}

@inproceedings{dvanhorn:Liang1995Monad,
    author = {Liang, Sheng and Hudak, Paul and Jones, Mark},
    booktitle = {Proceedings of the 22Nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {82468},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=199528},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/199448.199528},
    date-added = {2014-11-13 06:02:35},
    location = {San Francisco, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {Monad Transformers and Modular Interpreters},
    x-abstract = {We show how a set of building blocks can be used to construct programming language interpreters, and present implementations of such building blocks capable of supporting many commonly known features, including simple expressions, three different function call mechanisms (call-by-name, call-by-value and lazy evaluation), references and assignment, nondeterminism, first-class continuations, and program {tracing.The} underlying mechanism of our system is monad transformers, a simple form of abstraction for introducing a wide range of computational behaviors, such as state, {I/O}, continuations, and {exceptions.Our} work is significant in the following respects. First, we have succeeded in designing a fully modular interpreter based on monad transformers that incudes features missing from Steele's, Espinosa's, and Wadler's earlier efforts. Second, we have found new ways to lift monad operations through monad transformers, in particular difficult cases not achieved in Moggi's original work. Third, we have demonstrated that interactions between features are reflected in liftings and that semantics can be changed by reordering monad transformers. Finally, we have implemented our interpreter in Gofer, whose constructor classes provide just the added power over Haskell's type classes to allow precise and convenient expression of our ideas. This implementation includes a method for constructing extensible unions and a form of subtyping that is interesting in its own right.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/199448.199528},
    x-isbn = {0-89791-692-1},
    x-series = {POPL '95},
    x-url = {http://dx.doi.org/10.1145/199448.199528},
    xpages = {333--343},
    year = {1995}
}

@inproceedings{dvanhorn:Kastrinis2013Hybrid,
    author = {Kastrinis, George and Smaragdakis, Yannis},
    booktitle = {Proceedings of the 34th ACM SIGPLAN conference on Programming language design and implementation},
    citeulike-article-id = {12437335},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2462191},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2462156.2462191},
    date-added = {2014-11-13 05:18:07},
    location = {Seattle, Washington, USA},
    priority = {2},
    publisher = {ACM},
    title = {Hybrid Context-sensitivity for Points-to Analysis},
    x-abstract = {Context-sensitive points-to analysis is valuable for achieving high precision with good performance. The standard flavors of context-sensitivity are call-site-sensitivity ({kCFA}) and object-sensitivity. Combining both flavors of context-sensitivity increases precision but at an infeasibly high cost. We show that a selective combination of call-site- and object-sensitivity for Java points-to analysis is highly profitable. Namely, by keeping a combined context only when analyzing selected language features, we can closely approximate the precision of an analysis that keeps both contexts at all times. In terms of speed, the selective combination of both kinds of context not only vastly outperforms non-selective combinations but is also faster than a mere object-sensitive analysis. This result holds for a large array of analyses (e.g., 1-object-sensitive, 2-object-sensitive with a context-sensitive heap, type-sensitive) establishing a new set of performance/precision sweet spots.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2462156.2462191},
    x-isbn = {978-1-4503-2014-6},
    x-issn = {0362-1340},
    x-month = jun,
    x-series = {PLDI '13},
    x-url = {http://dx.doi.org/10.1145/2462156.2462191},
    xpages = {423--434},
    year = {2013}
}

@phdthesis{dvanhorn:Andersen1994Program,
    author = {Andersen, Lars O.},
    citeulike-article-id = {4924529},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.6502},
    date-added = {2014-11-13 05:00:51},
    priority = {2},
    school = {DIKU, University of Copenhagen},
    title = {Program Analysis and Specialization for the C Programming Language},
    x-abstract = {Software engineers are faced with a dilemma. They want to write general and wellstructured programs that are flexible and easy to maintain. On the other hand, generality has a price: efficiency. A specialized program solving a particular problem is often significantly faster than a general program. However, the development of specialized software is time-consuming, and is likely to exceed the production of today\^{a}s programmers. New techniques are required to solve this so-called software crisis. Partial evaluation is a program specialization technique that reconciles the benefits of generality with efficiency. This thesis presents an automatic partial evaluator for the Ansi C programming language. The content of this thesis is analysis and transformation of C programs. We develop several analyses that support the transformation of a program into its generating extension. A generating extension is a program that produces specialized programs when executed on parts of the input. The thesis contains the following main results.},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.6502},
    year = {1994}
}

@inproceedings{dvanhorn:Chase1990Analysis,
    author = {Chase, David R. and Wegman, Mark and Zadeck, F. Kenneth},
    booktitle = {Proceedings of the ACM SIGPLAN 1990 conference on Programming language design and implementation},
    citeulike-article-id = {741317},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=93585},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/93542.93585},
    date-added = {2014-11-13 03:58:43},
    location = {White Plains, New York, United States},
    priority = {2},
    publisher = {ACM},
    title = {Analysis of Pointers and Structures},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/93542.93585},
    x-isbn = {0-89791-364-7},
    x-issn = {0362-1340},
    x-month = jun,
    x-series = {PLDI '90},
    x-url = {http://dx.doi.org/10.1145/93542.93585},
    xpages = {296--310},
    year = {1990}
}

@article{dvanhorn:Midtgaard2012Controlflow,
    author = {Midtgaard, Jan},
    citeulike-article-id = {12591221},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2187671.2187672},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2187671.2187672},
    date-added = {2014-11-13 03:09:34},
    journal = {ACM Comput. Surv.},
    priority = {2},
    publisher = {ACM},
    title = {Control-flow Analysis of Functional Programs},
    x-abstract = {We present a survey of control-flow analysis of functional programs, which has been the subject of extensive investigation throughout the past 30 years. Analyses of the control flow of functional programs have been formulated in multiple settings and have led to many different approximations, starting with the seminal works of Jones, Shivers, and Sestoft. In this article, we survey control-flow analysis of functional programs by structuring the multitude of formulations and approximations and comparing them.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2187671.2187672},
    x-issn = {0360-0300},
    x-month = jun,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1145/2187671.2187672},
    x-volume = {44},
    year = {2012}
}

@inproceedings{dvanhorn:Smaragdakis2011Pick,
    author = {Smaragdakis, Yannis and Bravenboer, Martin and Lhot\'{a}k, Ondrej},
    booktitle = {Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {9533212},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1926390},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1925844.1926390},
    date-added = {2014-11-12 23:27:22},
    location = {Austin, Texas, USA},
    priority = {2},
    publisher = {ACM},
    title = {Pick Your Contexts Well: Understanding Object-sensitivity},
    x-abstract = {Object-sensitivity has emerged as an excellent context abstraction for points-to analysis in object-oriented languages. Despite its practical success, however, object-sensitivity is poorly understood. For instance, for a context depth of 2 or higher, past scalable implementations deviate significantly from the original definition of an object-sensitive analysis. The reason is that the analysis has many degrees of freedom, relating to which context elements are picked at every method call and object creation. We offer a clean model for the analysis design space, and discuss a formal and informal understanding of object-sensitivity and of how to create good object-sensitive analyses. The results are surprising in their extent. We find that past implementations have made a sub-optimal choice of contexts, to the severe detriment of precision and performance. We define a "full-object-sensitive" analysis that results in significantly higher precision, and often performance, for the exact same context depth. We also introduce "type-sensitivity" as an explicit approximation of object-sensitivity that preserves high context quality at substantially reduced cost. A type-sensitive points-to analysis makes an unconventional use of types as context: the context types are not dynamic types of objects involved in the analysis, but instead upper bounds on the dynamic types of their allocator objects. Our results expose the influence of context choice on the quality of points-to analysis and demonstrate type-sensitivity to be an idea with major impact: It decisively advances the state-of-the-art with a spectrum of analyses that simultaneously enjoy speed (several times faster than an analogous object-sensitive analysis), scalability (comparable to analyses with much less context-sensitivity), and precision (comparable to the best object-sensitive analysis with the same context depth).},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1925844.1926390},
    x-isbn = {978-1-4503-0490-0},
    x-issn = {0362-1340},
    x-month = jan,
    x-series = {POPL '11},
    x-url = {http://dx.doi.org/10.1145/1925844.1926390},
    xpages = {17--30},
    year = {2011}
}

@article{dvanhorn:Milanova2005Parameterized,
    author = {Milanova, Ana and Rountev, Atanas and Ryder, Barbara G.},
    citeulike-article-id = {3429127},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1044834.1044835},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1044834.1044835},
    date-added = {2014-11-12 22:59:11},
    journal = {ACM Trans. Softw. Eng. Methodol.},
    priority = {2},
    publisher = {ACM},
    title = {Parameterized Object Sensitivity for Points-to Analysis for {J}ava},
    x-abstract = {The goal of points-to analysis for Java is to determine the set of objects pointed to by a reference variable or a reference object field. We present object sensitivity, a new form of context sensitivity for flow-insensitive points-to analysis for Java. The key idea of our approach is to analyze a method separately for each of the object names that represent run-time objects on which this method may be invoked. To ensure flexibility and practicality, we propose a parameterization framework that allows analysis designers to control the tradeoffs between cost and precision in the object-sensitive {analysis.Side}-effect analysis determines the memory locations that may be modified by the execution of a program statement. Def-use analysis identifies pairs of statements that set the value of a memory location and subsequently use that value. The information computed by such analyses has a wide variety of uses in compilers and software tools. This work proposes new versions of these analyses that are based on object-sensitive points-to {analysis.We} have implemented two instantiations of our parameterized object-sensitive points-to analysis. On a set of 23 Java programs, our experiments show that these analyses have comparable cost to a context-insensitive points-to analysis for Java which is based on Andersen's analysis for C. Our results also show that object sensitivity significantly improves the precision of side-effect analysis and call graph construction, compared to (1) context-insensitive analysis, and (2) context-sensitive points-to analysis that models context using the invoking call site. These experiments demonstrate that object-sensitive analyses can achieve substantial precision improvement, while at the same time remaining efficient and practical.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1044834.1044835},
    x-issn = {1049-331X},
    x-month = jan,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1145/1044834.1044835},
    x-volume = {14},
    xpages = {1--41},
    year = {2005}
}

@article{dvanhorn:Xie2007Saturn,
    author = {Xie, Yichen and Aiken, Alex},
    citeulike-article-id = {2403573},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1232420.1232423},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1232420.1232423},
    date-added = {2014-10-28 06:53:33},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {Saturn: A Scalable Framework for Error Detection Using Boolean Satisfiability},
    x-abstract = {This article presents Saturn, a general framework for building precise and scalable static error detection systems. Saturn exploits recent advances in Boolean satisfiability ({SAT}) solvers and is path sensitive, precise down to the bit level, and models pointers and heap data. Our approach is also highly scalable, which we achieve using two techniques. First, for each program function, several optimizations compress the size of the Boolean formulas that model the control flow and data flow and the heap locations accessed by a function. Second, summaries in the spirit of type signatures are computed for each function, allowing interprocedural analysis without a dramatic increase in the size of the Boolean constraints to be solved. We have experimentally validated our approach by conducting two case studies involving a Linux lock checker and a memory leak checker. Results from the experiments show that our system scales well, parallelizes well, and finds more errors with fewer false positives than previous static error detection systems.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1232420.1232423},
    x-issn = {0164-0925},
    x-month = may,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1145/1232420.1232423},
    x-volume = {29},
    xpages = {16+},
    year = {2007}
}

@inproceedings{dvanhorn:Aiken2007Overview,
    author = {Aiken, Alex and Bugrara, Suhabe and Dillig, Isil and Dillig, Thomas and Hackett, Brian and Hawkins, Peter},
    booktitle = {Proceedings of the 7th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering},
    citeulike-article-id = {13410792},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1251543},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1251535.1251543},
    date-added = {2014-10-28 06:52:48},
    location = {San Diego, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {An Overview of the Saturn Project},
    x-abstract = {We present an overview of the Saturn program analysis system, including a rationale for three major design decisions: the use of function-at-a-time, or summary-based, analysis, the use of constraints, and the use of a logic programming language to express program analysis algorithms. We argue that the combination of summaries and constraints allows Saturn to achieve both great scalability and great precision, while the use of a logic programming language with constraints allows for succinct, high-level expression of program analyses.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1251535.1251543},
    x-isbn = {978-1-59593-595-3},
    x-series = {PASTE '07},
    x-url = {http://dx.doi.org/10.1145/1251535.1251543},
    xpages = {43--48},
    year = {2007}
}

@article{dvanhorn:Dillig2008Sound,
    author = {Dillig, Isil and Dillig, Thomas and Aiken, Alex},
    citeulike-article-id = {3383611},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1379022.1375615},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1379022.1375615},
    date-added = {2014-10-28 06:52:07},
    journal = {SIGPLAN Not.},
    priority = {2},
    publisher = {ACM},
    title = {Sound, Complete and Scalable Path-sensitive Analysis},
    x-abstract = {We present a new, precise technique for fully path- and context-sensitive program analysis. Our technique exploits two observations: First, using quantified, recursive formulas, path- and context-sensitive conditions for many program properties can be expressed exactly. To compute a closed form solution to such recursive constraints, we differentiate between observable and unobservable variables, the latter of which are existentially quantified in our approach. Using the insight that unobservable variables can be eliminated outside a certain scope, our technique computes satisfiability- and validity-preserving closed-form solutions to the original recursive constraints. We prove the solution is as precise as the original system for answering may and must queries as well as being small in practice, allowing our technique to scale to the entire Linux kernel, a program with over 6 million lines of code.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1379022.1375615},
    x-issn = {0362-1340},
    x-month = jun,
    x-number = {6},
    x-url = {http://dx.doi.org/10.1145/1379022.1375615},
    x-volume = {43},
    xpages = {270--280},
    year = {2008}
}

@inproceedings{dvanhorn:Reisner2010Using,
    author = {Reisner, Elnatan and Song, Charles and Ma, Kin K. and Foster, Jeffrey S. and Porter, Adam},
    booktitle = {Proceedings of the 32Nd ACM/IEEE International Conference on Software Engineering - Volume 1},
    citeulike-article-id = {9913859},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1806864},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1806799.1806864},
    date-added = {2014-10-23 04:41:52},
    location = {Cape Town, South Africa},
    priority = {2},
    publisher = {ACM},
    title = {Using Symbolic Evaluation to Understand Behavior in Configurable Software Systems},
    x-abstract = {Many modern software systems are designed to be highly configurable, which increases flexibility but can make programs hard to test, analyze, and understand. We present an initial empirical study of how configuration options affect program behavior. We conjecture that, at certain levels of abstraction, configuration spaces are far smaller than the worst case, in which every configuration is distinct. We evaluated our conjecture by studying three configurable software systems: vsftpd, {ngIRCd}, and grep. We used symbolic evaluation to discover how the settings of run-time configuration options affect line, basic block, edge, and condition coverage for our subjects under a given test suite. Our results strongly suggest that for these subject programs, test suites, and configuration options, when abstracted in terms of the four coverage criteria above, configuration spaces are in fact much smaller than combinatorics would suggest and are effectively the composition of many small, self-contained groupings of options.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1806799.1806864},
    x-isbn = {978-1-60558-719-6},
    x-series = {ICSE '10},
    x-url = {http://dx.doi.org/10.1145/1806799.1806864},
    xpages = {445--454},
    year = {2010}
}

@inproceedings{dvanhorn:Ma2011Directed,
    author = {Ma, Kin K. and Phang, Khoo Y. and Foster, Jeffrey S. and Hicks, Michael},
    booktitle = {Proceedings of the 18th International Conference on Static Analysis},
    citeulike-article-id = {13405703},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2041563},
    date-added = {2014-10-23 04:40:18},
    location = {Venice, Italy},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Directed Symbolic Execution},
    x-abstract = {In this paper, we study the problem of automatically finding program executions that reach a particular target line. This problem arises in many debugging scenarios; for example, a developer may want to confirm that a bug reported by a static analysis tool on a particular line is a true positive. We propose two new directed symbolic execution strategies that aim to solve this problem: shortest-distance symbolic execution ({SDSE}) uses a distance metric in an interprocedural control flow graph to guide symbolic execution toward a particular target; and call-chain-backward symbolic execution ({CCBSE}) iteratively runs forward symbolic execution, starting in the function containing the target line, and then jumping backward up the call chain until it finds a feasible path from the start of the program. We also propose a hybrid strategy, {Mix-CCBSE}, which alternates {CCBSE} with another (forward) search strategy. We compare these three with several existing strategies from the literature on a suite of six {GNU} Coreutils programs. We find that {SDSE} performs extremely well in many cases but may fail badly. {CCBSE} also performs quite well, but imposes additional overhead that sometimes makes it slower than {SDSE}. Considering all our benchmarks together, {Mix-CCBSE} performed best on average, combining to good effect the features of its constituent components.},
    x-address = {Berlin, Heidelberg},
    x-isbn = {978-3-642-23701-0},
    x-series = {SAS'11},
    x-url = {http://portal.acm.org/citation.cfm?id=2041563},
    xpages = {95--111},
    year = {2011}
}

@incollection{dvanhorn:Pasareanu2004Verification,
    author = {P\u{a}s\u{a}reanu, CorinaS and Visser, Willem},
    booktitle = {Model Checking Software},
    citeulike-article-id = {13405700},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-24732-6\_13},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-540-24732-6\_13},
    date-added = {2014-10-23 04:33:29},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Verification of Java Programs Using Symbolic Execution and Invariant Generation},
    x-abstract = {Software verification is recognized as an important and difficult problem. We present a novel framework, based on symbolic execution, for the automated verification of software. The framework uses annotations in the form of method specifications and loop invariants. We present a novel iterative technique that uses invariant strengthening and approximation for discovering these loop invariants automatically. The technique handles different types of data (e.g. boolean and numeric constraints, dynamically allocated structures and arrays) and it allows for checking universally quantified formulas. Our framework is built on top of the Java {PathFinder} model checking toolset and it was used for the verification of several non-trivial Java programs.},
    x-doi = {10.1007/978-3-540-24732-6\_13},
    x-editor = {Graf, Susanne and Mounier, Laurent},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-24732-6\_13},
    x-volume = {2989},
    xpages = {164--181},
    year = {2004}
}

@article{dvanhorn:Visser2004Test,
    author = {Visser, Willem and P\v{a}s\v{a}reanu, Corina S. and Khurshid, Sarfraz},
    citeulike-article-id = {80857},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1013886.1007526},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1013886.1007526},
    date-added = {2014-10-23 04:32:57},
    journal = {SIGSOFT Softw. Eng. Notes},
    priority = {2},
    publisher = {ACM},
    title = {Test Input Generation with Java {PathFinder}},
    x-abstract = {We show how model checking and symbolic execution can be used to generate test inputs to achieve structural coverage of code that manipulates complex data structures. We focus on obtaining branch-coverage during unit testing of some of the core methods of the red-black tree implementation in the Java {TreeMap} library, using the Java {PathFinder} model checker. Three different test generation techniques will be introduced and compared, namely, straight model checking of the code, model checking used in a black-box fashion to generate all inputs up to a fixed size, and lastly, model checking used during white-box test input generation. The main contribution of this work is to show how efficient white-box test input generation can be done for code manipulating complex data, taking into account complex method preconditions.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1013886.1007526},
    x-isbn = {1581138202},
    x-issn = {0163-5948},
    x-month = jul,
    x-number = {4},
    x-url = {http://dx.doi.org/10.1145/1013886.1007526},
    x-volume = {29},
    xpages = {97--107},
    year = {2004}
}

@inproceedings{dvanhorn:Song2008BitBlaze,
    author = {Song, Dawn and Brumley, David and Yin, Heng and Caballero, Juan and Jager, Ivan and Kang, Min G. and Liang, Zhenkai and Newsome, James and Poosankam, Pongsin and Saxena, Prateek},
    booktitle = {Proceedings of the 4th International Conference on Information Systems Security},
    chapter = {1},
    citeulike-article-id = {7356749},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1496257},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-89862-7\_1},
    citeulike-linkout-2 = {http://www.springerlink.com/content/j345p1214231552q},
    date-added = {2014-10-23 04:27:41},
    location = {Hyderabad, India},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {{BitBlaze}: A New Approach to Computer Security via Binary Analysis},
    x-abstract = {In this paper, we give an overview of the {BitBlaze} project, a new approach to computer security via binary analysis. In particular, {BitBlaze} focuses on building a unified binary analysis platform and using it to provide novel solutions to a broad spectrum of different security problems. The binary analysis platform is designed to enable accurate analysis, provide an extensible architecture, and combines static and dynamic analysis as well as program verification techniques to satisfy the common needs of security applications. By extracting security-related properties from binary programs directly, {BitBlaze} enables a principled, root-cause based approach to computer security, offering novel and effective solutions, as demonstrated with over a dozen different security applications.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-89862-7\_1},
    x-isbn = {978-3-540-89861-0},
    x-issn = {0302-9743},
    x-series = {ICISS '08},
    x-url = {http://dx.doi.org/10.1007/978-3-540-89862-7\_1},
    x-volume = {5352},
    xpages = {1--25},
    year = {2008}
}

@inproceedings{dvanhorn:Hayden2012Specifying,
    author = {Hayden, Christopher M. and Magill, Stephen and Hicks, Michael and Foster, Nate and Foster, Jeffrey S.},
    booktitle = {Proceedings of the 4th International Conference on Verified Software: Theories, Tools, Experiments},
    citeulike-article-id = {13405458},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2189336},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-642-27705-4\_22},
    date-added = {2014-10-22 21:31:01},
    location = {Philadelphia, PA},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Specifying and Verifying the Correctness of Dynamic Software Updates},
    x-abstract = {Dynamic software updating ({DSU}) systems allow running programs to be patched on-the-fly to add features or fix bugs. While dynamic updates can be tricky to write, techniques for establishing their correctness have received little attention. In this paper, we present the first methodology for automatically verifying the correctness of dynamic updates. Programmers express the desired properties of an updated execution using <em>client-oriented specifications</em> ({CO}-specs), which can describe a wide range of client-visible behaviors. We verify {CO}-specs automatically by using off-the-shelf tools to analyze a <em>merged</em> program, which is a combination of the old and new versions of a program. We formalize the merging transformation and prove it correct. We have implemented a program merger for C, and applied it to updates for the Redis key-value store and several synthetic programs. Using Thor, a verification tool, we could verify many of the synthetic programs; using Otter, a symbolic executor, we could analyze every program, often in less than a minute. Both tools were able to detect faulty patches and incurred only a factor-of-four slowdown, on average, compared to single version programs.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-27705-4\_22},
    x-isbn = {978-3-642-27704-7},
    x-series = {VSTTE'12},
    x-url = {http://dx.doi.org/10.1007/978-3-642-27705-4\_22},
    xpages = {278--293},
    year = {2012}
}

@article{dvanhorn:Harman1998Program,
    author = {Harman, Mark and Gallagher, Keith B.},
    citeulike-article-id = {13405423},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0950-5849(98)00084-6},
    date-added = {2014-10-22 20:25:37},
    journal = {Information and Software Technology},
    priority = {2},
    title = {Program slicing},
    x-doi = {10.1016/s0950-5849(98)00084-6},
    x-issn = {09505849},
    x-month = dec,
    x-number = {11-12},
    x-url = {http://dx.doi.org/10.1016/s0950-5849(98)00084-6},
    x-volume = {40},
    xpages = {577--581},
    year = {1998}
}

@inbook{dvanhorn:Binkley2004Survey,
    author = {Binkley, David and Harman, Mark},
    citeulike-article-id = {13405421},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0065-2458(03)62003-6},
    date-added = {2014-10-22 20:21:45},
    priority = {2},
    publisher = {Elsevier},
    title = {A Survey of Empirical Results on Program Slicing},
    x-doi = {10.1016/s0065-2458(03)62003-6},
    x-isbn = {9780120121625},
    x-url = {http://dx.doi.org/10.1016/s0065-2458(03)62003-6},
    x-volume = {62},
    xpages = {105--178},
    year = {2004}
}

@article{dvanhorn:Horwitz1990Interprocedural,
    author = {Horwitz, Susan and Reps, Thomas and Binkley, David},
    citeulike-article-id = {506076},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=77608},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/77606.77608},
    date-added = {2014-10-22 20:19:06},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {Interprocedural Slicing Using Dependence Graphs},
    x-abstract = {The notion of a program slice, originally introduced by Mark Weiser, is useful in program debugging, automatic parallelization, and program integration. A slice of a program is taken with respect to a program point p and a variable x; the slice consists of all statements of the program that might affect the value of x at point p. This paper concerns the problem of interprocedural slicing—generating a slice of an entire program, where the slice crosses the boundaries of procedure calls. To solve this problem, we introduce a new kind of graph to represent programs, called a system dependence graph, which extends previous dependence representations to incorporate collections of procedures (with procedure calls) rather than just monolithic programs. Our main result is an algorithm for interprocedural slicing that uses the new representation. (It should be noted that our work concerns a somewhat restricted kind of slice: rather than permitting a program to b
e sliced with respect to program point p and an arbitrary variable, a slice must be taken with respect to a variable that is defined or used at {p.)The} chief difficulty in interprocedural slicing is correctly accounting for the calling context of a called procedure. To handle this problem, system dependence graphs include some data dependence edges that represent transitive dependences due to the effects of procedure calls, in addition to the conventional direct-dependence edges. These edges are constructed with the aid of an auxiliary structure that represents calling and parameter-linkage relationships. This structure takes the form of an attribute grammar. The step of computing the required transitive-dependence edges is reduced to the construction of the subordinate characteristic graphs for the grammar's nonterminals.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/77606.77608},
    x-issn = {0164-0925},
    x-month = jan,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1145/77606.77608},
    x-volume = {12},
    xpages = {26--60},
    year = {1990}
}

@article{dvanhorn:Weiser1984Program,
    author = {Weiser, Mark},
    citeulike-article-id = {13405258},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2283037.2283165},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tse.1984.5010248},
    date-added = {2014-10-22 20:18:28},
    journal = {IEEE Trans. Softw. Eng.},
    priority = {2},
    publisher = {IEEE Press},
    title = {Program Slicing},
    x-abstract = {Program slicing is a method for automatically decomposing programs by analyzing their data flow and control flow. Starting from a subset of a program's behavior, slicing reduces that program to a minimal form which still produces that behavior. The reduced program, called a ``slice,'' is an independent program guaranteed to represent faithfully the original program within the domain of the specified subset of behavior. Some properties of slices are presented. In particular, finding statement-minimal slices is in general unsolvable, but using data flow analysis is sufficient to find approximate slices. Potential applications include automatic slicing tools for debuggng and parallel processing of slices.},
    x-address = {Piscataway, NJ, USA},
    x-doi = {10.1109/tse.1984.5010248},
    x-issn = {0098-5589},
    x-month = jul,
    x-number = {4},
    x-url = {http://dx.doi.org/10.1109/tse.1984.5010248},
    x-volume = {10},
    xpages = {352--357},
    year = {1984}
}

@inproceedings{dvanhorn:Weiser1981Program,
    author = {Weiser, Mark},
    booktitle = {Proceedings of the 5th International Conference on Software Engineering},
    citeulike-article-id = {522778},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=802557},
    date-added = {2014-10-22 20:15:42},
    location = {San Diego, California, USA},
    priority = {2},
    publisher = {IEEE Press},
    title = {Program Slicing},
    x-abstract = {Program slicing is a method used by experienced computer programmers for abstracting from programs. Starting from a subset of a program's behavior, slicing reduces that program to a minimal form which still produces that behavior. The reduced program, called a  ” slice”, is an independent program guaranteed to faithfully represent the original program within the domain of the specified subset of {behavior.Finding} a slice is in general unsolvable. A dataflow algorithm is presented for approximating slices when the behavior subset is specified as the values of a set of variables at a statement. Experimental evidence is presented that these slices are used by programmers during debugging. Experience with two automatic slicing tools is summarized. New measures of program complexity are suggested based on the organization of a program's slices.},
    x-address = {Piscataway, NJ, USA},
    x-isbn = {0-89791-146-6},
    x-series = {ICSE '81},
    x-url = {http://portal.acm.org/citation.cfm?id=802557},
    xpages = {439--449},
    year = {1981}
}

@inproceedings{dvanhorn:Cook2013Reasoning,
    author = {Cook, Byron and Koskinen, Eric},
    booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13403975},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2491969},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2491956.2491969},
    date-added = {2014-10-22 13:36:01},
    location = {Seattle, Washington, USA},
    priority = {2},
    publisher = {ACM},
    title = {Reasoning About Nondeterminism in Programs},
    x-abstract = {Branching-time temporal logics (e.g. {CTL}, {CTL}*, modal mu-calculus) allow us to ask sophisticated questions about the nondeterminism that appears in systems. Applications of this type of reasoning include planning, games, security analysis, disproving, precondition synthesis, environment synthesis, etc. Unfortunately, existing automatic branching-time verification tools have limitations that have traditionally restricted their applicability (e.g. push-down systems only, universal path quantifiers only, etc). In this paper we introduce an automation strategy that lifts many of these previous restrictions. Our method works reliably for properties with non-trivial mixtures of universal and existential modal operators. Furthermore, our approach is designed to support (possibly infinite-state) programs. The basis of our approach is the observation that existential reasoning can be reduced to universal reasoning if the system's state-space is appropriately restricted. This restriction on the state-space must meet a constraint derived from recent work on proving non-termination. The observation leads to a new route for implementation based on existing tools. To demonstrate the practical viability of our approach, we report on the results applying our preliminary implementation to a set of benchmarks drawn from the Windows operating system, the {PostgreSQL} database server, {SoftUpdates} patching system, as well as other hand-crafted examples.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2491956.2491969},
    x-isbn = {978-1-4503-2014-6},
    x-series = {PLDI '13},
    x-url = {http://dx.doi.org/10.1145/2491956.2491969},
    xpages = {219--230},
    year = {2013}
}

@inproceedings{dvanhorn:Nguyen2014Soft,
    author = {Nguyen, Ph\'{u}c C. and Hochstadt, Sam T. and Van Horn, David},
    booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {13403599},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2628156},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2628136.2628156},
    date-added = {2014-10-22 00:16:50},
    location = {Gothenburg, Sweden},
    priority = {2},
    publisher = {ACM},
    title = {Soft Contract Verification},
    x-abstract = {Behavioral software contracts are a widely used mechanism for governing the flow of values between components. However, run-time monitoring and enforcement of contracts imposes significant overhead and delays discovery of faulty components to run-time. To overcome these issues, we present soft contract verification, which aims to statically prove either complete or partial contract correctness of components, written in an untyped, higher-order language with first-class contracts. Our approach uses higher-order symbolic execution, leveraging contracts as a source of symbolic values including unknown behavioral values, and employs an updatable heap of contract invariants to reason about flow-sensitive facts. We prove the symbolic execution soundly approximates the dynamic semantics and that verified programs can't be blamed. The approach is able to analyze first-class contracts, recursive data structures, unknown functions, and control-flow-sensitive refinements of values, which are all idiomatic in dynamic languages. It makes effective use of an off-the-shelf solver to decide problems without heavy encodings. The approach is competitive with a wide range of existing tools - including type systems, flow analyzers, and model checkers - on their own benchmarks.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2628136.2628156},
    x-isbn = {978-1-4503-2873-9},
    x-series = {ICFP '14},
    x-url = {http://dx.doi.org/10.1145/2628136.2628156},
    xpages = {139--152},
    year = {2014}
}

@incollection{dvanhorn:Hoffmann2014TypeBased,
    author = {Hoffmann, Jan and Shao, Zhong},
    booktitle = {Functional and Logic Programming},
    citeulike-article-id = {13388845},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-319-07151-0\_10},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-319-07151-0\_10},
    date-added = {2014-10-11 18:59:51},
    priority = {2},
    publisher = {Springer International Publishing},
    title = {{Type-Based} Amortized Resource Analysis with Integers and Arrays},
    x-abstract = {Proving bounds on the resource consumption of a program by statically analyzing its source code is an important and well-studied problem. Automatic approaches for numeric programs with side effects usually apply abstract interpretation–based invariant generation to derive bounds on loops and recursion depths of function calls. This paper presents an alternative approach to resource-bound analysis for numeric, heap-manipulating programs that uses type-based amortized resource analysis. As a first step towards the analysis of imperative code, the technique is developed for a first-order {ML}-like language with unsigned integers and arrays. The analysis automatically derives bounds that are multivariate polynomials in the numbers and the lengths of the arrays in the input. Experiments with example programs demonstrate two main advantages of amortized analysis over current abstract interpretation–based techniques. For one thing, amortized analysis can handle programs with non-linear intermediate values like f((n + m)2). For another thing, amortized analysis is compositional and works naturally for compound programs like f(g(x)).},
    x-doi = {10.1007/978-3-319-07151-0\_10},
    x-editor = {Codish, Michael and Sumii, Eijiro},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-319-07151-0\_10},
    x-volume = {8475},
    xpages = {152--168},
    year = {2014}
}

@incollection{dvanhorn:Hoffmann2010BAmortized,
    author = {Hoffmann, Jan and Hofmann, Martin},
    booktitle = {Programming Languages and Systems},
    citeulike-article-id = {13388842},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2175502},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-642-11957-6\_16},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-642-11957-6\_16},
    date-added = {2014-10-11 18:57:42},
    location = {Paphos, Cyprus},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Amortized Resource Analysis with Polynomial Potential},
    x-abstract = {In 2003, Hofmann and Jost introduced a type system that uses a potential-based amortized analysis to infer bounds on the resource consumption of (first-order) functional programs. This analysis has been successfully applied to many standard algorithms but is limited to bounds that are linear in the size of the input. Here we extend this system to polynomial resource bounds. An automatic amortized analysis is used to infer these bounds for functional programs without further annotations if a maximal degree for the bounding polynomials is given. The analysis is generic in the resource and can obtain good bounds on heap-space, stack-space and time usage.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-11957-6\_16},
    x-editor = {Gordon, AndrewD},
    x-isbn = {3-642-11956-5, 978-3-642-11956-9},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-11957-6\_16},
    x-volume = {6012},
    xpages = {287--306},
    year = {2010}
}

@incollection{dvanhorn:Hoffmann2012Resource,
    author = {Hoffmann, Jan and Aehlig, Klaus and Hofmann, Martin},
    booktitle = {Computer Aided Verification},
    citeulike-article-id = {11841310},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-31424-7\_64},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-31424-7\_64},
    date-added = {2014-10-11 18:53:34},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Resource Aware {ML}},
    x-abstract = {The automatic determination of the quantitative resource consumption of programs is a classic research topic which has many applications in software development. Recently, we developed a novel multivariate amortized resource analysis that automatically computes polynomial resource bounds for first-order functional programs. In this tool paper, we describe Resource Aware {ML} ({RAML}), a functional programming language that implements our analysis. Other than in earlier articles, we focus on the practical aspects of the implementation. We describe the syntax of {RAML}, the code transformation prior to the analysis, the web interface, the output of the analysis, and the results of our experiments with the analysis of example programs.},
    x-doi = {10.1007/978-3-642-31424-7\_64},
    x-editor = {Madhusudan, P. and Seshia, SanjitA},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-31424-7\_64},
    x-volume = {7358},
    xpages = {781--786},
    year = {2012}
}

@inproceedings{dvanhorn:Hoffmann2010Amortized,
    author = {Hoffmann, Jan and Hofmann, Martin},
    booktitle = {Proceedings of the 8th Asian Conference on Programming Languages and Systems},
    citeulike-article-id = {13388841},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1947891},
    date-added = {2014-10-11 18:47:53},
    location = {Shanghai, China},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Amortized Resource Analysis with Polymorphic Recursion and Partial Big-step Operational Semantics},
    x-abstract = {This paper studies the problem of statically determining upper bounds on the resource consumption of first-order functional programs. A previous work approached the problem with an automatic type-based amortized analysis for polynomial resource bounds. The analysis is parametric in the resource and can be instantiated to heap space, stack space, or clock cycles. Experiments with a prototype implementation have shown that programs are analyzed efficiently and that the computed bounds exactly match the measured worst-case resource behavior for many functions. This paper describes the inference algorithm that is used in the implementation of the system. It can deal with resource-polymorphic recursion which is required in the type derivation of many functions. The computation of the bounds is fully automatic if a maximal degree of the polynomials is given. The soundness of the inference is proved with respect to a novel operational semantics for partial evaluations to show that the inferred bounds hold for terminating as well as non-terminating computations. A corollary is that run-time bounds also establish the termination of programs.},
    x-address = {Berlin, Heidelberg},
    x-isbn = {3-642-17163-X, 978-3-642-17163-5},
    x-series = {APLAS'10},
    x-url = {http://portal.acm.org/citation.cfm?id=1947891},
    xpages = {172--187},
    year = {2010}
}

@inproceedings{dvanhorn:Carbonneaux2014Endtoend,
    author = {Carbonneaux, Quentin and Hoffmann, Jan and Ramananandro, Tahina and Shao, Zhong},
    booktitle = {Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13388840},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2594301},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2666356.2594301},
    date-added = {2014-10-11 18:45:54},
    priority = {2},
    publisher = {ACM},
    title = {End-to-end Verification of Stack-space Bounds for C Programs},
    x-abstract = {Verified compilers guarantee the preservation of semantic properties and thus enable formal verification of programs at the source level. However, important quantitative properties such as memory and time usage still have to be verified at the machine level where interactive proofs tend to be more tedious and automation is more challenging. This article describes a framework that enables the formal verification of stack-space bounds of compiled machine code at the C level. It consists of a verified {CompCert}-based compiler that preserves quantitative properties, a verified quantitative program logic for interactive stack-bound development, and a verified stack analyzer that automatically derives stack bounds during compilation. The framework is based on event traces that record function calls and returns. The source language is {CompCert} Clight and the target language is x86 assembly. The compiler is implemented in the Coq Proof Assistant and it is proved that crucial properties of event traces are preserved during compilation. A novel quantitative Hoare logic is developed to verify stack-space bounds at the {CompCert} Clight level. The quantitative logic is implemented in Coq and proved sound with respect to event traces generated by the small-step semantics of {CompCert} Clight. Stack-space bounds can be proved at the source level without taking into account low-level details that depend on the implementation of the compiler. The compiler fills in these low-level details during compilation and generates a concrete stack-space bound that applies to the produced machine code. The verified stack analyzer is guaranteed to automatically derive bounds for code with non-recursive functions. It generates a derivation in the quantitative logic to ensure soundness as well as interoperability with interactively developed stack bounds. In an experimental evaluation, the developed framework is used to obtain verified stack-space bounds for micro benchmarks as well as real system code. The examples include the verified operating-system kernel {CertiKOS}, parts of the {MiBench} embedded benchmark suite, and programs from the {CompCert} benchmarks. The derived bounds are close to the measured stack-space usage of executions of the compiled programs on a Linux x86 system.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2666356.2594301},
    x-issn = {0362-1340},
    x-month = jun,
    x-url = {http://dx.doi.org/10.1145/2666356.2594301},
    xpages = {270--281},
    year = {2014}
}

@inproceedings{dvanhorn:Shalimov2013Advanced,
    author = {Shalimov, Alexander and Zuikov, Dmitry and Zimarina, Daria and Pashkov, Vasily and Smeliansky, Ruslan},
    booktitle = {Proceedings of the 9th Central \&\#38; Eastern European Software Engineering Conference in Russia},
    citeulike-article-id = {13388839},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2556621},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2556610.2556621},
    date-added = {2014-10-11 18:41:18},
    location = {Moscow, Russia},
    priority = {2},
    publisher = {ACM},
    title = {Advanced Study of {SDN}/{OpenFlow} Controllers},
    x-abstract = {This paper presents an independent comprehensive analysis of the efficiency indexes of popular open source {SDN}/{OpenFlow} controllers ({NOX}, {POX}, Beacon, Floodlight, {MuL}, Maestro, Ryu). The analysed indexes include performance, scalability, reliability, and security. For testing purposes we developed the new framework called hcprobe. The test bed and the methodology we used are discussed in detail so that everyone could reproduce our experiments. The result of the evaluation show that modern {SDN}/{OpenFlow} controllers are not ready to be used in production and have to be improved in order to increase all above mentioned characteristics.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2556610.2556621},
    x-isbn = {978-1-4503-2641-4},
    x-series = {CEE-SECR '13},
    x-url = {http://dx.doi.org/10.1145/2556610.2556621},
    year = {2013}
}

@inproceedings{dvanhorn:Gulwani2009Controlflow,
    author = {Gulwani, Sumit and Jain, Sagar and Koskinen, Eric},
    booktitle = {Proceedings of the 2009 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13381674},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1542476.1542518},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1543135.1542518},
    date-added = {2014-10-03 15:04:46},
    priority = {2},
    publisher = {ACM},
    title = {Control-flow Refinement and Progress Invariants for Bound Analysis},
    x-abstract = {Symbolic complexity bounds help programmers understand the performance characteristics of their implementations. Existing work provides techniques for statically determining bounds of procedures with simple control-flow. However, procedures with nested loops or multiple paths through a single loop are challenging. In this paper we describe two techniques, control-flow refinement and progress invariants, that together enable estimation of precise bounds for procedures with nested and multi-path loops. Control-flow refinement transforms a multi-path loop into a semantically equivalent code fragment with simpler loops by making the structure of path interleaving explicit. We show that this enables non-disjunctive invariant generation tools to find a bound on many procedures for which previous techniques were unable to prove termination. Progress invariants characterize relationships between consecutive states that can arise at a program location. We further present an algorithm that uses progress invariants to compute precise bounds for nested loops. The utility of these two techniques goes beyond our application to symbolic bound analysis. In particular, we discuss applications of control-flow refinement to proving safety properties that otherwise require disjunctive invariants. We have applied our methodology to over 670,000 lines of code of a significant Microsoft product and were able to find symbolic bounds for 90\% of the loops. We are not aware of any other published results that report experiences running a bound analysis on a real code-base.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1543135.1542518},
    x-issn = {0362-1340},
    x-month = jun,
    x-url = {http://dx.doi.org/10.1145/1543135.1542518},
    xpages = {375--385},
    year = {2009}
}

@inproceedings{dvanhorn:Gulwani2010Dimensions,
    author = {Gulwani, S.},
    booktitle = {Formal Methods in Computer-Aided Design (FMCAD), 2010},
    citeulike-article-id = {13381221},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5770924},
    date-added = {2014-10-03 01:14:21},
    institution = {Microsoft Res., Redmond, WA, USA},
    priority = {2},
    publisher = {IEEE},
    title = {Dimensions in program synthesis},
    x-isbn = {978-1-4577-0734-6},
    x-month = oct,
    x-url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5770924},
    xpages = {1},
    year = {2010}
}

@inproceedings{dvanhorn:Torlak2014Lightweight,
    author = {Torlak, Emina and Bodik, Rastislav},
    booktitle = {Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13381220},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2594340},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2594291.2594340},
    date-added = {2014-10-03 01:13:37},
    location = {Edinburgh, United Kingdom},
    priority = {2},
    publisher = {ACM},
    title = {A Lightweight Symbolic Virtual Machine for Solver-aided Host Languages},
    x-abstract = {Solver-aided domain-specific languages ({SDSLs}) are an emerging class of computer-aided programming systems. They ease the construction of programs by using satisfiability solvers to automate tasks such as verification, debugging, synthesis, and non-deterministic execution. But reducing programming tasks to satisfiability problems involves translating programs to logical constraints, which is an engineering challenge even for domain-specific languages. We have previously shown that translation to constraints can be avoided if {SDSLs} are implemented by (traditional) embedding into a host language that is itself solver-aided. This paper describes how to implement a symbolic virtual machine ({SVM}) for such a host language. Our symbolic virtual machine is lightweight because it compiles to constraints only a small subset of the host's constructs, while allowing {SDSL} designers to use the entire language, including constructs for {DSL} embedding. This lightweight compilation employs a novel symbolic execution technique with two key properties: it produces compact encodings, and it enables concrete evaluation to strip away host constructs that are outside the subset compilable to constraints. Our symbolic virtual machine architecture is at the heart of Rosette, a solver-aided language that is host to several new {SDSLs}.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2594291.2594340},
    x-isbn = {978-1-4503-2784-8},
    x-series = {PLDI '14},
    x-url = {http://dx.doi.org/10.1145/2594291.2594340},
    xpages = {530--541},
    year = {2014}
}

@inproceedings{dvanhorn:Lezama2005Programming,
    author = {Lezama, Armando S. and Rabbah, Rodric and Bod'{\i}k, Rastislav and Ebcio\u{g}lu, Kemal},
    booktitle = {Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13381219},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1065045},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1064978.1065045},
    date-added = {2014-10-03 01:11:56},
    priority = {2},
    publisher = {ACM},
    title = {Programming by Sketching for Bit-streaming Programs},
    x-abstract = {This paper introduces the concept of programming with sketches, an approach for the rapid development of high-performance applications. This approach allows a programmer to write clean and portable reference code, and then obtain a high-quality implementation by simply sketching the outlines of the desired implementation. Subsequently, a compiler automatically fills in the missing details while also ensuring that a completed sketch is faithful to the input reference code. In this paper, we develop {StreamBit} as a sketching methodology for the important class of bit-streaming programs (e.g., coding and {cryptography).A} sketch is a partial specification of the implementation, and as such, it affords several benefits to programmer in terms of productivity and code robustness. First, a sketch is easier to write compared to a complete implementation. Second, sketching allows the programmer to focus on exploiting algorithmic properties rather than on orchestrating low-level details. Third, a sketch-aware compiler rejects "buggy" sketches, thus improving reliability while allowing the programmer to quickly evaluate sophisticated implementation {ideas.We} evaluated the productivity and performance benefits of our programming methodology in a user-study, where a group of novice {StreamBit} programmers competed with a group of experienced C programmers on implementing a cipher. We learned that, given the same time budget, the ciphers developed in {StreamBit} ran 2.5x faster than ciphers coded in C. We also produced implementations of {DES} and Serpent that were competitive with hand optimized implementations available in the public domain.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1064978.1065045},
    x-issn = {0362-1340},
    x-month = jun,
    x-url = {http://dx.doi.org/10.1145/1064978.1065045},
    xpages = {281--294},
    year = {2005}
}

@article{dvanhorn:Lezama2006Combinatorial,
    author = {Lezama, Armando S. and Tancau, Liviu and Bodik, Rastislav and Seshia, Sanjit and Saraswat, Vijay},
    citeulike-article-id = {13098036},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1168907},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1168917.1168907},
    date-added = {2014-10-03 01:11:02},
    journal = {SIGOPS Oper. Syst. Rev.},
    priority = {2},
    publisher = {ACM},
    title = {Combinatorial Sketching for Finite Programs},
    x-abstract = {Sketching is a software synthesis approach where the programmer develops a partial implementation - a sketch - and a separate specification of the desired functionality. The synthesizer then completes the sketch to behave like the specification. The correctness of the synthesized implementation is guaranteed by the compiler, which allows, among other benefits, rapid development of highly tuned implementations without the fear of introducing {bugs.We} develop {SKETCH}, a language for finite programs with linguistic support for sketching. Finite programs include many highperformance kernels, including cryptocodes. In contrast to prior synthesizers, which had to be equipped with domain-specific rules, {SKETCH} completes sketches by means of a combinatorial search based on generalized boolean satisfiability. Consequently, our combinatorial synthesizer is complete for the class of finite programs: it is guaranteed to complete any sketch in theory, and in practice has scaled to realistic programming {problems.Freed} from domain rules, we can now write sketches as simpleto-understand partial programs, which are regular programs in which difficult code fragments are replaced with holes to be filled by the synthesizer. Holes may stand for index expressions, lookup tables, or bitmasks, but the programmer can easily define new kinds of holes using a single versatile synthesis {operator.We} have used {SKETCH} to synthesize an efficient implementation of the {AES} cipher standard. The synthesizer produces the most complex part of the implementation and runs in about an hour.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1168917.1168907},
    x-issn = {0163-5980},
    x-month = oct,
    x-number = {5},
    x-url = {http://dx.doi.org/10.1145/1168917.1168907},
    x-volume = {40},
    xpages = {404--415},
    year = {2006}
}

@inproceedings{dvanhorn:Alur2013Syntaxguided,
    author = {Alur, R. and Bodik, R. and Juniwal, G. and Martin, M. M. K. and Raghothaman, M. and Seshia, S. A. and Singh, R. and Solar-Lezama, A. and Torlak, E. and Udupa, A.},
    booktitle = {Formal Methods in Computer-Aided Design (FMCAD), 2013},
    citeulike-article-id = {13381218},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/fmcad.2013.6679385},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6679385},
    date-added = {2014-10-03 01:10:11},
    institution = {Univ. of Pennsylvania, Philadelphia, PA, USA},
    priority = {2},
    publisher = {IEEE},
    title = {Syntax-guided synthesis},
    x-doi = {10.1109/fmcad.2013.6679385},
    x-month = oct,
    x-url = {http://dx.doi.org/10.1109/fmcad.2013.6679385},
    xpages = {1--17},
    year = {2013}
}

@incollection{dvanhorn:Sharma2012Interpolants,
    author = {Sharma, Rahul and Nori, AdityaV and Aiken, Alex},
    booktitle = {Computer Aided Verification},
    citeulike-article-id = {13381217},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-31424-7\_11},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-31424-7\_11},
    date-added = {2014-10-03 01:09:03},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Interpolants as Classifiers},
    x-abstract = {We show how interpolants can be viewed as classifiers in supervised machine learning. This view has several advantages: First, we are able to use off-the-shelf classification techniques, in particular support vector machines ({SVMs}), for interpolation. Second, we show that {SVMs} can find relevant predicates for a number of benchmarks. Since classification algorithms are predictive, the interpolants computed via classification are likely to be invariants. Finally, the machine learning view also enables us to handle superficial non-linearities. Even if the underlying problem structure is linear, the symbolic constraints can give an impression that we are solving a non-linear problem. Since learning algorithms try to mine the underlying structure directly, we can discover the linear structure for such problems. We demonstrate the feasibility of our approach via experiments over benchmarks from various papers on program verification.},
    x-doi = {10.1007/978-3-642-31424-7\_11},
    x-editor = {Madhusudan, P. and Seshia, SanjitA},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-31424-7\_11},
    x-volume = {7358},
    xpages = {71--87},
    year = {2012}
}

@incollection{dvanhorn:Sharma2013Data,
    author = {Sharma, Rahul and Gupta, Saurabh and Hariharan, Bharath and Aiken, Alex and Liang, Percy and Nori, AdityaV},
    booktitle = {Programming Languages and Systems},
    citeulike-article-id = {13381216},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-37036-6\_31},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-37036-6\_31},
    date-added = {2014-10-03 01:08:20},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {A Data Driven Approach for Algebraic Loop Invariants},
    x-abstract = {We describe a {Guess-and-Check} algorithm for computing algebraic equation invariants of the form ∧ i f i (x 1,…,x n ) = 0, where each f i  is a polynomial over the variables x 1,…,x n  of the program. The  ” guess” phase is data driven and derives a candidate invariant from data generated from concrete executions of the program. This candidate invariant is subsequently validated in a  ” check” phase by an off-the-shelf {SMT} solver. Iterating between the two phases leads to a sound algorithm. Moreover, we are able to prove a bound on the number of decision procedure queries which {Guess-and-Check} requires to obtain a sound invariant. We show how {Guess-and-Check} can be extended to generate arbitrary boolean combinations of linear equalities as invariants, which enables us to generate expressive invariants to be consumed by tools that cannot handle non-linear arithmetic. We have evaluated our technique on a number of benchmark programs from recent papers on invariant generation. Our results are encouraging – we are able to efficiently compute algebraic invariants in all cases, with only a few tests.},
    x-doi = {10.1007/978-3-642-37036-6\_31},
    x-editor = {Felleisen, Matthias and Gardner, Philippa},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-37036-6\_31},
    x-volume = {7792},
    xpages = {574--592},
    year = {2013}
}

@incollection{dvanhorn:Sharma2014From,
    author = {Sharma, Rahul and Aiken, Alex},
    booktitle = {Computer Aided Verification},
    citeulike-article-id = {13381215},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-319-08867-9\_6},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-319-08867-9\_6},
    date-added = {2014-10-03 01:07:22},
    priority = {2},
    publisher = {Springer International Publishing},
    title = {From Invariant Checking to Invariant Inference Using Randomized Search},
    x-abstract = {We describe a general framework c2i for generating an invariant inference procedure from an invariant checking procedure. Given a checker and a language of possible invariants, c2i generates an inference procedure that iteratively invokes two phases. The search phase uses randomized search to discover candidate invariants and the validate phase uses the checker to either prove or refute that the candidate is an actual invariant. To demonstrate the applicability of c2i, we use it to generate inference procedures that prove safety properties of numerical programs, prove non-termination of numerical programs, prove functional specifications of array manipulating programs, prove safety properties of string manipulating programs, and prove functional specifications of heap manipulating programs that use linked list data structures.},
    x-doi = {10.1007/978-3-319-08867-9\_6},
    x-editor = {Biere, Armin and Bloem, Roderick},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-319-08867-9\_6},
    x-volume = {8559},
    xpages = {88--105},
    year = {2014}
}

@book{dvanhorn:ColindelaHiguera2010Grammatical,
    author = {Colin de la Higuera},
    citeulike-article-id = {13381214},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1830440},
    date-added = {2014-10-03 01:06:38},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Grammatical Inference: Learning Automata and Grammars},
    x-abstract = {The problem of inducing, learning or inferring grammars has been studied for decades, but only in recent years has grammatical inference emerged as an independent field with connections to many scientific disciplines, including bio-informatics, computational linguistics and pattern recognition. This book meets the need for a comprehensive and unified summary of the basic techniques and results, suitable for researchers working in these various areas. In Part I, the objects of use for grammatical inference are studied in detail: strings and their topology, automata and grammars, whether probabilistic or not. Part {II} carefully explores the main questions in the field: What does learning mean? How can we associate complexity theory with learning? In Part {III} the author describes a number of techniques and algorithms that allow us to learn from text, from an informant, or through interaction with the environment. These concern automata, grammars, rewriting systems, pattern languages or transducers.},
    x-address = {New York, NY, USA},
    x-isbn = {0521763169, 9780521763165},
    x-url = {http://portal.acm.org/citation.cfm?id=1830440},
    year = {2010}
}

@article{dvanhorn:Angluin1980Inductive,
    author = {Angluin, Dana},
    citeulike-article-id = {5845274},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0019-9958(80)90285-5},
    date-added = {2014-10-03 01:05:23},
    journal = {Information and Control},
    priority = {2},
    title = {Inductive inference of formal languages from positive data},
    x-doi = {10.1016/s0019-9958(80)90285-5},
    x-issn = {00199958},
    x-month = may,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1016/s0019-9958(80)90285-5},
    x-volume = {45},
    xpages = {117--135},
    year = {1980}
}

@article{dvanhorn:Xie2009Data,
    author = {Xie, Tao and Thummalapenta, S. and Lo, D. and Liu, Chao},
    citeulike-article-id = {5527867},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/MC.2009.256},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/mc.2009.256},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5197425},
    date-added = {2014-10-03 01:04:17},
    institution = {North Carolina State Univ., Raleigh, NC, USA},
    journal = {Computer},
    priority = {2},
    publisher = {IEEE},
    title = {Data Mining for Software Engineering},
    x-abstract = {To improve software productivity and quality, software engineers are increasingly applying data mining algorithms to various software engineering tasks. However, mining {SE} data poses several challenges. The authors present various algorithms to effectively mine sequences, graphs, and text from such data.},
    x-address = {Los Alamitos, CA, USA},
    x-doi = {10.1109/mc.2009.256},
    x-issn = {0018-9162},
    x-month = aug,
    x-number = {8},
    x-url = {http://dx.doi.org/10.1109/mc.2009.256},
    x-volume = {42},
    xpages = {55--62},
    year = {2009}
}

@inproceedings{dvanhorn:Shoham2007Static,
    author = {Shoham, Sharon and Yahav, Eran and Fink, Stephen and Pistoia, Marco},
    booktitle = {Proceedings of the 2007 International Symposium on Software Testing and Analysis},
    citeulike-article-id = {2808863},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1273463.1273487},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1273463.1273487},
    date-added = {2014-10-03 01:03:30},
    location = {London, United Kingdom},
    priority = {2},
    publisher = {ACM},
    title = {Static Specification Mining Using Automata-based Abstractions},
    x-abstract = {We present a novel approach to client-side mining of temporal {API} specifications based on static analysis. Specifically, we present an interprocedural analysis over a combined domain that abstracts both aliasing and event sequences for individual objects. The analysis uses a new family of automata-based abstractions to represent unbounded event sequences, designed to disambiguate distinct usage patterns and merge similar usage patterns. Additionally, our approach includes an algorithm that summarizes abstract traces based on automata clusters, and effectively rules out spurious behaviors. We show experimental results mining specifications from a number of Java clients and {APIs}. The results indicate that effective static analysis for client-side mining requires fairly precise treatment of aliasing and abstract event sequences. Based on the results, we conclude that static client-side specification mining shows promise as a complement or alternative to dynamic approaches.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1273463.1273487},
    x-isbn = {978-1-59593-734-6},
    x-series = {ISSTA '07},
    x-url = {http://dx.doi.org/10.1145/1273463.1273487},
    xpages = {174--184},
    year = {2007}
}

@inproceedings{dvanhorn:Ammons2002Mining,
    author = {Ammons, Glenn and Bodik, Rastislav and Larus, James R.},
    booktitle = {Proceedings of the 29th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {3418},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=503275},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/503272.503275},
    date-added = {2014-10-03 00:58:54},
    location = {Portland, Oregon},
    priority = {2},
    publisher = {ACM},
    title = {Mining Specifications},
    x-abstract = {Program verification is a promising approach to improving program quality, because it can search all possible program executions for specific errors. However, the need to formally describe correct behavior or errors is a major barrier to the widespread adoption of program verification, since programmers historically have been reluctant to write formal specifications. Automating the process of formulating specifications would remove a barrier to program verification and enhance its {practicality.This} paper describes specification mining, a machine learning approach to discovering formal specifications of the protocols that code must obey when interacting with an application program interface or abstract data type. Starting from the assumption that a working program is well enough debugged to reveal strong hints of correct protocols, our tool infers a specification by observing program execution and concisely summarizing the frequent interaction patterns as state machines that capture both temporal and data dependences. These state machines can be examined by a programmer, to refine the specification and identify errors, and can be utilized by automatic verification tools, to find {bugs.Our} preliminary experience with the mining tool has been promising. We were able to learn specifications that not only captured the correct protocol, but also discovered serious bugs.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/503272.503275},
    x-isbn = {1-58113-450-9},
    x-issn = {0362-1340},
    x-month = jan,
    x-series = {POPL '02},
    x-url = {http://dx.doi.org/10.1145/503272.503275},
    xpages = {4--16},
    year = {2002}
}

@inproceedings{dvanhorn:Saxena2009Loopextended,
    author = {Saxena, Prateek and Poosankam, Pongsin and McCamant, Stephen and Song, Dawn},
    booktitle = {Proceedings of the Eighteenth International Symposium on Software Testing and Analysis},
    citeulike-article-id = {6588691},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1572272.1572299},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1572272.1572299},
    date-added = {2014-10-03 00:51:25},
    location = {Chicago, IL, USA},
    priority = {2},
    publisher = {ACM},
    title = {Loop-extended Symbolic Execution on Binary Programs},
    x-abstract = {Mixed concrete and symbolic execution is an important technique for finding and understanding software bugs, including security-relevant ones. However, existing symbolic execution techniques are limited to examining one execution path at a time, in which symbolic variables reflect only direct data dependencies. We introduce loop-extended symbolic execution, a generalization that broadens the coverage of symbolic results in programs with loops. It introduces symbolic variables for the number of times each loop executes, and links these with features of a known input grammar such as variable-length or repeating fields. This allows the symbolic constraints to cover a class of paths that includes different numbers of loop iterations, expressing loop-dependent program values in terms of properties of the input. By performing more reasoning symbolically, instead of by undirected exploration, applications of loop-extended symbolic execution can achieve better results and/or require fewer program executions. To demonstrate our technique, we apply it to the problem of discovering and diagnosing buffer-overflow vulnerabilities in software given only in binary form. Our tool finds vulnerabilities in both a standard benchmark suite and 3 real-world applications, after generating only a handful of candidate inputs, and also diagnoses general vulnerability conditions.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1572272.1572299},
    x-isbn = {978-1-60558-338-9},
    x-series = {ISSTA '09},
    x-url = {http://dx.doi.org/10.1145/1572272.1572299},
    xpages = {225--236},
    year = {2009}
}

@inproceedings{dvanhorn:Cho2013BLITZ,
    author = {Cho, Chia Y. and D'Silva, V. and Song, D.},
    booktitle = {Automated Software Engineering (ASE), 2013 IEEE/ACM 28th International Conference on},
    citeulike-article-id = {13381206},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ase.2013.6693074},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6693074},
    date-added = {2014-10-03 00:50:41},
    institution = {Univ. of California, Berkeley, Berkeley, CA, USA},
    priority = {2},
    publisher = {IEEE},
    title = {{BLITZ}: Compositional bounded model checking for real-world programs},
    x-doi = {10.1109/ase.2013.6693074},
    x-month = nov,
    x-url = {http://dx.doi.org/10.1109/ase.2013.6693074},
    xpages = {136--146},
    year = {2013}
}

@inproceedings{dvanhorn:Cho2011MACE,
    author = {Cho, Chia Y. and Babi\'{c}, Domagoj and Poosankam, Pongsin and Chen, Kevin Z. and Wu, Edward X. and Song, Dawn},
    booktitle = {Proceedings of the 20th USENIX Conference on Security},
    citeulike-article-id = {13381205},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2028077},
    date-added = {2014-10-03 00:49:23},
    location = {San Francisco, CA},
    priority = {2},
    publisher = {USENIX Association},
    title = {{MACE}: Model-inference-assisted Concolic Exploration for Protocol and Vulnerability Discovery},
    x-abstract = {Programstate-space exploration is central to software security, testing, and verification. In this paper, we propose a novel technique for state-space exploration of software that maintains an ongoing interaction with its environment. Our technique uses a combination of symbolic and concrete execution to build an abstract model of the analyzed application, in the form of a finite-state automaton, and uses the model to guide further state-space exploration. Through exploration, {MACE} further refines the abstract model. Using the abstract model as a scaffold, our technique wields more control over the search process. In particular: (1) shifting search to different parts of the search-space becomes easier, resulting in higher code coverage, and (2) the search is less likely to get stuck in small local state-subspaces (e.g., loops) irrelevant to the application's interaction with the environment. Preliminary experimental results show significant increases in the code coverage and exploration depth. Further, our approach found a number of new deep vulnerabilities.},
    x-address = {Berkeley, CA, USA},
    x-series = {SEC'11},
    x-url = {http://portal.acm.org/citation.cfm?id=2028077},
    xpages = {10},
    year = {2011}
}

@inproceedings{dvanhorn:Cho2010Inference,
    author = {Cho, Chia Y. and Domagoj Babi and Eui Chul Richard Shin and Song, Dawn},
    booktitle = {Proceedings of the 17th ACM Conference on Computer and Communications Security},
    citeulike-article-id = {13381204},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1866307.1866355},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1866307.1866355},
    date-added = {2014-10-03 00:47:58},
    location = {Chicago, Illinois, USA},
    priority = {2},
    publisher = {ACM},
    title = {Inference and Analysis of Formal Models of Botnet Command and Control Protocols},
    x-abstract = {We propose a novel approach to infer protocol state machines in the realistic high-latency network setting, and apply it to the analysis of botnet Command and Control (C \&C) protocols. Our proposed techniques enable an order of magnitude reduction in the number of queries and time needed to learn a botnet C \&C protocol compared to classic algorithms (from days to hours for inferring the {MegaD} C \&C protocol). We also show that the computed protocol state machines enable formal analysis for botnet defense, including finding the weakest links in a protocol, uncovering protocol design flaws, inferring the existence of unobservable communication back-channels among botnet servers, and finding deviations of protocol implementations which can be used for fingerprinting. We validate our technique by inferring the protocol state-machine from Postfix's {SMTP} implementation and comparing the inferred state-machine to the {SMTP} standard. Further, our experimental results offer new insights into {MegaD}'s C \&C, showing our technique can be used as a powerful tool for defense against botnets.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1866307.1866355},
    x-isbn = {978-1-4503-0245-6},
    x-series = {CCS '10},
    x-url = {http://dx.doi.org/10.1145/1866307.1866355},
    xpages = {426--439},
    year = {2010}
}

@inproceedings{dvanhorn:Gulwani2010Reachabilitybound,
    author = {Gulwani, Sumit and Zuleger, Florian},
    booktitle = {Proceedings of the 2010 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13381203},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1806630},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1806596.1806630},
    date-added = {2014-10-03 00:46:52},
    location = {Toronto, Ontario, Canada},
    priority = {2},
    publisher = {ACM},
    title = {The Reachability-bound Problem},
    x-abstract = {We define the reachability-bound problem to be the problem of finding a symbolic worst-case bound on the number of times a given control location inside a procedure is visited in terms of the inputs to that procedure. This has applications in bounding resources consumed by a program such as time, memory, network-traffic, power, as well as estimating quantitative properties (as opposed to boolean properties) of data in programs, such as information leakage or uncertainty propagation. Our approach to solving the reachability-bound problem brings together two different techniques for reasoning about loops in an effective manner. One of these techniques is an abstract-interpretation based iterative technique for computing precise disjunctive invariants (to summarize nested loops). The other technique is a non-iterative proof-rules based technique (for loop bound computation) that takes over the role of doing inductive reasoning, while deriving its power from the use of {SMT} solvers to reason about abstract loop-free fragments. Our solution to the reachability-bound problem allows us to compute precise symbolic complexity bounds for several loops in .Net base-class libraries for which earlier techniques fail. We also illustrate the precision of our algorithm for disjunctive invariant computation (which has a more general applicability beyond the reachability-bound problem) on a set of benchmark examples.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1806596.1806630},
    x-isbn = {978-1-4503-0019-3},
    x-series = {PLDI '10},
    x-url = {http://dx.doi.org/10.1145/1806596.1806630},
    xpages = {292--304},
    year = {2010}
}

@inproceedings{dvanhorn:Chang2009Inputs,
    author = {Chang, R. and Jiang, Guofei and Ivancic, F. and Sankaranarayanan, S. and Shmatikov, V.},
    booktitle = {Computer Security Foundations Symposium, 2009. CSF '09. 22nd IEEE},
    citeulike-article-id = {13381202},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/csf.2009.13},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5230618},
    date-added = {2014-10-03 00:45:44},
    institution = {Univ. of Texas at Austin, Austin, TX, USA},
    priority = {2},
    publisher = {IEEE},
    title = {Inputs of Coma: Static Detection of {Denial-of-Service} Vulnerabilities},
    x-doi = {10.1109/csf.2009.13},
    x-isbn = {978-0-7695-3712-2},
    x-issn = {1940-1434},
    x-month = jul,
    x-url = {http://dx.doi.org/10.1109/csf.2009.13},
    xpages = {186--199},
    year = {2009}
}

@inproceedings{dvanhorn:Avgerinos2014Enhancing,
    author = {Avgerinos, Thanassis and Rebert, Alexandre and Cha, Sang K. and Brumley, David},
    booktitle = {Proceedings of the 36th International Conference on Software Engineering},
    citeulike-article-id = {13381201},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2568293},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2568225.2568293},
    date-added = {2014-10-03 00:44:50},
    location = {Hyderabad, India},
    priority = {2},
    publisher = {ACM},
    title = {Enhancing Symbolic Execution with Veritesting},
    x-abstract = {We present {MergePoint}, a new binary-only symbolic execution system for large-scale and fully unassisted testing of commodity off-the-shelf ({COTS}) software. {MergePoint} introduces veritesting, a new technique that employs static symbolic execution to amplify the effect of dynamic symbolic execution. Veritesting allows {MergePoint} to find twice as many bugs, explore orders of magnitude more paths, and achieve higher code coverage than previous dynamic symbolic execution systems. {MergePoint} is currently running daily on a 100 node cluster analyzing 33,248 Linux binaries; has generated more than 15 billion {SMT} queries, 200 million test cases, 2,347,420 crashes, and found 11,687 bugs in 4,379 distinct applications.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2568225.2568293},
    x-isbn = {978-1-4503-2756-5},
    x-series = {ICSE 2014},
    x-url = {http://dx.doi.org/10.1145/2568225.2568293},
    xpages = {1083--1094},
    year = {2014}
}

@article{dvanhorn:Ciortea2010Cloud9,
    author = {Ciortea, Liviu and Zamfir, Cristian and Bucur, Stefan and Chipounov, Vitaly and Candea, George},
    citeulike-article-id = {12601293},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1713257},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1713254.1713257},
    date-added = {2014-10-03 00:44:00},
    journal = {SIGOPS Oper. Syst. Rev.},
    priority = {2},
    publisher = {ACM},
    title = {Cloud9: A Software Testing Service},
    x-abstract = {Cloud9 aims to reduce the resource-intensive and laborintensive nature of high-quality software testing. First, Cloud9 parallelizes symbolic execution (an effective, but still poorly scalable test automation technique) to large shared-nothing clusters. To our knowledge, Cloud9 is the first symbolic execution engine that scales to large clusters of machines, thus enabling thorough automated testing of real software in conveniently short amounts of time. Preliminary results indicate one to two orders of magnitude speedup over a state-of-the-art symbolic execution engine. Second, Cloud9 is an on-demand software testing service: it runs on compute clouds, like Amazon {EC2}, and scales its use of resources over a wide dynamic range, proportionally with the testing task at hand.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1713254.1713257},
    x-issn = {0163-5980},
    x-month = jan,
    x-number = {4},
    x-url = {http://dx.doi.org/10.1145/1713254.1713257},
    x-volume = {43},
    xpages = {5--10},
    year = {2010}
}

@inproceedings{dvanhorn:Xie2005Saturn,
    author = {Xie, Yichen and Aiken, Alex},
    booktitle = {Proceedings of the 17th International Conference on Computer Aided Verification},
    citeulike-article-id = {13381200},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2153248},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/11513988\_13},
    date-added = {2014-10-03 00:42:52},
    location = {Edinburgh, Scotland, UK},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Saturn: A {SAT}-based Tool for Bug Detection},
    x-abstract = {Saturn is a boolean satisfiability ({SAT}) based framework for static bug detection. Saturn targets software written in C and is designed to support a wide range of property checkers.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/11513988\_13},
    x-isbn = {3-540-27231-3, 978-3-540-27231-1},
    x-series = {CAV'05},
    x-url = {http://dx.doi.org/10.1007/11513988\_13},
    xpages = {139--143},
    year = {2005}
}

@inproceedings{dvanhorn:Gulwani2009SPEED,
    author = {Gulwani, Sumit and Mehra, Krishna K. and Chilimbi, Trishul},
    booktitle = {Proceedings of the 36th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {13381198},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1480898},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1594834.1480898},
    date-added = {2014-10-03 00:35:22},
    priority = {2},
    publisher = {ACM},
    title = {{SPEED}: Precise and Efficient Static Estimation of Program Computational Complexity},
    x-abstract = {This paper describes an inter-procedural technique for computing symbolic bounds on the number of statements a procedure executes in terms of its scalar inputs and user-defined quantitative functions of input data-structures. Such computational complexity bounds for even simple programs are usually disjunctive, non-linear, and involve numerical properties of heaps. We address the challenges of generating these bounds using two novel ideas. We introduce a proof methodology based on multiple counter instrumentation (each counter can be initialized and incremented at potentially multiple program locations) that allows a given linear invariant generation tool to compute linear bounds individually on these counter variables. The bounds on these counters are then composed together to generate total bounds that are non-linear and disjunctive. We also give an algorithm for automating this proof methodology. Our algorithm generates complexity bounds that are usually precise not only in terms of the computational complexity, but also in terms of the constant factors. Next, we introduce the notion of user-defined quantitative functions that can be associated with abstract data-structures, e.g., length of a list, height of a tree, etc. We show how to compute bounds in terms of these quantitative functions using a linear invariant generation tool that has support for handling uninterpreted functions. We show application of this methodology to commonly used data-structures (namely lists, list of lists, trees, bit-vectors) using examples from Microsoft product code. We observe that a few quantitative functions for each data-structure are usually sufficient to allow generation of symbolic complexity bounds of a variety of loops that iterate over these data-structures, and that it is straightforward to define these quantitative functions. The combination of these techniques enables generation of precise computational complexity bounds for real-world examples (drawn from Microsoft product code and C++ {STL} library code) for some of which it is non-trivial to even prove termination. Such automatically generated bounds are very useful for early detection of egregious performance problems in large modular codebases that are constantly being changed by multiple developers who make heavy use of code written by others without a good understanding of their implementation complexity.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1594834.1480898},
    x-issn = {0362-1340},
    x-month = jan,
    x-url = {http://dx.doi.org/10.1145/1594834.1480898},
    xpages = {127--139},
    year = {2009}
}

@incollection{dvanhorn:Sinn2014Simple,
    author = {Sinn, Moritz and Zuleger, Florian and Veith, Helmut},
    booktitle = {Computer Aided Verification},
    citeulike-article-id = {13381196},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-319-08867-9\_50},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-319-08867-9\_50},
    date-added = {2014-10-03 00:33:57},
    priority = {2},
    publisher = {Springer International Publishing},
    title = {A Simple and Scalable Static Analysis for Bound Analysis and Amortized Complexity Analysis},
    x-abstract = {We present the first scalable bound analysis that achieves amortized complexity analysis. In contrast to earlier work, our bound analysis is not based on general purpose reasoners such as abstract interpreters, software model checkers or computer algebra tools. Rather, we derive bounds directly from abstract program models, which we obtain from programs by comparatively simple invariant generation and symbolic execution techniques. As a result, we obtain an analysis that is more predictable and more scalable than earlier approaches. We demonstrate by a thorough experimental evaluation that our analysis is fast and at the same time able to compute bounds for challenging loops in a large real-world benchmark. Technically, our approach is based on lossy vector addition systems ({VASS}). Our bound analysis first computes a lexicographic ranking function that proves the termination of a {VASS}, and then derives a bound from this ranking function. Our methodology achieves amortized analysis based on a new insight how lexicographic ranking functions can be used for bound analysis.},
    x-doi = {10.1007/978-3-319-08867-9\_50},
    x-editor = {Biere, Armin and Bloem, Roderick},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-319-08867-9\_50},
    x-volume = {8559},
    xpages = {745--761},
    year = {2014}
}

@article{dvanhorn:Hoffmann2012Multivariate,
    author = {Hoffmann, Jan and Aehlig, Klaus and Hofmann, Martin},
    citeulike-article-id = {12602611},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2362393},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2362389.2362393},
    date-added = {2014-10-03 00:32:32},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {Multivariate Amortized Resource Analysis},
    x-abstract = {We study the problem of automatically analyzing the worst-case resource usage of procedures with several arguments. Existing automatic analyses based on amortization or sized types bound the resource usage or result size of such a procedure by a sum of unary functions of the sizes of the arguments. In this article we generalize this to arbitrary multivariate polynomial functions thus allowing bounds of the form mn which had to be grossly overestimated by m2 \&plus; n2 before. Our framework even encompasses bounds like ∑i,j≤ n mi mj where the mi are the sizes of the entries of a list of length n. This allows us for the first time to derive useful resource bounds for operations on matrices that are represented as lists of lists and to considerably improve bounds on other superlinear operations on lists such as longest common subsequence and removal of duplicates from lists of lists. Furthermore, resource bounds are now closed under composition which improves accuracy of the analysis of composed programs when some or all of the components exhibit superlinear resource or size behavior. The analysis is based on a novel multivariate amortized resource analysis. We present it in form of a type system for a simple first-order functional language with lists and trees, prove soundness, and describe automatic type inference based on linear programming. We have experimentally validated the automatic analysis on a wide range of examples from functional programming with lists and trees. The obtained bounds were compared with actual resource consumption. All bounds were asymptotically tight, and the constants were close or even identical to the optimal ones.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2362389.2362393},
    x-issn = {0164-0925},
    x-month = nov,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1145/2362389.2362393},
    x-volume = {34},
    year = {2012}
}

@inproceedings{dvanhorn:Magill2010Automatic,
    author = {Magill, Stephen and Tsai, Ming H. and Lee, Peter and Tsay, Yih K.},
    booktitle = {Proceedings of the 37th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {13381195},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1707801.1706326},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1707801.1706326},
    date-added = {2014-10-03 00:31:34},
    priority = {2},
    publisher = {ACM},
    title = {Automatic Numeric Abstractions for Heap-manipulating Programs},
    x-abstract = {We present a logic for relating heap-manipulating programs to numeric abstractions. These numeric abstractions are expressed as simple imperative programs over integer variables and have the property that termination and safety of the numeric program ensures termination and safety of the original, heap-manipulating program. We have implemented an automated version of this abstraction process and present experimental results for programs involving a variety of data structures.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1707801.1706326},
    x-issn = {0362-1340},
    x-month = jan,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1145/1707801.1706326},
    x-volume = {45},
    xpages = {211--222},
    year = {2010}
}

@inproceedings{dvanhorn:Goldsmith2007Measuring,
    author = {Goldsmith, Simon F. and Aiken, Alex S. and Wilkerson, Daniel S.},
    booktitle = {Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering},
    citeulike-article-id = {5287267},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1287681},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1287624.1287681},
    date-added = {2014-10-03 00:30:24},
    location = {Dubrovnik, Croatia},
    priority = {2},
    publisher = {ACM},
    title = {Measuring Empirical Computational Complexity},
    x-abstract = {The standard language for describing the asymptotic behavior of algorithms is theoretical computational complexity. We propose a method for describing the asymptotic behavior of programs in practice by measuring their empirical computational complexity. Our method involves running a program on workloads spanning several orders of magnitude in size, measuring their performance, and fitting these observations to a model that predicts performance as a function of workload size. Comparing these models to the programmer's expectations or to theoretical asymptotic bounds can reveal performance bugs or confirm that a program's performance scales as expected. Grouping and ranking program locations based on these models focuses attention on scalability-critical code. We describe our tool, the Trend Profiler (trend-prof), for constructing models of empirical computational complexity that predict how many times each basic block in a program runs as a linear (y = a + bx) or a powerlaw (y = axb) function of user-specified features of the program's workloads. We ran trend-prof on several large programs and report cases where a program scaled as expected, beat its worst-case theoretical complexity bound, or had a performance bug.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1287624.1287681},
    x-isbn = {978-1-59593-811-4},
    x-series = {ESEC-FSE '07},
    x-url = {http://dx.doi.org/10.1145/1287624.1287681},
    xpages = {395--404},
    year = {2007}
}

@inproceedings{dvanhorn:Crosby2003Denial,
    author = {Crosby, Scott A. and Wallach, Dan S.},
    booktitle = {Proceedings of the 12th Conference on USENIX Security Symposium - Volume 12},
    citeulike-article-id = {4021705},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1251356},
    date-added = {2014-10-02 16:55:34},
    location = {Washington, DC},
    priority = {2},
    publisher = {USENIX Association},
    title = {Denial of Service via Algorithmic Complexity Attacks},
    x-abstract = {We present a new class of low-bandwidth denial of service attacks that exploit algorithmic deficiencies in many common applications' data structures. Frequently used data structures have "average-case" expected running time that's far more efficient than the worst case. For example, both binary trees and hash tables can degenerate to linked lists with carefully chosen input. We show how an attacker can effectively compute such input, and we demonstrate attacks against the hash table implementations in two versions of Perl, the Squid web proxy, and the Bro intrusion detection system. Using bandwidth less than a typical dialup modem, we can bring a dedicated Bro server to its knees; after six minutes of carefully chosen packets, our Bro server was dropping as much as 71\% of its traffic and consuming all of its {CPU}. We show how modern universal hashing techniques can yield performance comparable to commonplace hash functions while being provably secure against these attacks.},
    x-address = {Berkeley, CA, USA},
    x-series = {SSYM'03},
    x-url = {http://portal.acm.org/citation.cfm?id=1251356},
    xpages = {3},
    year = {2003}
}

@incollection{dvanhorn:Heidegger2010ContractDriven,
    author = {Heidegger, Phillip and Thiemann, Peter},
    booktitle = {Objects, Models, Components, Patterns},
    citeulike-article-id = {13372257},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-13953-6\_9},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-13953-6\_9},
    date-added = {2014-09-24 01:18:16},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {{Contract-Driven} Testing of {JavaScript} Code},
    x-abstract = {{JSConTest} is a tool that enhances {JavaScript} with simple, type-like contracts and provides a framework for monitoring and guided random testing of programs against these contracts at the same time. Function contracts in {JSConTest} serve a dual role as specifications of the input/output behavior and as test case generators. Generation of test data for a contract is generally random, but it can be guided by annotations on the contract to achieve higher coverage. Annotations may indicate dependencies among parameters and the result or they may select lightweight program analyses, the results of which influence the choice of test data. A case study substantiates that {JSConTest} finds type-related errors with high probability.},
    x-doi = {10.1007/978-3-642-13953-6\_9},
    x-editor = {Vitek, Jan},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-13953-6\_9},
    x-volume = {6141},
    xpages = {154--172},
    year = {2010}
}

@inproceedings{dvanhorn:export:79160,
    author = {Barnett, Michael and Fahndrich, Manuel and Logozzo, Francesco and de Halleux, Peli and Tillmann, Nikolai},
    booktitle = {Proc. 31st International Conference on Software Engineering (ICSE'2009)},
    citeulike-article-id = {13372256},
    citeulike-linkout-0 = {http://research.microsoft.com/apps/pubs/default.aspx?id=79160},
    date-added = {2014-09-24 01:10:48},
    priority = {2},
    publisher = {IEEE},
    title = {Exploiting the Synergy between {Automated-Test}-Generation and {Programming-by-Contract}},
    x-abstract = {<{p>This} demonstration presents two tools, Code Contracts and Pex, that utilize specification constructs for advanced testing, runtime checking, and static checking of object-oriented .{NET} programs.</p>},
    x-month = may,
    x-note = {Research Demonstration},
    x-url = {http://research.microsoft.com/apps/pubs/default.aspx?id=79160},
    year = {2009}
}

@inproceedings{dvanhorn:Claessen2000QuickCheck,
    author = {Claessen, Koen and Hughes, John},
    booktitle = {Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {2298329},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=351266},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/351240.351266},
    date-added = {2014-09-24 01:06:52},
    priority = {2},
    publisher = {ACM},
    title = {{QuickCheck}: A Lightweight Tool for Random Testing of Haskell Programs},
    x-abstract = {Quick Check is a tool which aids the Haskell programmer in formulating and testing properties of programs. Properties are described as Haskell functions, and can be automatically tested on random input, but it is also possible to define custom test data generators. We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffices to obtain good coverage of the definition under test.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/351240.351266},
    x-isbn = {1-58113-202-6},
    x-series = {ICFP '00},
    x-url = {http://dx.doi.org/10.1145/351240.351266},
    xpages = {268--279},
    year = {2000}
}

@inproceedings{dvanhorn:Klein2010Random,
    author = {Klein, Casey and Flatt, Matthew and Findler, Robert B.},
    booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
    citeulike-article-id = {13372252},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1932682.1869505},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1869459.1869505},
    date-added = {2014-09-24 00:59:53},
    location = {Reno/Tahoe, Nevada, USA},
    priority = {2},
    publisher = {ACM},
    title = {Random Testing for Higher-order, Stateful Programs},
    x-abstract = {Testing is among the most effective tools available for finding bugs. Still, we know of no automatic technique for generating test cases that expose bugs involving a combination of mutable state and callbacks, even though objects and method overriding set up exactly that combination. For such cases, a test generator must create callbacks or subclasses that aggressively exercise side-effecting operations using combinations of generated objects. This paper presents a new algorithm for randomly testing programs that use state and callbacks. Our algorithm exploits a combination of contracts and environment bindings to guide the test-case generator toward interesting inputs. Our prototype implementation for Racket (formerly {PLT} Scheme) - which has a Java-like class system, but with first-class classes as well as gbeta-like augmentable methods - uncovered dozens of bugs in a well-tested and widely used text-editor library. We describe our approach in a precise, formal notation, borrowing the techniques used to describe operational semantics and type systems. The formalism enables us to provide a compact and self-contained explanation of the core of our technique without the ambiguity usually present in pseudo-code descriptions.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1869459.1869505},
    x-isbn = {978-1-4503-0203-6},
    x-series = {OOPSLA '10},
    x-url = {http://dx.doi.org/10.1145/1869459.1869505},
    xpages = {555--566},
    year = {2010}
}

@inproceedings{dvanhorn:Bouajjani1997Reachability,
    author = {Bouajjani, Ahmed and Esparza, Javier and Maler, Oded},
    booktitle = {CONCUR '97: Concurrency Theory},
    citeulike-article-id = {3857624},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-63141-0\_10},
    citeulike-linkout-1 = {http://www.springerlink.com/content/q415g87p87k56781},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/3-540-63141-0\_10},
    date-added = {2014-08-04 03:04:37},
    journal = {CONCUR '97: Concurrency Theory},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Reachability analysis of pushdown automata: Application to model-checking},
    x-abstract = {We apply the symbolic analysis principle to pushdown systems. We represent (possibly infinite) sets of configurations of such systems by means of finite-state automata. In order to reason in a uniform way about analysis problems involving both existential and universal path quantification (such as model-checking for branching-time logics), we consider the more general class of alternating pushdown systems and use alternating finite-state automata as a representation structure for sets of their configurations. We give a simple and natural procedure to compute sets of predecessors using this representation structure. We incorporate this procedure into the automata-theoretic approach to model-checking to define new model-checking algorithms for pushdown systems against both linear and branching-time properties. From these results we derive upper bounds for several model-checking problems as well as matching lower bounds.},
    x-doi = {10.1007/3-540-63141-0\_10},
    x-editor = {Mazurkiewicz, Antoni and Winkowski, J\'{o}zef},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/3-540-63141-0\_10},
    xpages = {135--150},
    year = {1997}
}

@article{dvanhorn:Wegman1991Constant,
    author = {Wegman, Mark N. and Zadeck, F. Kenneth},
    citeulike-article-id = {225307},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=103136},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/103135.103136},
    date-added = {2014-08-04 02:30:33},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {algorithm, optimization, ssa},
    priority = {2},
    publisher = {ACM},
    title = {Constant propagation with conditional branches},
    x-abstract = {Constant propagation is a well-known global flow analysis problem. The goal of constant propagation is to discover values that are constant on all possible executions of a program and to propagate these constant values as far foward through the program as possible. Expressions whose operands are all constants can be evaluated at compile time and the results propagated further. Using the algorithms presented in this paper can produce smaller and faster compiled programs. The same algorithms can be used for other kinds of analyses (e.g., type of determination). We present four algorithms in this paper, all conservitive in the sense that all constants may not be found, but each constant found is constant over all possible executions of the program. These algorithms are among the simplest, fastest, and most powerful global constant propagation algorithms known. We also present a new algorithm that performs a form of interprocedural data flow analysis in which aliasing information is gathered in conjunction with constant progagation. Several variants of this algorithm are considered.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/103135.103136},
    x-issn = {0164-0925},
    x-month = apr,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1145/103135.103136},
    x-volume = {13},
    xpages = {181--210},
    year = {1991}
}

@inproceedings{dvanhorn:CousotEtAl-TASE07,
    author = {Cousot, Patrick and Cousot, Radhia and Feret, J\'{e}r\^{o}me and Mauborgne, Laurent and Min\'{e}, Antoine and Monniaux, David and Rival, Xavier},
    booktitle = {Proc. First IEEE \& IFIP International Symposium on Theoretical Aspects of Software Engineering},
    citeulike-article-id = {13215701},
    date-added = {2014-08-04 02:23:58},
    keywords = {abstract-interpretation},
    priority = {2},
    publisher = {IEEE Computer Society Press, Los Alamitos, California, United States},
    title = {Varieties of Static Analyzers: A Comparison with {A}str\'{e}e, invited paper},
    x-address = {Shanghai, China},
    x-editor = {Jifeng, He and Sanders, J.},
    x-month = jun,
    xpages = {3--17},
    year = {2007}
}

@inproceedings{dvanhorn:Filinski1994Representing,
    author = {Filinski, Andrzej},
    booktitle = {Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {4838},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=174675.178047},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/174675.178047},
    date-added = {2014-08-04 02:10:41},
    location = {Portland, Oregon, USA},
    priority = {2},
    publisher = {ACM},
    title = {Representing Monads},
    x-abstract = {We show that any monad whose unit and extension operations are expressible as purely functional terms can be embedded in a call-by-value language with  ” composable continuations”. As part of the development, we extend Meyer and Wand's characterization of the relationship between continuation-passing and direct style to one for continuation-passing vs. general  ” monadic” style. We further show that the composable-continuations construct can itself be represented using ordinary, non-composable first-class continuations and a single piece of state. Thus, in the presence of two specific computational effects - storage and escapes - any expressible monadic structure (e.g., nondeterminism as represented by the list monad) can be added as a purely definitional extension, without requiring a reinterpretation of the whole language. The paper includes an implementation of the construction (in Standard {ML} with some New Jersey extensions) and several examples.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/174675.178047},
    x-isbn = {0-89791-636-0},
    x-series = {POPL '94},
    x-url = {http://dx.doi.org/10.1145/174675.178047},
    xpages = {446--457},
    year = {1994}
}

@inproceedings{dvanhorn:Hardekopf2014Widening,
    author = {Hardekopf, Ben and Wiedermann, Ben and Churchill, Berkeley and Kashyap, Vineeth},
    booktitle = {Verification, Model Checking, and Abstract Interpretation},
    citeulike-article-id = {13315106},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-54013-4\_26},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-54013-4\_26},
    date-added = {2014-08-04 01:59:04},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Widening for {Control-Flow}},
    x-abstract = {We present a parameterized widening operator that determines the control-flow sensitivity of an analysis, i.e., its flow-sensitivity, context-sensitivity, and path-sensitivity. By instantiating the operator's parameter in different ways, the analysis can be tuned to arbitrary sensitivities without changing the abstract semantics of the analysis itself. Similarly, the analysis can be implemented so that its sensitivity can be tuned without changing the analysis implementation. Thus, the sensitivity is an independent concern, allowing the analysis designer to design and implement the analysis without worrying about its sensitivity and then easily experiment with different sensitivities after the fact. Additionally, we show that the space of control-flow sensitivities induced by this widening operator forms a lattice. The lattice meet and join operators are the product and sum of sensitivities, respectively. They can be used to automatically create new sensitivities from existing ones without manual effort. The sum operation in particular is a novel construction, which creates a new sensitivity less precise than either of its operands but containing elements of both.},
    x-doi = {10.1007/978-3-642-54013-4\_26},
    x-editor = {McMillan, KennethL and Rival, Xavier},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-54013-4\_26},
    xpages = {472--491},
    year = {2014}
}

@inproceedings{dvanhorn:Kiselyov2007Delimited,
    author = {Kiselyov, Oleg and Shan, Chung-chieh},
    booktitle = {Modeling and Using Context},
    citeulike-article-id = {4039650},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-74255-5\_22},
    citeulike-linkout-1 = {http://www.springerlink.com/content/c72411687q51834v},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-540-74255-5\_22},
    date-added = {2014-08-04 00:08:00},
    journal = {Modeling and Using Context},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Delimited Continuations in Operating Systems},
    x-abstract = {Delimited continuations are the meanings of delimited evaluation contexts in programming languages. We show they offer a uniform view of many scenarios that arise in systems programming, such as a request for a system service, an event handler for input/ output, a snapshot of a process, a file system being read and updated, and a Web page. Explicitly recognizing these uses of delimited continuations helps us design a system of concurrent, isolated transactions where desirable features such as snapshots, undo, copy-on-write, reconciliation, and interposition fall out by default. It also lets us take advantage of efficient implementation techniques from programming-language research. The Zipper File System prototypes these ideas.},
    x-doi = {10.1007/978-3-540-74255-5\_22},
    x-editor = {Kokinov, Boicho and Richardson, DanielC and Roth-Berghofer, ThomasR and Vieu, Laure},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-74255-5\_22},
    xpages = {291--302},
    year = {2007}
}

@inproceedings{dvanhorn:Oh2012Design,
    author = {Oh, Hakjoo and Heo, Kihong and Lee, Wonchan and Lee, Woosuk and Yi, Kwangkeun},
    booktitle = {Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13315073},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2254092},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2345156.2254092},
    date-added = {2014-08-03 23:14:21},
    priority = {2},
    publisher = {ACM},
    title = {Design and Implementation of Sparse Global Analyses for C-like Languages},
    x-abstract = {In this article we present a general method for achieving global static analyzers that are precise, sound, yet also scalable. Our method generalizes the sparse analysis techniques on top of the abstract interpretation framework to support relational as well as non-relational semantics properties for C-like languages. We first use the abstract interpretation framework to have a global static analyzer whose scalability is unattended. Upon this underlying sound static analyzer, we add our generalized sparse analysis techniques to improve its scalability while preserving the precision of the underlying analysis. Our framework determines what to prove to guarantee that the resulting sparse version should preserve the precision of the underlying analyzer. We formally present our framework; we present that existing sparse analyses are all restricted instances of our framework; we show more semantically elaborate design examples of sparse non-relational and relational static analyses; we present their implemen- tation results that scale to analyze up to one million lines of C programs. We also show a set of implementation techniques that turn out to be critical to economically support the sparse analysis process.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2345156.2254092},
    x-issn = {0362-1340},
    x-month = jun,
    x-url = {http://dx.doi.org/10.1145/2345156.2254092},
    xpages = {229--238},
    year = {2012}
}

@inproceedings{dvanhorn:Reif1977Symbolic,
    author = {Reif, John H. and Lewis, Harry R.},
    booktitle = {Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {3353403},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=512961},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/512950.512961},
    date-added = {2014-08-03 23:10:25},
    location = {Los Angeles, California},
    priority = {2},
    publisher = {ACM},
    title = {Symbolic Evaluation and the Global Value Graph},
    x-abstract = {This paper is concerned with difficult global flow problems which require the symbolic evaluation of programs. We use, as is common in global flow analysis, a model in which the expressions computed are specified, but the flow of control is indicated only by a directed graph whose nodes are blocks of assignment statements. We show that if such a program model is interpreted in the domain of integer arithmetic then many natural global flow problems are unsolvable. We then develop a direct (non-iterative) method for finding general symbolic values for program expressions. Our method gives results similar to an iterative method due to Kildall and a direct method due to Fong, Kam, and Ullman. By means of a structure called the global value graph which compactly represents both symbolic values and the flow of these values through the program, we are able to obtain results that are as strong as either of these algorithms at a lower time cost, while retaining applicability to all flow graphs.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/512950.512961},
    x-series = {POPL '77},
    x-url = {http://dx.doi.org/10.1145/512950.512961},
    xpages = {104--118},
    year = {1977}
}

@inproceedings{dvanhorn:Salvati2011Krivine,
    author = {Salvati, S. and Walukiewicz, I.},
    booktitle = {Proceedings of the 38th International Conference on Automata, Languages and Programming},
    citeulike-article-id = {13315068},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2027239},
    date-added = {2014-08-03 22:59:57},
    location = {Zurich, Switzerland},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Krivine Machines and Higher-order Schemes},
    x-abstract = {We propose a new approach to analysing higher-order recursive schemes. Many results in the literature use automata models generalising pushdown automata, most notably higher-order pushdown automata with collapse ({CPDA}). Instead, we propose to use the Krivine machine model. Compared to {CPDA}, this model is closer to lambda-calculus, and incorporates nicely many invariants of computations, as for example the typing information. The usefulness of the proposed approach is demonstrated with new proofs of two central results in the field: the decidability of the local and global model checking problems for higher-order schemes with respect to the mu-calculus.},
    x-address = {Berlin, Heidelberg},
    x-isbn = {978-3-642-22011-1},
    x-series = {ICALP'11},
    x-url = {http://portal.acm.org/citation.cfm?id=2027239},
    xpages = {162--173},
    year = {2011}
}

@incollection{dvanhorn:Schwoon2005Note,
    author = {Schwoon, Stefan and Esparza, Javier},
    booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
    citeulike-article-id = {13315065},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-31980-1\_12},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-540-31980-1\_12},
    date-added = {2014-08-03 22:52:17},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {A Note on {On-the-Fly} Verification Algorithms},
    x-abstract = {The automata-theoretic approach to {LTL} verification relies on an algorithm for finding accepting cycles in a B\"{u}chi automaton. Explicit-state model checkers typically construct the automaton  ” on the fly” and explore its states using depth-first search. We survey algorithms proposed for this purpose and identify two good algorithms, a new algorithm based on nested {DFS}, and another based on strongly connected components. We compare these algorithms both theoretically and experimentally and determine cases where both algorithms can be useful.},
    x-doi = {10.1007/978-3-540-31980-1\_12},
    x-editor = {Halbwachs, Nicolas and Zuck, LenoreD},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-31980-1\_12},
    xpages = {174--190},
    year = {2005}
}

@inproceedings{dvanhorn:Shivers2011Modular,
    author = {Shivers, Olin and Turon, Aaron J.},
    booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {13315061},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2034773.2034783},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2034773.2034783},
    date-added = {2014-08-03 22:42:22},
    location = {Tokyo, Japan},
    priority = {2},
    publisher = {ACM},
    title = {Modular Rollback Through Control Logging: A Pair of Twin Functional Pearls},
    x-abstract = {We present a technique, based on the use of first-class control operators, enabling programs to maintain and invoke rollback logs for sequences of reversible effects. Our technique is modular, in that it provides complete separation between some library of effectful operations, and a client, "driver" program which invokes and rolls back sequences of these operations. In particular, the checkpoint mechanism, which is entirely encapsulated within the effect library, logs not only the library's effects, but also the client's control state. Thus, logging and rollback can be almost completely transparent to the client code. This separation of concerns manifests itself nicely when we must implement software with sophisticated error handling. We illustrate with two examples that exploit the architecture to disentangle some core parsing task from its error management. The parser code is completely separate from the error-correction code, although the two components are deeply intertwined at run time.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2034773.2034783},
    x-isbn = {978-1-4503-0865-6},
    x-series = {ICFP '11},
    x-url = {http://dx.doi.org/10.1145/2034773.2034783},
    xpages = {58--68},
    year = {2011}
}

@inproceedings{dvanhorn:Ong2011Verifying,
    author = {Ong, C. H. Luke and Ramsay, Steven J.},
    booktitle = {Proceedings of the 38th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {13231111},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1926453},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1925844.1926453},
    date-added = {2014-06-17 15:43:43},
    priority = {2},
    publisher = {ACM},
    title = {Verifying Higher-order Functional Programs with Pattern-matching Algebraic Data Types},
    x-abstract = {Type-based model checking algorithms for higher-order recursion schemes have recently emerged as a promising approach to the verification of functional programs. We introduce pattern-matching recursion schemes ({PMRS}) as an accurate model of computation for functional programs that manipulate algebraic data-types. {PMRS} are a natural extension of higher-order recursion schemes that incorporate pattern-matching in the defining rules. This paper is concerned with the following (undecidable) verification problem: given a correctness property φ, a functional program ℘ (qua {PMRS}) and a regular input set ℑ, does every term that is reachable from ℑ under rewriting by ℘ satisfy φ? To solve the {PMRS} verification problem, we present a sound semi-algorithm which is based on model-checking and counterexample guided abstraction refinement. Given a no-instance of the verification problem, the method is guaranteed to terminate. From an order-n {PMRS} and an input set generated by a regular tree grammar, our method constructs an order-n weak {PMRS} which over-approximates only the first-order pattern-matching behaviour, whilst remaining completely faithful to the higher-order control flow. Using a variation of Kobayashi's type-based approach, we show that the (trivial automaton) model-checking problem for weak {PMRS} is decidable. When a violation of the property is detected in the abstraction which does not correspond to a violation in the model, the abstraction is automatically refined by `unfolding' the pattern-matching rules in the program to give successively more and more accurate weak {PMRS} models.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1925844.1926453},
    x-issn = {0362-1340},
    x-month = jan,
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/1925844.1926453},
    xpages = {587--598},
    year = {2011}
}

@inproceedings{dvanhorn:Ngo2007Detecting,
    author = {Ngo, Minh N. and Hee Beng Kuan Tan},
    booktitle = {Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering},
    citeulike-article-id = {13231088},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1287655},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1287624.1287655},
    date-added = {2014-06-17 14:45:34},
    location = {Dubrovnik, Croatia},
    priority = {2},
    publisher = {ACM},
    title = {Detecting Large Number of Infeasible Paths Through Recognizing Their Patterns},
    x-abstract = {A great majority of program paths are found to be infeasible, which in turn make static analysis overly conservative. As static analysis plays a central part in many software engineering activities, knowledge about infeasible program paths can be used to greatly improve the performance of these activities especially structural testing and coverage analysis. In this paper, we present an empirical approach to the problem of infeasible path detection. We have discovered that many infeasible paths exhibit some common properties which are caused by four code patterns including identical/complement-decision, mutually-exclusive-decision, check-then-do and looping-by-flag pattern. Through realizing these properties from source code, many infeasible paths can be precisely detected. Binomial tests have been conducted which give strong statistical evidences to support the validity of the empirical properties. Our experimental results show that even with some limitations in the current prototype tool, the proposed approach accurately detects 82.3\% of all the infeasible paths.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1287624.1287655},
    x-isbn = {978-1-59593-811-4},
    x-series = {ESEC-FSE '07},
    x-url = {http://dx.doi.org/10.1145/1287624.1287655},
    xpages = {215--224},
    year = {2007}
}

@article{dvanhorn:King1975New,
    author = {King, James C.},
    citeulike-article-id = {13231087},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=800027.808444},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/390016.808444},
    date-added = {2014-06-17 14:39:05},
    journal = {SIGPLAN Not.},
    priority = {2},
    publisher = {ACM},
    title = {A New Approach to Program Testing},
    x-abstract = {The current approach for testing a program is, in principle, quite primitive. Some small sample of the data that a program is expected to handle is presented to the program. If the program produces correct results for the sample, it is assumed to be correct. Much current work focuses on the question of how to choose this sample. We propose that a program can be more effectively tested by executing it "symbolically." Instead of supplying specific constants as input values to a program being tested, one supplies symbols. The normal computational definitions for the basic operations performed by a program can be expanded to accept symbolic inputs and produce symbolic formulae as output. If the flow of control in the program is completely independent of its input parameters, then all output values can be symbolically computed as formulae over the symbolic inputs and examined for correctness. When the control flow of the program is input dependent, a case analysis can be performed producing output formulae for each class of inputs determined by the control flow dependencies. Using these ideas, we have designed and implemented an interactive debugging/testing system called {EFFIGY}.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/390016.808444},
    x-issn = {0362-1340},
    x-month = apr,
    x-number = {6},
    x-url = {http://dx.doi.org/10.1145/390016.808444},
    x-volume = {10},
    xpages = {228--233},
    year = {1975}
}

@inproceedings{dvanhorn:Chen2003Mirror,
    author = {Chen, T. Y. and Kuo, F. C. and Merkel, R. G. and Ng, S. P.},
    booktitle = {Proceedings of the Third International Conference on Quality Software},
    citeulike-article-id = {13231084},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=951282},
    date-added = {2014-06-17 14:36:01},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Mirror Adaptive Random Testing},
    x-abstract = {Adaptive random testing ({ART}) has recently beenintroduced to improve the fault-detection effectivenessof random testing ({RT}) for certain types of failure-causingpatterns. However, {ART} requires extracomputations to ensure an even spread of test cases,which may render {ART} to be less cost-effective than {RT}.In this paper, we introduce an innovative approach,namely Mirror Adaptive Random Testing ({MART}), toreduce these computations. Our simulation resultsclearly show that {MART} does improve the cost-effectivenessof {ART}.},
    x-address = {Washington, DC, USA},
    x-isbn = {0-7695-2015-4},
    x-series = {QSIC '03},
    x-url = {http://portal.acm.org/citation.cfm?id=951282},
    year = {2003}
}

@article{dvanhorn:Chen2010Adaptive,
    author = {Chen, Tsong Y. and Kuo, Fei-Ching and Merkel, Robert G. and Tse, T. H.},
    citeulike-article-id = {13231083},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jss.2009.02.022},
    date-added = {2014-06-17 14:35:01},
    journal = {Journal of Systems and Software},
    priority = {2},
    title = {Adaptive Random Testing: The {ART} of test case diversity},
    x-abstract = {Random testing is not only a useful testing technique in itself, but also plays a core role in many other testing methods. Hence, any significant improvement to random testing has an impact throughout the software testing community. Recently, Adaptive Random Testing ({ART}) was proposed as an effective alternative to random testing. This paper presents a synthesis of the most important research results related to {ART}. In the course of our research and through further reflection, we have realised how the techniques and concepts of {ART} can be applied in a much broader context, which we present here. We believe such ideas can be applied in a variety of areas of software testing, and even beyond software testing. Amongst these ideas, we particularly note the fundamental role of diversity in test case selection strategies. We hope this paper serves to provoke further discussions and investigations of these ideas.},
    x-doi = {10.1016/j.jss.2009.02.022},
    x-issn = {01641212},
    x-month = jan,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1016/j.jss.2009.02.022},
    x-volume = {83},
    xpages = {60--66},
    year = {2010}
}

@article{dvanhorn:Cohen2008Constructing,
    author = {Cohen, Myra B. and Dwyer, Matthew B. and Shi, Jiangfan},
    booktitle = {Software Engineering, IEEE Transactions on},
    citeulike-article-id = {5043174},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/TSE.2008.50},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tse.2008.50},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4564473},
    date-added = {2014-06-17 14:33:09},
    day = {27},
    journal = {IEEE Transactions on Software Engineering},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Constructing Interaction Test Suites for {Highly-Configurable} Systems in the Presence of Constraints: A Greedy Approach},
    x-abstract = {Researchers have explored the application of combinatorial interaction testing ({CIT}) methods to construct samples to drive systematic testing of software system configurations. Applying {CIT} to highly-configurable software systems is complicated by the fact that, in many such systems, there are constraints between specific configuration parameters that render certain combinations invalid. Many {CIT} algorithms lack a mechanism to avoid these. In recent work, automated constraint solving methods have been combined with search-based {CIT} construction methods to address the constraint problem with promising results. However, these techniques can incur a non-trivial overhead. In this paper, we build upon our previous work to develop a family of greedy {CIT} sample generation algorithms that exploit calculations made by modern boolean satisfiability ({SAT}) solvers to prune the search space of the {CIT} problem. We perform a comparative evaluation of the cost-effectiveness of these algorithms on four real-world highly-configurable software systems and on a population of synthetic examples that share the characteristics of those systems. In combination our techniques reduce the cost of {CIT} in the presence of constraints to 30\% of the cost of widely-used unconstrained {CIT} methods without sacrificing the quality of the solutions.},
    x-doi = {10.1109/tse.2008.50},
    x-month = jun,
    x-number = {5},
    x-url = {http://dx.doi.org/10.1109/tse.2008.50},
    x-volume = {34},
    xpages = {633--650},
    year = {2008}
}

@incollection{dvanhorn:Brinksma2001Testing,
    author = {Brinksma, Ed and Tretmans, Jan},
    booktitle = {Modeling and Verification of Parallel Processes},
    citeulike-article-id = {2505475},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-45510-8\_9},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/3-540-45510-8\_9},
    date-added = {2014-06-17 14:30:28},
    journal = {Modeling and Verification of Parallel Processes},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Testing Transition Systems: An Annotated Bibliography},
    x-abstract = {Labelled transition system based test theory has made remarkable progress over the past 15 years. From a theoretically interesting approach to the semantics of reactive systems it has developed into a field where testing theory is (slowly) narrowing the gap with testing practice. In particular, new test generation algorithms are being designed that can be used in realistic situations whilst maintaining a sound theoretical basis. In this paper we present an annotated bibliography of labelled transition system based test theory and its applications covering the main developments.},
    x-doi = {10.1007/3-540-45510-8\_9},
    x-editor = {Cassez, Franck and Jard, Claude and Rozoy, Brigitte and Ryan, MarkDermot},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/3-540-45510-8\_9},
    x-volume = {2067},
    xpages = {187--195},
    year = {2001}
}

@article{dvanhorn:Lee1996Principles,
    author = {Lee, D. and Yannakakis, M.},
    booktitle = {Proceedings of the IEEE},
    citeulike-article-id = {3404075},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/5.533956},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=533956},
    date-added = {2014-06-17 14:28:35},
    journal = {Proceedings of the IEEE},
    keywords = {finite-state-machine, lecture-vts, reactive-language, testing},
    priority = {2},
    title = {Principles and methods of testing finite state machines-a survey},
    x-abstract = {With advanced computer technology, systems are getting larger to fulfill more complicated tasks: however, they are also becoming less reliable. Consequently, testing is an indispensable part of system design and implementation; yet it has proved to be a formidable task for complex systems. This motivates the study of testing finite stare machines to ensure the correct functioning of systems and to discover aspects of their behavior. A finite state machine contains a finite number of states and produces outputs on state transitions after receiving inputs. Finite state machines are widely used to model systems in diverse areas, including sequential circuits, certain types of programs, and, more recently, communication protocols. In a testing problem we have a machine about which we lack some information; we would like to deduce this information by providing a sequence of inputs to the machine and observing the outputs produced. Because of its practical importance and theoretical interest, the problem of testing finite state machines has been studied in different areas and at various times. The earliest published literature on this topic dates back to the 1950's. Activities in the 1960's mid early 1970's were motivated mainly by automata theory and sequential circuit testing. The area seemed to have mostly died down until a few years ago when the testing problem was resurrected and is now being studied anew due to its applications to conformance testing of communication protocols. While some old problems which had been open for decades were resolved recently, new concepts and more intriguing problems from new applications emerge. We review the fundamental problems in testing finite state machines and techniques for solving these problems, tracing progress in the area from its inception to the present and the stare of the art. In addition, we discuss extensions of finite state machines and some other topics related to testing},
    x-doi = {10.1109/5.533956},
    x-issn = {00189219},
    x-month = aug,
    x-number = {8},
    x-url = {http://dx.doi.org/10.1109/5.533956},
    x-volume = {84},
    xpages = {1090--1123},
    year = {1996}
}

@incollection{dvanhorn:Xie2005Symstra,
    author = {Xie, Tao and Marinov, Darko and Schulte, Wolfram and Notkin, David},
    booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
    chapter = {24},
    citeulike-article-id = {1869884},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-31980-1\_24},
    citeulike-linkout-1 = {http://www.springerlink.com/content/4d3vv767nvtmh9hk},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-540-31980-1\_24},
    date-added = {2014-06-17 14:27:22},
    journal = {Tools and Algorithms for the Construction and Analysis of Systems},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Symstra: A Framework for Generating {Object-Oriented} Unit Tests Using Symbolic Execution},
    x-abstract = {Object-oriented unit tests consist of sequences of method invocations. Behavior of an invocation depends on the method's arguments and the state of the receiver at the beginning of the invocation. Correspondingly, generating unit tests involves two tasks: generating method sequences that build relevant receiver-object states and generating relevant method arguments. This paper proposes Symstra, a framework that achieves both test generation tasks using symbolic execution of method sequences with symbolic arguments. The paper defines symbolic states of object-oriented programs and novel comparisons of states. Given a set of methods from the class under test and a bound on the length of sequences, Symstra systematically explores the object-state space of the class and prunes this exploration based on the state comparisons. Experimental results show that Symstra generates unit tests that achieve higher branch coverage faster than the existing test-generation techniques based on concrete method arguments.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-31980-1\_24},
    x-editor = {Halbwachs, Nicolas and Zuck, LenoreD},
    x-isbn = {978-3-540-25333-4},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-31980-1\_24},
    x-volume = {3440},
    xpages = {365--381},
    year = {2005}
}

@article{dvanhorn:Anand2013Orchestrated,
    author = {Anand, Saswat and Burke, Edmund K. and Chen, Tsong Y. and Clark, John and Cohen, Myra B. and Grieskamp, Wolfgang and Harman, Mark and Harrold, Mary J. and McMinn, Phil},
    citeulike-article-id = {13231079},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jss.2013.02.061},
    date-added = {2014-06-17 14:23:29},
    journal = {Journal of Systems and Software},
    priority = {2},
    title = {An orchestrated survey of methodologies for automated software test case generation},
    x-abstract = { We present an orchestrated survey of the most prominent techniques for automatic generation of software test cases. The survey covers symbolic execution, model-based, combinatorial, search-based and adaptive random testing techniques. For each technique, basic concepts and research challenges are reported, and future research directions are envisioned. Each technique is surveyed by a world renowned expert(s) and active researcher(s) on the topic in a self-contained section. The experts' contributions were coordinated and the paper was edited by the orchestrators/editors into a consistent paper. Test case generation is among the most labour-intensive tasks in software testing. It also has a strong impact on the effectiveness and efficiency of software testing. For these reasons, it has been one of the most active research topics in software testing for several decades, resulting in many different approaches and tools. This paper presents an orchestrated survey of the most prominent techniques for automatic generation of software test cases, reviewed in self-standing sections. The techniques presented include: (a) structural testing using symbolic execution, (b) model-based testing, (c) combinatorial testing, (d) random testing and its variant of adaptive random testing, and (e) search-based testing. Each section is contributed by world-renowned active researchers on the technique, and briefly covers the basic ideas underlying the method, the current state of the art, a discussion of the open research problems, and a perspective of the future development of the approach. As a whole, the paper aims at giving an introductory, up-to-date and (relatively) short overview of research in automatic test case generation, while ensuring a comprehensive and authoritative treatment.},
    x-doi = {10.1016/j.jss.2013.02.061},
    x-issn = {01641212},
    x-month = aug,
    x-number = {8},
    x-url = {http://dx.doi.org/10.1016/j.jss.2013.02.061},
    x-volume = {86},
    xpages = {1978--2001},
    year = {2013}
}

@incollection{dvanhorn:Rushby2008Automated,
    author = {Rushby, John},
    booktitle = {Verified Software: Theories, Tools, Experiments},
    citeulike-article-id = {13231073},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-69149-5\_18},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-540-69149-5\_18},
    date-added = {2014-06-17 14:17:34},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Automated Test Generation and Verified Software},
    x-abstract = {Testing remains the principal means of verification in commercial practice and in many certification regimes. Formal methods of verification will coexist with testing and should be developed in ways that improve, supplement, and exploit the value of testing. I describe automated test generation, which uses technology from formal methods to mechanize the construction of test cases, and discuss some of the research challenges in this area.},
    x-doi = {10.1007/978-3-540-69149-5\_18},
    x-editor = {Meyer, Bertrand and Woodcock, Jim},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-69149-5\_18},
    x-volume = {4171},
    xpages = {161--172},
    year = {2008}
}

@article{dvanhorn:Johnson2014Pushdown,
    author = {Johnson, J. Ian and Sergey, Ilya and Earl, Christopher and Might, Matthew and Van Horn, David},
    citeulike-article-id = {13214892},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=9262409},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796814000100},
    date-added = {2014-06-06 22:21:24},
    journal = {Journal of Functional Programming},
    priority = {2},
    title = {Pushdown flow analysis with abstract garbage collection},
    x-abstract = {In the static analysis of functional programs, pushdown flow analysis and abstract garbage collection push the boundaries of what we can learn about programs statically. This work illuminates and poses solutions to theoretical and practical challenges that stand in the way of combining the power of these techniques. Pushdown flow analysis grants unbounded yet computable polyvariance to the analysis of return-flow in higher-order programs. garbage collection grants unbounded polyvariance to abstract addresses which become unreachable between invocations of the abstract contexts in which they were created. Pushdown analysis solves the problem of precisely analyzing recursion in higher-order languages; abstract garbage collection is essential in solving the  ” stickiness” problem. Alone, our benchmarks demonstrate that each method can reduce analysis times and boost precision by orders of magnitude. We combine these methods. The challenge in marrying these techniques is not subtle: computing the reachable control states of a pushdown system relies on limiting access during transition to the top of the stack; abstract garbage collection, on the other hand, needs full access to the entire stack to compute a root set, just as concrete collection does. Conditional pushdown systems were developed for just such a conundrum, but existing methods are ill-suited for the dynamic nature of garbage collection. We show fully precise and approximate solutions to the feasible paths problem for pushdown garbage-collecting control-flow analysis. Experiments reveal synergistic interplay between garbage collection and pushdown techniques, and the fusion demonstrates  ” better-than-both-worlds” precision.},
    x-doi = {10.1017/s0956796814000100},
    x-issn = {1469-7653},
    x-month = may,
    x-url = {http://dx.doi.org/10.1017/s0956796814000100},
    x-volume = {24},
    xpages = {218--283},
    year = {2014}
}

@inproceedings{dvanhorn:Reps1995Precise,
    author = {Reps, Thomas and Horwitz, Susan and Sagiv, Mooly},
    booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {778826},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=199462},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/199448.199462},
    date-added = {2014-06-06 22:13:27},
    location = {San Francisco, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {Precise Interprocedural Dataflow Analysis via Graph Reachability},
    x-abstract = {The paper shows how a large class of interprocedural dataflow-analysis problems can be solved precisely in polynomial time by transforming them into a special kind of graph-reachability problem. The only restrictions are that the set of dataflow facts must be a finite set, and that the dataflow functions must distribute over the confluence operator (either union or intersection). This class of probable problems includes—but is not limited to—the classical separable problems (also known as  ” gen/kill” or  ” bit-vector” problems)—e.g., reaching definitions, available expressions, and live variables. In addition, the class of problems that our techniques handle includes many non-separable problems, including truly-live variables, copy constant propagation, and possibly-uninitialized {variables.Results} are reported from a preliminary experimental study of C programs (for the problem of finding possibly-uninitialized variables).},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/199448.199462},
    x-isbn = {0-89791-692-1},
    x-series = {POPL '95},
    x-url = {http://dx.doi.org/10.1145/199448.199462},
    xpages = {49--61},
    year = {1995}
}

@inproceedings{dvanhorn:Ernst2006Daikon,
    author = {Ernst, Michael D. and Perkins, Jeff H. and Guo, Philip J. and Mccamant, Stephen and Pacheco, Carlos and Tschantz, Matthew S. and Xiao, Chen},
    booktitle = {Science of Computer Programming},
    citeulike-article-id = {13138627},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.1548},
    date-added = {2014-04-15 14:04:51},
    priority = {2},
    title = {The Daikon system for dynamic detection of likely invariants},
    x-abstract = {Daikon is an implementation of dynamic detection of likely invariants; that is, the Daikon invariant detector reports likely program invariants. An invariant is a property that holds at a certain point or points in a program; these are often used in assert statements, documentation, and formal specifications. Examples include being constant (x = a), non-zero (x \"{i}¿½ = 0), being in a range (a \^{a}¤ x \^{a}¤ b), linear relationships (y = ax + b), ordering (x \^{a}¤ y), functions from a library (x = fn(y)), containment (x \^{a} y), sortedness (x is sorted), and many more. Users can extend Daikon to check for additional invariants. Dynamic invariant detection runs a program, observes the values that the program computes, and then reports properties that were true over the observed executions. Dynamic invariant detection is a machine learning technique that can be applied to arbitrary data. Daikon can detect invariants in C, C++, Java, and Perl programs, and in record-structured data sources; it is easy to extend Daikon to other applications. Invariants can be useful in program understanding and a host of other applications. Daikon\^{a}s output has been used for generating test cases, predicting incompatibilities in component integration, automating theorem-proving, repairing inconsistent data structures, and checking the validity of data streams, among other tasks. Daikon is freely available in source and binary form, along with extensive documentation,},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.1548},
    year = {2006}
}

@inproceedings{dvanhorn:Johnson2013Optimizing,
    author = {Johnson, J. Ian and Labich, Nicholas and Might, Matthew and Van Horn, David},
    booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {13138099},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2500604},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2500365.2500604},
    date-added = {2014-04-14 20:55:17},
    location = {Boston, Massachusetts, USA},
    priority = {2},
    publisher = {ACM},
    title = {Optimizing Abstract Abstract Machines},
    x-abstract = {The technique of abstracting abstract machines ({AAM}) provides a systematic approach for deriving computable approximations of evaluators that are easily proved sound. This article contributes a complementary step-by-step process for subsequently going from a naive analyzer derived under the {AAM} approach, to an efficient and correct implementation. The end result of the process is a two to three order-of-magnitude improvement over the systematically derived analyzer, making it competitive with hand-optimized implementations that compute fundamentally less precise results.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2500365.2500604},
    x-isbn = {978-1-4503-2326-0},
    x-series = {ICFP '13},
    x-url = {http://dx.doi.org/10.1145/2500365.2500604},
    xpages = {443--454},
    year = {2013}
}

@inproceedings{dvanhorn:Necula1997Proofcarrying,
    author = {Necula, George C.},
    booktitle = {Proceedings of the 24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {1102230},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=263712},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/263699.263712},
    date-added = {2014-03-23 18:56:22},
    location = {Paris, France},
    priority = {2},
    publisher = {ACM},
    title = {Proof-carrying Code},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/263699.263712},
    x-isbn = {0-89791-853-3},
    x-series = {POPL '97},
    x-url = {http://dx.doi.org/10.1145/263699.263712},
    xpages = {106--119},
    year = {1997}
}

@article{dvanhorn:Shao2010Certified,
    author = {Shao, Zhong},
    citeulike-article-id = {13114912},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1859226},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1859204.1859226},
    date-added = {2014-03-23 18:50:50},
    journal = {Commun. ACM},
    priority = {2},
    publisher = {ACM},
    title = {Certified Software},
    x-abstract = {Only if the programmer can prove (through formal machine-checkable proofs) it is free of bugs with respect to a claim of dependability.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1859204.1859226},
    x-issn = {0001-0782},
    x-month = dec,
    x-number = {12},
    x-url = {http://dx.doi.org/10.1145/1859204.1859226},
    x-volume = {53},
    xpages = {56--66},
    year = {2010}
}

@article{dvanhorn:Klein2010SeL4,
    author = {Klein, Gerwin and Andronick, June and Elphinstone, Kevin and Heiser, Gernot and Cock, David and Derrin, Philip and Elkaduwe, Dhammika and Engelhardt, Kai and Kolanski, Rafal and Norrish, Michael and Sewell, Thomas and Tuch, Harvey and Winwood, Simon},
    citeulike-article-id = {9621433},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1743574},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1743546.1743574},
    date-added = {2014-03-23 18:29:04},
    journal = {Commun. ACM},
    priority = {2},
    publisher = {ACM},
    title = {{seL4}: Formal Verification of an Operating-system Kernel},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1743546.1743574},
    x-issn = {0001-0782},
    x-month = jun,
    x-number = {6},
    x-url = {http://dx.doi.org/10.1145/1743546.1743574},
    x-volume = {53},
    xpages = {107--115},
    year = {2010}
}

@article{dvanhorn:Leroy2009Formal,
    author = {Leroy, Xavier},
    citeulike-article-id = {5918113},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1538788.1538814},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1538788.1538814},
    date-added = {2014-03-23 18:27:44},
    journal = {Commun. ACM},
    priority = {2},
    publisher = {ACM},
    title = {Formal Verification of a Realistic Compiler},
    x-abstract = {This paper reports on the development and formal verification (proof of semantic preservation) of {CompCert}, a compiler from Clight (a large subset of the C programming language) to {PowerPC} assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a verified compiler is useful in the context of critical software and its formal verification: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1538788.1538814},
    x-issn = {0001-0782},
    x-month = jul,
    x-number = {7},
    x-url = {http://dx.doi.org/10.1145/1538788.1538814},
    x-volume = {52},
    xpages = {107--115},
    year = {2009}
}

@article{dvanhorn:Dsilva2008Survey,
    author = {D'silva, V. and Kroening, D. and Weissenbacher, G.},
    citeulike-article-id = {6053706},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2302032},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tcad.2008.923410},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4544862},
    date-added = {2014-03-23 18:24:24},
    day = {17},
    institution = {Comput. Lab., Univ. of Oxford, Oxford},
    journal = {Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on},
    priority = {2},
    publisher = {IEEE},
    title = {A Survey of Automated Techniques for Formal Software Verification},
    x-abstract = {The quality and the correctness of software are often the greatest concern in electronic systems. Formal verification tools can provide a guarantee that a design is free of specific flaws. This paper surveys algorithms that perform automatic static analysis of software to detect programming errors or prove their absence. The three techniques considered are static analysis with abstract domains, model checking, and bounded model checking. A short tutorial on these techniques is provided, highlighting their differences when applied to practical problems. This paper also surveys tools implementing these techniques and describes their merits and shortcomings.},
    x-address = {Piscataway, NJ, USA},
    x-doi = {10.1109/tcad.2008.923410},
    x-issn = {0278-0070},
    x-month = jul,
    x-number = {7},
    x-url = {http://dx.doi.org/10.1109/tcad.2008.923410},
    x-volume = {27},
    xpages = {1165--1178},
    year = {2008}
}

@article{dvanhorn:Knowles2010Hybrid,
    author = {Knowles, Kenneth and Flanagan, Cormac},
    citeulike-article-id = {6658568},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1667048.1667051},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1667048.1667051},
    date-added = {2014-02-28 02:07:19},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {Hybrid Type Checking},
    x-abstract = {Traditional static type systems are effective for verifying basic interface specifications. Dynamically checked contracts support more precise specifications, but these are not checked until runtime, resulting in incomplete detection of defects. Hybrid type checking is a synthesis of these two approaches that enforces precise interface specifications, via static analysis where possible, but also via dynamic checks where necessary. This article explores the key ideas and implications of hybrid type checking, in the context of the λ-calculus extended with contract types, that is, with dependent function types and with arbitrary refinements of base types.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1667048.1667051},
    x-issn = {0164-0925},
    x-month = feb,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1145/1667048.1667051},
    x-volume = {32},
    xpages = {1--34},
    year = {2010}
}

@inproceedings{dvanhorn:Terauchi2010Dependent,
    author = {Terauchi, Tachio},
    booktitle = {Proceedings of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {13074547},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1706299.1706315},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1706299.1706315},
    date-added = {2014-02-28 01:01:00},
    location = {Madrid, Spain},
    priority = {2},
    publisher = {ACM},
    title = {Dependent Types from Counterexamples},
    x-abstract = {Motivated by recent research in abstract model checking, we present a new approach to inferring dependent types. Unlike many of the existing approaches, our approach does not rely on programmers to supply the candidate (or the correct) types for the recursive functions and instead does counterexample-guided refinement to automatically generate the set of candidate dependent types. The main idea is to extend the classical fixed-point type inference routine to return a counterexample if the program is found untypable with the current set of candidate types. Then, an interpolating theorem prover is used to validate the counterexample as a real type error or generate additional candidate dependent types to refute the spurious counterexample. The process is repeated until either a real type error is found or sufficient candidates are generated to prove the program typable. Our system makes non-trivial use of "linear" intersection types in the refinement phase. The paper presents the type inference system and reports on the experience with a prototype implementation that infers dependent types for a subset of the Ocaml language. The implementation infers dependent types containing predicates from the quantifier-free theory of linear arithmetic and equality with uninterpreted function symbols.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1706299.1706315},
    x-isbn = {978-1-60558-479-9},
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/1706299.1706315},
    xpages = {119--130},
    year = {2010}
}

@inproceedings{dvanhorn:Larson2003High,
    author = {Larson, Eric and Austin, Todd},
    booktitle = {Proceedings of the 12th Conference on USENIX Security Symposium - Volume 12},
    citeulike-article-id = {6665223},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1251362},
    date-added = {2014-02-26 14:28:56},
    location = {Washington, DC},
    priority = {2},
    publisher = {USENIX Association},
    title = {High Coverage Detection of Input-related Security Faults},
    x-abstract = {Improperly bounded program inputs present a major class of program defects. In secure applications, these bugs can be exploited by malicious users, allowing them to overwrite buffers and execute harmful code. In this paper, we present a high coverage dynamic technique for detecting software faults caused by improperly bounded program inputs. Our approach is novel in that it retains the advantages of dynamic bug detection, scope and precision; while at the same time, relaxing the requirement that the user specify the input that exposes the bug. To implement our approach, inputs are shadowed by additional state that characterize the allowed bounds of input-derived variables. Program operations and decision points may alter the shadowed state associated with input variables. Potentially hazardous program sites, such as an array references and string functions, are checked against the entire range of values that the user might specify. The approach found several bugs including two high-risk security bugs in a recent version of {OpenSSH}.},
    x-address = {Berkeley, CA, USA},
    x-series = {USENIX Security},
    x-url = {http://portal.acm.org/citation.cfm?id=1251362},
    xpages = {9},
    year = {2003}
}

@inproceedings{dvanhorn:Henglein1995Safe,
    author = {Henglein, Fritz and Rehof, Jakob},
    booktitle = {Proceedings of the Seventh International Conference on Functional Programming Languages and Computer Architecture},
    citeulike-article-id = {13053681},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=224203},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/224164.224203},
    date-added = {2014-02-19 15:45:53},
    location = {La Jolla, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {Safe Polymorphic Type Inference for a Dynamically Typed Language: Translating Scheme to {ML}},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/224164.224203},
    x-isbn = {0-89791-719-7},
    x-series = {FPCA '95},
    x-url = {http://dx.doi.org/10.1145/224164.224203},
    xpages = {192--203},
    year = {1995}
}

@article{dvanhorn:King1976Symbolic,
    author = {King, James C.},
    citeulike-article-id = {80858},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=360252},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/360248.360252},
    date-added = {2014-02-16 22:52:26},
    journal = {Commun. ACM},
    priority = {2},
    publisher = {ACM},
    title = {Symbolic Execution and Program Testing},
    x-abstract = {This paper describes the symbolic execution of programs. Instead of supplying the normal inputs to a program (e.g. numbers) one supplies symbols representing arbitrary values. The execution proceeds as in a normal execution except that values may be symbolic formulas over the input symbols. The difficult, yet interesting issues arise during the symbolic execution of conditional branch type statements. A particular system called {EFFIGY} which provides symbolic execution for program testing and debugging is also described. It interpretively executes programs written in a simple {PL}/I style programming language. It includes many standard debugging features, the ability to manage and to prove things about symbolic expressions, a simple program testing manager, and a program verifier. A brief discussion of the relationship between symbolic execution and program proving is also included.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/360248.360252},
    x-issn = {0001-0782},
    x-month = jul,
    x-number = {7},
    x-url = {http://dx.doi.org/10.1145/360248.360252},
    x-volume = {19},
    xpages = {385--394},
    year = {1976}
}

@inproceedings{dvanhorn:Boyer1975SELECTa,
    author = {Boyer, Robert S. and Elspas, Bernard and Levitt, Karl N.},
    booktitle = {Proceedings of the International Conference on Reliable Software},
    citeulike-article-id = {9950017},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=808445},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/390016.808445},
    date-added = {2014-02-16 22:45:38},
    journal = {SIGPLAN Not.},
    location = {Los Angeles, California},
    priority = {2},
    publisher = {ACM},
    title = {{SELECT}--a Formal System for Testing and Debugging Programs by Symbolic Execution},
    x-abstract = {{SELECT} is an experimental system for assisting in the formal systematic debugging of programs. It is intended to be a compromise between an automated program proving system and the current ad hoc debugging practice, and is similar to a system being developed by King et al. of {IBM}. {SELECT} systematically handles the paths of programs written in a {LISP} subset that includes arrays. For each execution path {SELECT} returns simplified conditions on input variables that cause the path to be executed, and simplified symbolic values for program variables at the path output. For conditions which form a system of linear equalities and inequalities {SELECT} will return input variable values that can serve as sample test data. The user can insert constraint conditions, at any point in the program including the output, in the form of symbolically executable assertions. These conditions can induce the system to select test data in user-specified regions. {SELECT} can also determine if the path is correct with respect to an output assertion. We present four examples demonstrating the various modes of system operation and their effectiveness in finding bugs. In some examples, {SELECT} was successful in automatically finding useful test data. In others, user interaction was required in the form of output assertions. {SELECT} appears to be a useful tool for rapidly revealing program errors, but for the future there is a need to expand its expressive and deductive power.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/390016.808445},
    x-issn = {0362-1340},
    x-month = apr,
    x-url = {http://dx.doi.org/10.1145/390016.808445},
    x-volume = {10},
    xpages = {234--245},
    year = {1975}
}

@inproceedings{dvanhorn:Schwartz2010All,
    author = {Schwartz, Edward J. and Avgerinos, Thanassis and Brumley, David},
    booktitle = {Proceedings of the 2010 IEEE Symposium on Security and Privacy},
    citeulike-article-id = {9300207},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1849981},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/SP.2010.26},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/sp.2010.26},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5504796},
    date-added = {2014-02-16 16:58:01},
    journal = {Security and Privacy, IEEE Symposium on},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {All You Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic Execution (but Might Have Been Afraid to Ask)},
    x-abstract = {Dynamic taint analysis and forward symbolic execution are quickly becoming staple techniques in security analyses. Example applications of dynamic taint analysis and forward symbolic execution include malware analysis, input filter generation, test case generation, and vulnerability discovery. Despite the widespread usage of these two techniques, there has been little effort to formally define the algorithms and summarize the critical issues that arise when these techniques are used in typical security contexts. The contributions of this paper are two-fold. First, we precisely describe the algorithms for dynamic taint analysis and forward symbolic execution as extensions to the run-time semantics of a general language. Second, we highlight important implementation choices, common pitfalls, and considerations when using these techniques in a security context.},
    x-address = {Washington, DC, USA},
    x-doi = {10.1109/sp.2010.26},
    x-isbn = {978-0-7695-4035-1},
    x-issn = {1081-6011},
    x-month = may,
    x-series = {SP '10},
    x-url = {http://dx.doi.org/10.1109/sp.2010.26},
    x-volume = {0},
    xpages = {317--331},
    year = {2010}
}

@inproceedings{dvanhorn:Swamy2013Verifying,
    author = {Swamy, Nikhil and Weinberger, Joel and Schlesinger, Cole and Chen, Juan and Livshits, Benjamin},
    booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13050512},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2491956.2491978},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2499370.2491978},
    date-added = {2014-02-15 17:37:36},
    priority = {2},
    publisher = {ACM},
    title = {Verifying Higher-order Programs with the {D}ijkstra Monad},
    x-abstract = {Modern programming languages, ranging from Haskell and {ML}, to {JavaScript}, C\# and Java, all make extensive use of higher-order state. This paper advocates a new verification methodology for higher-order stateful programs, based on a new monad of predicate transformers called the Dijkstra monad. Using the Dijkstra monad has a number of benefits. First, the monad naturally yields a weakest pre-condition calculus. Second, the computed specifications are structurally simpler in several ways, e.g., single-state post-conditions are sufficient (rather than the more complex two-state post-conditions). Finally, the monad can easily be varied to handle features like exceptions and heap invariants, while retaining the same type inference algorithm. We implement the Dijkstra monad and its type inference algorithm for the F* programming language. Our most extensive case study evaluates the Dijkstra monad and its F* implementation by using it to verify {JavaScript} programs. Specifically, we describe a tool chain that translates programs in a subset of {JavaScript} decorated with assertions and loop invariants to F*. Once in F*, our type inference algorithm computes verification conditions and automatically discharges their proofs using an {SMT} solver. We use our tools to prove that a core model of the {JavaScript} runtime in F* respects various invariants and that a suite of {JavaScript} source programs are free of runtime errors.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2499370.2491978},
    x-issn = {0362-1340},
    x-month = jun,
    x-number = {6},
    x-series = {PLDI'13},
    x-url = {http://dx.doi.org/10.1145/2499370.2491978},
    x-volume = {48},
    xpages = {387--398},
    year = {2013}
}

@incollection{dvanhorn:Barrett2011CVC4,
    author = {Barrett, Clark and Conway, ChristopherL and Deters, Morgan and Hadarean, Liana and Jovanovi\'{c}, Dejan and King, Tim and Reynolds, Andrew and Tinelli, Cesare},
    booktitle = {Computer Aided Verification},
    citeulike-article-id = {9791297},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-22110-1\_14},
    citeulike-linkout-1 = {http://www.springerlink.com/content/r3g3k74m2p281j0n},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-642-22110-1\_14},
    date-added = {2013-07-11 21:52:08},
    priority = {2},
    publisher = {Springer},
    title = {CVC4},
    x-abstract = {{CVC4} is the latest version of the Cooperating Validity Checker. A joint project of {NYU} and U Iowa, {CVC4} aims to support the useful feature set of {CVC3} and {SMT}-{LIBv2} while optimizing the design of the core system architecture and decision procedures to take advantage of recent engineering and algorithmic advances. {CVC4} represents a completely new code base; it is a from-scratch rewrite of {CVC3}, and many subsystems have been completely redesigned. Additional decision procedures for {CVC4} are currently under development, but for what it currently achieves, it is a lighter-weight and higher-performing tool than {CVC3}. We describe the system architecture, subsystems of note, and discuss some applications and continuing work.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-22110-1\_14},
    x-editor = {Gopalakrishnan, Ganesh and Qadeer, Shaz},
    x-isbn = {978-3-642-22109-5},
    x-series = {CAV},
    x-url = {http://dx.doi.org/10.1007/978-3-642-22110-1\_14},
    x-volume = {6806},
    xpages = {171--177},
    year = {2011}
}

@inproceedings{dvanhorn:DeMoura2008Z3,
    author = {{De Moura}, Leonardo and Bj{\o}rner, Nikolaj},
    booktitle = {Proceedings of the Theory and practice of software, 14th international conference on Tools and algorithms for the construction and analysis of systems},
    citeulike-article-id = {12475017},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1792766},
    date-added = {2013-07-11 21:36:59},
    location = {Budapest, Hungary},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Z3: an efficient {SMT} solver},
    x-abstract = {Satisfiability Modulo Theories ({SMT}) problem is a decision problem for logical first order formulas with respect to combinations of background theories such as: arithmetic, bit-vectors, arrays, and uninterpreted functions. Z3 is a new and efficient {SMT} Solver freely available from Microsoft Research. It is used in various software verification and analysis applications.},
    x-address = {Berlin, Heidelberg},
    x-isbn = {3-540-78799-2, 978-3-540-78799-0},
    x-series = {TACAS},
    x-url = {http://portal.acm.org/citation.cfm?id=1792766},
    xpages = {337--340},
    year = {2008}
}

@incollection{dvanhorn:StAmour2012Typing,
    author = {St-Amour, Vincent and Tobin-Hochstadt, Sam and Flatt, Matthew and Felleisen, Matthias},
    booktitle = {Practical Aspects of Declarative Languages},
    citeulike-article-id = {12474890},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2187146},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-642-27694-1\_21},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-642-27694-1\_21},
    date-added = {2013-07-11 19:08:13},
    location = {Philadelphia, PA},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Typing the Numeric Tower},
    x-abstract = {In the past, the creators of numerical programs had to choose between simple expression of mathematical formulas and static type checking. While the Lisp family and its dynamically typed relatives support the straightforward expression via a rich numeric tower, existing statically typed languages force programmers to pollute textbook formulas with explicit coercions or unwieldy notation. In this paper, we demonstrate how the type system of Typed Racket accommodates both a textbook programming style and expressive static checking. The type system provides a hierarchy of numeric types that can be freely mixed as well as precise specifications of sign, representation, and range information—all while supporting generic operations. In addition, the type system provides information to the compiler so that it can perform standard numeric optimizations.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-27694-1\_21},
    x-editor = {Russo, Claudio and Zhou, Neng-Fa},
    x-isbn = {978-3-642-27693-4},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-27694-1\_21},
    x-volume = {7149},
    xpages = {289--303},
    year = {2012}
}

@incollection{dvanhorn:Dimoulas2012Complete,
    author = {Dimoulas, Christos and Tobin-Hochstadt, Sam and Felleisen, Matthias},
    booktitle = {21st European Symposium on Programming},
    citeulike-article-id = {12473623},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-28869-2\_11},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-28869-2\_11},
    date-added = {2013-07-10 19:07:43},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Complete Monitors for Behavioral Contracts},
    x-abstract = {A behavioral contract in a higher-order language may invoke methods of unknown objects. Although this expressive power allows programmers to formulate sophisticated contracts, it also poses a problem for language designers. Indeed, two distinct semantics have emerged for such method calls, dubbed lax and picky. While lax fails to protect components in certain scenarios, picky may blame an uninvolved party for a contract violation.
                          In this paper, we present complete monitoring as the fundamental correctness criterion for contract systems. It demands correct blame assignment as well as complete monitoring of all channels of communication between components. According to this criterion, lax and picky are indeed incorrect ways to monitor contracts. A third semantics, dubbed indy, emerges as the only correct variant.},
    x-doi = {10.1007/978-3-642-28869-2\_11},
    x-editor = {Seidl, Helmut},
    x-series = {ESOP'12},
    x-url = {http://dx.doi.org/10.1007/978-3-642-28869-2\_11},
    x-volume = {7211},
    xpages = {214--233},
    year = {2012}
}

@inproceedings{dvanhorn:Gronski2007Unifying,
    author = {Gronski, Jessica and Flanagan, Cormac},
    booktitle = {In Eighth Symposium on Trends in Functional Programming},
    citeulike-article-id = {5820562},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.123.3771},
    date-added = {2013-07-10 19:05:09},
    priority = {2},
    title = {Unifying hybrid types and contracts},
    x-abstract = {Contract systems and hybrid type systems provide two alternative approaches for enforcing precisely-defined interface specifications, with complementary advantages: contract systems excel at blame assignment, whereas hybrid type systems support type-based static analysis. We unify these two approaches by demonstrating that hybrid type checking is sufficiently expressive to encode higher-order contracts with proper blame assignment. In particular, a contract obligation that enforces both sides of a contract is decomposed into two type casts that each enforce one side of the contract. This expressiveness result provides several benefits, including allowing one of these casts to be lifted to earlier in the program\^{a}s execution, resulting in improved contract coverage. 1},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.123.3771},
    year = {2007}
}

@article{dvanhorn:Blume2006Sound,
    author = {Blume, Matthias and McAllester, David},
    citeulike-article-id = {9524694},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1166016},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796806005971},
    date-added = {2013-07-10 18:57:43},
    journal = {J. Funct. Program.},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Sound and complete models of contracts},
    x-abstract = {Even in statically typed languages it is useful to have certain invariants checked dynamically. Findler and Felleisen gave an algorithm for dynamically checking expressive higher-order types called contracts. They did not, however, give a semantics of contracts. The lack of a semantics makes it impossible to define and prove soundness and completeness of the checking algorithm. (Given a semantics, a sound checker never reports violations that do not exist under that semantics; a complete checker is – in principle – able to find violations when violations exist.) Ideally, a semantics should capture what programmers intuitively feel is the meaning of a contract or otherwise clearly point out where intuition does not match reality. In this paper we give an interpretation of contracts for which we prove the {Findler-Felleisen} algorithm sound and (under reasonable assumptions) complete. While our semantics mostly matches intuition, it also exposes a problem with predicate contracts where an arguably more intuitive interpretation than ours would render the checking algorithm unsound. In our semantics we have to make use of a notion of safety (which we define in the paper) to avoid unsoundness. We are able to eliminate the  ” leakage” of safety into the semantics by changing the language, replacing the original version of unrestricted predicate contracts with a restricted form. The corresponding loss in expressive power can be recovered by making safety explicit as a contract. This can be done either in ad-hoc fashion or by including general recursive contracts. The addition of recursive contracts has far-reaching implications, deeply affecting the formulation of our model and requiring different techniques for proving soundness.},
    x-address = {New York, NY, USA},
    x-doi = {10.1017/s0956796806005971},
    x-issn = {0956-7968},
    x-month = jul,
    x-number = {4-5},
    x-url = {http://dx.doi.org/10.1017/s0956796806005971},
    x-volume = {16},
    xpages = {375--414},
    year = {2006}
}

@inproceedings{dvanhorn:Plosch1997Design,
    author = {Plosch, R.},
    booktitle = {Software Engineering Conference, 1997. Asia Pacific ... and International Computer Science Conference 1997. APSEC '97 and ICSC '97. Proceedings},
    citeulike-article-id = {4221458},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/apsec.1997.640178},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=640178},
    date-added = {2013-07-10 03:45:54},
    institution = {Johannes Kepler Univ., Linz, Austria},
    journal = {Software Engineering Conference, 1997. Asia Pacific ... and International Computer Science Conference 1997. APSEC '97 and ICSC '97. Proceedings},
    location = {Hong Kong},
    priority = {2},
    publisher = {IEEE},
    title = {Design by contract for {P}ython},
    x-abstract = {The idea of design by contract ({DEC}), realized in the statically typed object-oriented programming language Eiffel, can be viewed as a systematic approach to specifying and implementing object-oriented software systems. We believe that a statically typed programming language is not suitable in the analysis and design phase of a prototyping-oriented software life cycle. For this purpose, dynamically typed interpreted programming languages are better suited. Unfortunately, dynamically typed programming languages usually do not support the concept of {DEC}. Therefore we integrated {DEC} into the programming language Python by using a metaprogramming approach, i.e., without changing the language or the run-time system. We adopted the {DEC} concept by adding mechanisms for dynamic type checking for method parameters and instance variables. The proposed combination of a more formal approach with a slim programming language provides a good basis for elicitation and documentation tasks in the analysis and design phase, especially in cases of a prototyping-oriented software development approach. Although the approach presented provides basic tool support for the analysis and design phase, further tool support especially for browsing assertions, is desirable},
    x-doi = {10.1109/apsec.1997.640178},
    x-isbn = {0-8186-8271-X},
    x-month = dec,
    x-note = {APSEC/ICSC'97},
    x-url = {http://dx.doi.org/10.1109/apsec.1997.640178},
    xpages = {213--219},
    year = {1997}
}

@inproceedings{dvanhorn:Strickland2012Chaperones,
    author = {Strickland, T. Stephen and Tobin-Hochstadt, Sam and Findler, Robert B. and Flatt, Matthew},
    booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
    citeulike-article-id = {12271764},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2384685},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2398857.2384685},
    date-added = {2013-07-10 03:04:47},
    priority = {2},
    publisher = {ACM},
    title = {Chaperones and impersonators: run-time support for reasonable interposition},
    x-abstract = {Chaperones and impersonators provide run-time support for interposing on primitive operations such as function calls, array access and update, and structure field access and update. Unlike most interposition support, chaperones and impersonators are restricted so that they constrain the behavior of the interposing code to reasonable interposition, which in practice preserves the abstraction mechanisms and reasoning that programmers and compiler analyses rely on. Chaperones and impersonators are particularly useful for implementing contracts, and our implementation in Racket allows us to improve both the expressiveness and the performance of Racket's contract system. Specifically, contracts on mutable data can be enforced without changing the {API} to that data; contracts on large data structures can be checked lazily on only the accessed parts of the structure; contracts on objects and classes can be implemented with lower overhead; and contract wrappers can preserve object equality where appropriate. With this extension, gradual typing systems, such as Typed Racket, that rely on contracts for interoperation with untyped code can now pass mutable values safely between typed and untyped modules.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2398857.2384685},
    x-issn = {0362-1340},
    x-month = oct,
    x-series = {OOPSLA},
    x-url = {http://dx.doi.org/10.1145/2398857.2384685},
    xpages = {943--962},
    year = {2012}
}

@article{dvanhorn:Greenberg2012Contracts,
    author = {Greenberg, Michael and Pierce, Benjamin C. and Weirich, Stephanie},
    citeulike-article-id = {12472814},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=8626437},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796812000135},
    date-added = {2013-07-09 22:52:29},
    journal = {Journal of Functional Programming},
    priority = {2},
    title = {Contracts made manifest},
    x-abstract = {Since Findler and Felleisen (Findler, R. B. \& Felleisen, M. 2002) introduced higher-order contracts, many variants have been proposed. Broadly, these fall into two groups: some follow Findler and Felleisen (2002) in using latent contracts, purely dynamic checks that are transparent to the type system; others use manifest contracts, where refinement types record the most recent check that has been applied to each value. These two approaches are commonly assumed to be equivalent—different ways of implementing the same idea, one retaining a simple type system, and the other providing more static information. Our goal is to formalize and clarify this folklore understanding. Our work extends that of Gronski and Flanagan (Gronski, J. \& Flanagan, C. 2007), who defined a latent calculus {λC} and a manifest calculus {λH}, gave a translation φ from {λC} to {λH}, and proved that if a {λC} term reduces to a constant, so does its φ-image. We enrich their account with a translation ψ from {λH} to {λC} and prove an analogous theorem. We then generalize the whole framework to dependent contracts, whose predicates can mention free variables. This extension is both pragmatically crucial, supporting a much more interesting range of contracts, and theoretically challenging. We define dependent versions of {λH} and two dialects ( ” lax” and  ” picky”) of {λC}, establish type soundness—a substantial result in itself, for {λH} — and extend φ and ψ accordingly. Surprisingly, the intuition that the latent and manifest systems are equivalent now breaks down: the extended translations preserve behavior in one direction, but in the other, sometimes yield terms that blame more.},
    x-doi = {10.1017/s0956796812000135},
    x-issn = {1469-7653},
    x-month = may,
    x-url = {http://dx.doi.org/10.1017/s0956796812000135},
    x-volume = {22},
    xpages = {225--274},
    year = {2012}
}

@inproceedings{dvanhorn:Freeman1991Refinement,
    author = {Freeman, Tim and Pfenning, Frank},
    booktitle = {Proceedings of the ACM SIGPLAN 1991 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {497232},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=113468},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/113445.113468},
    date-added = {2013-07-09 20:22:08},
    location = {Toronto, Ontario, Canada},
    priority = {2},
    publisher = {ACM},
    title = {Refinement Types for {ML}},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/113445.113468},
    x-isbn = {0-89791-428-7},
    x-issn = {0362-1340},
    x-month = jun,
    x-number = {6},
    x-series = {PLDI},
    x-url = {http://dx.doi.org/10.1145/113445.113468},
    x-volume = {26},
    xpages = {268--277},
    year = {1991}
}

@article{dvanhorn:Cartwright1996Program,
    author = {Cartwright, Robert and Felleisen, Matthias},
    citeulike-article-id = {190442},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=234747},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/234528.234747},
    date-added = {2013-07-09 20:02:05},
    journal = {ACM Comput. Surv.},
    priority = {2},
    publisher = {ACM},
    title = {Program verification through soft typing},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/234528.234747},
    x-issn = {0360-0300},
    x-month = jun,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1145/234528.234747},
    x-volume = {28},
    xpages = {349--351},
    year = {1996}
}

@inproceedings{dvanhorn:Aiken1994Soft,
    author = {Aiken, Alexander and Wimmers, Edward L. and Lakshman, T. K.},
    booktitle = {Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {7062350},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=174675.177847},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/174675.177847},
    date-added = {2013-07-09 19:29:35},
    location = {Portland, Oregon, USA},
    priority = {2},
    publisher = {ACM},
    title = {Soft typing with conditional types},
    x-abstract = {We present a simple and powerful type inference method for dynamically typed languages where no type information is supplied by the user. Type inference is reduced to the problem of solvability of a system of type inclusion constraints over a type language that includes function types, constructor types, union, intersection, and recursive types, and conditional types. Conditional types enable us to analyze control flow using type inference, thus facilitating computation of accurate types. We demonstrate the power and practicality of the method with examples and performance results from an implementation.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/174675.177847},
    x-isbn = {0-89791-636-0},
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/174675.177847},
    xpages = {163--173},
    year = {1994}
}

@incollection{dvanhorn:Kawaguchi2010Dsolve,
    author = {Kawaguchi, Ming and Rondon, PatrickM and Jhala, Ranjit},
    booktitle = {Computer Aided Verification},
    citeulike-article-id = {12465105},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-14295-6\_12},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-14295-6\_12},
    date-added = {2013-07-09 19:24:25},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Dsolve: Safety Verification via Liquid Types},
    x-abstract = {We present Dsolve, a verification tool for {OCaml}. Dsolve automates verification by inferring  ” Liquid” refinement types that are expressive enough to verify a variety of complex safety properties.},
    x-doi = {10.1007/978-3-642-14295-6\_12},
    x-editor = {Touili, Tayssir and Cook, Byron and Jackson, Paul},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-14295-6\_12},
    x-volume = {6174},
    xpages = {123--126},
    year = {2010}
}

@inproceedings{dvanhorn:Vazou2013Abstract,
    author = {Vazou, Niki and Rondon, PatrickM and Jhala, Ranjit},
    booktitle = {European Symposium on Programming},
    citeulike-article-id = {12465100},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-37036-6\_13},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-37036-6\_13},
    date-added = {2013-07-09 19:19:26},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Abstract Refinement Types},
    x-abstract = {We present abstract refinement types which enable quantification over the refinements of data- and function-types. Our key insight is that we can avail of quantification while preserving {SMT}-based decidability, simply by encoding refinement parameters as uninterpreted propositions within the refinement logic. We illustrate how this mechanism yields a variety of sophisticated means for reasoning about programs, including: parametric refinements for reasoning with type classes, index-dependent refinements for reasoning about key-value maps, recursive refinements for reasoning about recursive data types, and inductive refinements for reasoning about higher-order traversal routines. We have implemented our approach in a refinement type checker for Haskell and present experiments using our tool to verify correctness invariants of various programs.},
    x-doi = {10.1007/978-3-642-37036-6\_13},
    x-editor = {Felleisen, Matthias and Gardner, Philippa},
    x-series = {ESOP},
    x-url = {http://dx.doi.org/10.1007/978-3-642-37036-6\_13},
    x-volume = {7792},
    xpages = {209--228},
    year = {2013}
}

@article{dvanhorn:Henglein1994Dynamic,
    author = {Henglein, Fritz},
    citeulike-article-id = {853230},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0167-6423(94)00004-2},
    citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6V17-45GMGM9-1K/2/6f1a92280b24d91191679940d586c4fa},
    date-added = {2013-07-09 19:14:49},
    journal = {Science of Computer Programming},
    priority = {2},
    title = {Dynamic typing: syntax and proof theory},
    x-abstract = {We present the dynamically typed \^{I}»-calculus, an extension of the statically typed \^{I}»-calculus with a special type Dyn and explicit dynamic type coercions corresponding to run-time type tagging and type check-and-untag operations. Programs in run-time typed languages can be interpreted in the dynamically typed \^{I}»-calculus via a nondeterministic completion process that inserts explicit coercions and type declarations such that a well-typed term results. We characterize when two different completions of the same run-time typed program are coherent with an equational theory that is independent of an underlying \^{I}»-theory. This theory is refined by orienting some equations to define safety and minimality of completions. Intuitively, a safe completion is one that does not produce an error at run-time which another completion would have avoided, and a minimal completion is a safe completion that executes fewest tagging and check-and-untag operations amongst all safe completions. We show that every untyped \^{I}»-term has a safe completion at any type and that it is unique modulo a suitable congruence relation. Furthermore, we present a rewriting system for generating minimal completions. Assuming strong normalization of this rewriting system we show that every {\^{I}»I}-term has a minimal completion at any type, which is furthermore unique modulo equality in the dynamically typed \^{I}»-calculus.},
    x-doi = {10.1016/0167-6423(94)00004-2},
    x-issn = {01676423},
    x-month = jun,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1016/0167-6423(94)00004-2},
    x-volume = {22},
    xpages = {197--230},
    year = {1994}
}

@inproceedings{dvanhorn:Cartwright1991Soft,
    author = {Cartwright, Robert and Fagan, Mike},
    booktitle = {Proceedings of the ACM SIGPLAN 1991 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {2792466},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=113445.113469},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/113445.113469},
    date-added = {2013-07-09 19:07:46},
    location = {Toronto, Ontario, Canada},
    priority = {2},
    publisher = {ACM},
    title = {Soft typing},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/113445.113469},
    x-isbn = {0-89791-428-7},
    x-series = {PLDI},
    x-url = {http://dx.doi.org/10.1145/113445.113469},
    xpages = {278--292},
    year = {1991}
}

@inproceedings{dvanhorn:Tsukada2010Untyped,
    author = {Tsukada, Takeshi and Kobayashi, Naoki},
    booktitle = {Proceedings of the 13th International Conference on Foundations of Software Science and Computational Structures},
    citeulike-article-id = {12464893},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2175551},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-642-12032-9\_24},
    date-added = {2013-07-09 15:58:48},
    location = {Paphos, Cyprus},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Untyped recursion schemes and infinite intersection types},
    x-abstract = {A new framework for higher-order program verification has been recently proposed, in which higher-order functional programs are modelled as higher-order recursion schemes and then model-checked. As recursion schemes are essentially terms of the simply-typed lambda-calculus with recursion and tree constructors, however, it was not clear how the new framework applies to programs written in languages with more advanced type systems. To circumvent the limitation, this paper introduces an untyped version of recursion schemes and develops an infinite intersection type system that is equivalent to the model checking of untyped recursion schemes, so that the model checking can be reduced to type checking as in recent work by Kobayashi and Ong for typed recursion schemes. The type system is undecidable but we can obtain decidable subsets of the type system by restricting the shapes of intersection types, yielding a sound (but incomplete in general) model checking algorithm.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-12032-9\_24},
    x-isbn = {3-642-12031-8, 978-3-642-12031-2},
    x-series = {FoSSaCS},
    x-url = {http://dx.doi.org/10.1007/978-3-642-12032-9\_24},
    xpages = {343--357},
    year = {2010}
}

@inproceedings{dvanhorn:Kobayashi2013ModelChecking,
    author = {Kobayashi, Naoki and Igarashi, Atsushi},
    booktitle = {European Symposium on Programming},
    citeulike-article-id = {12461148},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-37036-6\_24},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-37036-6\_24},
    date-added = {2013-07-05 19:35:52},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {{Model-Checking} {Higher-Order} Programs with Recursive Types},
    x-abstract = {Model checking of higher-order recursion schemes ({HORS}, for short) has been recently studied as a new promising technique for automated verification of higher-order programs. The previous {HORS} model checking could however deal with only simply-typed programs, so that its application was limited to functional programs. To deal with a broader range of programs such as object-oriented programs and multi-threaded programs, we extend {HORS} model checking to check properties of programs with recursive types. Although the extended model checking problem is undecidable, we develop a sound model-checking algorithm that is relatively complete with respect to a recursive intersection type system and prove its correctness. Preliminary results on the implementation and applications to verification of object-oriented programs and multi-threaded programs are also reported.},
    x-doi = {10.1007/978-3-642-37036-6\_24},
    x-editor = {Felleisen, Matthias and Gardner, Philippa},
    x-series = {ESOP},
    x-url = {http://dx.doi.org/10.1007/978-3-642-37036-6\_24},
    xpages = {431--450},
    year = {2013}
}

@inproceedings{dvanhorn:Kobayashi2009Modelchecking,
    author = {Kobayashi, Naoki},
    booktitle = {Proceedings of the 11th ACM SIGPLAN Conference on Principles and Practice of Declarative Programming},
    citeulike-article-id = {6647894},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1599410.1599415},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1599410.1599415},
    date-added = {2013-07-05 19:20:54},
    location = {Coimbra, Portugal},
    priority = {2},
    publisher = {ACM},
    title = {Model-checking higher-order functions},
    x-abstract = {We propose a novel type-based model checking algorithm for higher-order recursion schemes. As shown by Kobayashi, verification problems of higher-order functional programs can easily be translated into model checking problems of recursion schemes. Thus, the model checking algorithm serves as a basis for verification of higher-order functional programs. To our knowledge, this is the first practical algorithm for model checking recursion schemes: all the previous algorithms always suffer from the {n-EXPTIME} bottleneck, not only in the worst, and there was no implementation of the algorithms. We have implemented a model checker for recursion schemes based on the proposed algorithm, and applied it to verification of functional programs, including reachability, flow analysis and resource usage verification problems. According to our experiments, the model checker is surprisingly fast: it could automatically verify a number of small but tricky higher-order functional programs in less than a second.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1599410.1599415},
    x-isbn = {978-1-60558-568-0},
    x-series = {PPDP},
    x-url = {http://dx.doi.org/10.1145/1599410.1599415},
    xpages = {25--36},
    year = {2009}
}

@inproceedings{dvanhorn:Kobayashi2010Higherorder,
    author = {Kobayashi, Naoki and Tabuchi, Naoshi and Unno, Hiroshi},
    booktitle = {Proceedings of the 37th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {12461139},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1706355},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1707801.1706355},
    date-added = {2013-07-05 19:18:12},
    priority = {2},
    publisher = {ACM},
    title = {Higher-order multi-parameter tree transducers and recursion schemes for program verification},
    x-abstract = {We introduce higher-order, multi-parameter, tree transducers ({HMTTs}, for short), which are kinds of higher-order tree transducers that take input trees and output a (possibly infinite) tree. We study the problem of checking whether the tree generated by a given {HMTT} conforms to a given output specification, provided that the input trees conform to input specifications (where both input/output specifications are regular tree languages). {HMTTs} subsume higher-order recursion schemes and ordinary tree transducers, so that their verification has a number of potential applications to verification of functional programs using recursive data structures, including resource usage verification, string analysis, and exact type-checking of {XML}-processing programs. We propose a sound but incomplete verification algorithm for the {HMTT} verification problem: the algorithm reduces the verification problem to a model-checking problem for higher-order recursion schemes extended with finite data domains, and then uses (an extension {of)Kobayashi}'s algorithm for model-checking recursion schemes. While the algorithm is incomplete (indeed, as we show in the paper, the verification problem is undecidable in general), it is sound and complete for a subclass of {HMTTs} called linear {HMTTs} . We have applied our {HMTT} verification algorithm to various program verification problems and obtained promising results.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1707801.1706355},
    x-issn = {0362-1340},
    x-month = jan,
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/1707801.1706355},
    xpages = {495--508},
    year = {2010}
}

@inproceedings{dvanhorn:Kobayashi2009Type,
    author = {Kobayashi, Naoki and Ong, C. H. Luke},
    booktitle = {2009 24th Annual IEEE Symposium on Logic In Computer Science},
    citeulike-article-id = {12461130},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/lics.2009.29},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5230581},
    date-added = {2013-07-05 19:12:49},
    location = {Los Angeles, California, USA},
    priority = {2},
    publisher = {IEEE},
    title = {A Type System Equivalent to the Modal {Mu-Calculus} Model Checking of {Higher-Order} Recursion Schemes},
    x-doi = {10.1109/lics.2009.29},
    x-isbn = {978-0-7695-3746-7},
    x-month = aug,
    x-series = {LICS},
    x-url = {http://dx.doi.org/10.1109/lics.2009.29},
    xpages = {179--188},
    year = {2009}
}

@article{dvanhorn:Leroy2009Coinductive,
    author = {Leroy, Xavier and Grall, Herv\'{e}},
    citeulike-article-id = {5447147},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1513247},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.ic.2007.12.004},
    date-added = {2013-06-01 01:45:12},
    journal = {Information and Computation},
    priority = {2},
    publisher = {Academic Press, Inc.},
    title = {Coinductive big-step operational semantics},
    x-abstract = {Using a call-by-value functional language as an example, this article illustrates the use of coinductive definitions and proofs in big-step operational semantics, enabling it to describe diverging evaluations in addition to terminating evaluations. We formalize the connections between the coinductive big-step semantics and the standard small-step semantics, proving that both semantics are equivalent. We then study the use of coinductive big-step semantics in proofs of type soundness and proofs of semantic preservation for compilers. A methodological originality of this paper is that all results have been proved using the Coq proof assistant. We explain the proof-theoretic presentation of coinductive definitions and proofs offered by Coq, and show that it facilitates the discovery and the presentation of the results.},
    x-address = {Duluth, MN, USA},
    x-doi = {10.1016/j.ic.2007.12.004},
    x-issn = {08905401},
    x-month = feb,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1016/j.ic.2007.12.004},
    x-volume = {207},
    xpages = {284--304},
    year = {2009}
}

@article{dvanhorn:Schmidt1998TraceBased,
    author = {Schmidt, David A.},
    citeulike-article-id = {12382116},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=305408},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/a:1007734417713},
    date-added = {2013-06-01 01:42:45},
    journal = {Lisp Symb. Comput.},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{Trace-Based} Abstract Interpretation of Operational Semantics},
    x-abstract = {We present trace-based abstract interpretation, 
a unification of several
lines of research on applying {Cousot-Cousot}-style 
abstract interpretation a.i. to
operational semantics definitions (such as flowchart, big-step, 
and small-step semantics)
that express a program's semantics as a concrete computation 
tree of trace paths. A
program's trace-based a.i. is also a computation 
tree whose nodes contain abstractions of
state and whose paths simulate the paths in the program's 
concrete computation tree.
Using such computation trees, we provide a simple explanation 
of the central concept of collecting semantics, 
and we distinguish concrete from abstract collecting
semantics and state-based from path-based collecting semantics. 
We also expose the
relationship between collecting semantics extraction and results 
garnered from flow-analytic and model-checking-based analysis techniques. 
We adapt concepts from
concurrency theory to formalize  ” safe” 
and  ” live” a.i.'s for computation 
trees; in particular, coinduction techniques help extend 
fundamental results to infinite computation {trees.Problems} specific to the various operational semantics 
methodologies are discussed: Big-step semantics cannot express 
divergence, so we employ a mixture of induction and
coinduction in response; small-step semantics generate sequences of program
configurations unbounded in size, so we abstractly interpret source 
language syntax.
Applications of trace-based a.i. to data-flow 
analysis, model checking, closure analysis,
and concurrency theory are demonstrated.},
    x-address = {Hingham, MA, USA},
    x-doi = {10.1023/a:1007734417713},
    x-issn = {0892-4635},
    x-month = may,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1023/a:1007734417713},
    x-volume = {10},
    xpages = {237--271},
    year = {1998}
}

@inproceedings{dvanhorn:Cousot1992Inductive,
    author = {Cousot, Patrick and Cousot, Radhia},
    booktitle = {Proceedings of the 19th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {4744445},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=143184},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/143165.143184},
    date-added = {2013-06-01 01:39:36},
    location = {Albuquerque, New Mexico, USA},
    priority = {2},
    publisher = {ACM},
    title = {Inductive definitions, semantics and abstract interpretations},
    x-abstract = {We introduce and illustrate a specification method combining rule-based inductive definitions, well-founded induction principles, fixed-point theory and abstract interpretation for general use in computer science. Finite as well as infinite objects can be specified, at various levels of details related by abstraction. General proof principles are applicable to prove properties of the specified {objects.The} specification method is illustrated by introducing G ∞ {SOS}, a structured operational semantics generalizing Plotkin's [28] structured operational semantics ({SOS}) so as to describe the finite, as well as the infinite behaviors of programs in a uniform way and by constructively deriving inductive presentations of the other (relational, denotational, predicate  transformers, …) semantics from G ∞ {SOS} by abstract interpretation.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/143165.143184},
    x-isbn = {0-89791-453-8},
    x-series = {POPL '92},
    x-url = {http://dx.doi.org/10.1145/143165.143184},
    xpages = {83--94},
    year = {1992}
}

@proceedings{dvanhorn:DBLP:conf/cav/2011,
    booktitle = {CAV},
    citeulike-article-id = {12338748},
    date-added = {2013-05-13 03:41:50},
    priority = {2},
    publisher = {Springer},
    title = {Computer Aided Verification - 23rd International Conference, {CAV} 2011, Snowbird, {UT}, {USA}, July 14-20, 2011. Proceedings},
    x-editor = {Gopalakrishnan, Ganesh and Qadeer, Shaz},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {6806},
    year = {2011}
}

@inproceedings{dvanhorn:DBLP:conf/cav/JhalaMR11,
    author = {Jhala, Ranjit and Majumdar, Rupak and Rybalchenko, Andrey},
    booktitle = {CAV},
    citeulike-article-id = {12338747},
    date-added = {2013-05-13 03:41:50},
    priority = {2},
    publisher = {Springer},
    title = {{HMC}: Verifying Functional Programs Using Abstract Interpreters},
    x-editor = {Gopalakrishnan, Ganesh and Qadeer, Shaz},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {6806},
    xpages = {470--485},
    year = {2011}
}

@misc{dvanhorn:Ponto2011Traces,
    archivePrefix = {arXiv},
    author = {Ponto, Kate and Shulman, Michael},
    citeulike-article-id = {9604375},
    citeulike-linkout-0 = {http://arxiv.org/abs/1107.6032},
    citeulike-linkout-1 = {http://arxiv.org/pdf/1107.6032},
    date-added = {2013-05-13 00:15:51},
    day = {29},
    eprint = {1107.6032},
    priority = {2},
    title = {Traces in symmetric monoidal categories},
    x-abstract = {The purpose of this expository note is to describe duality and trace in a
symmetric monoidal category, along with important properties (including
naturality and functoriality), and to give as many examples as possible. Among
other things, this note is intended as background for the generalizations to
the context of bicategories and indexed monoidal categories.},
    x-month = jul,
    x-url = {http://arxiv.org/abs/1107.6032},
    year = {2011}
}

@article{dvanhorn:Joyal1996Traced,
    author = {Joyal, Andr\'{e} and Street, Ross and Verity, Dominic},
    citeulike-article-id = {4870283},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=2102776},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0305004100074338},
    date-added = {2013-05-13 00:14:01},
    journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
    priority = {2},
    title = {Traced monoidal categories},
    x-abstract = {Traced monoidal categories are introduced, a structure theorem is proved for them, and an example is provided where the structure theorem has application.},
    x-doi = {10.1017/s0305004100074338},
    x-issn = {1469-8064},
    x-month = mar,
    x-number = {03},
    x-url = {http://dx.doi.org/10.1017/s0305004100074338},
    x-volume = {119},
    xpages = {447--468},
    year = {1996}
}

@article{dvanhorn:Stein2005SAGE,
    author = {Stein, William and Joyner, David},
    citeulike-article-id = {6506506},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1101884.1101889},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1101884.1101889},
    date-added = {2013-05-13 00:09:38},
    journal = {SIGSAM Bull.},
    priority = {2},
    publisher = {ACM},
    title = {{SAGE}: system for algebra and geometry experimentation},
    x-abstract = {{SAGE} is a framework for number theory, algebra, and geometry computation that is initially being designed for computing with elliptic curves and modular forms. The current implementation is primarily due to William Stein. It is open source and freely available under the terms of the {GNU} General Public License ({GPL}).},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1101884.1101889},
    x-issn = {0163-5824},
    x-month = jun,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1145/1101884.1101889},
    x-volume = {39},
    xpages = {61--64},
    year = {2005}
}

@book{dvanhorn:GMRFbook,
    author = {Rue, H. and Held, L.},
    citeulike-article-id = {12338620},
    date-added = {2013-05-12 21:09:21},
    priority = {2},
    publisher = {Chapman \& Hall},
    title = {Gaussian {M}arkov Random Fields: {T}heory and Applications},
    x-address = {London},
    x-series = {Monographs on Statistics and Applied Probability},
    x-volume = {104},
    year = {2005}
}

@inproceedings{dvanhorn:Friedman1998Learning,
    author = {Friedman, Nir and Murphy, Kevin and Russell, Stuart},
    booktitle = {Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence},
    citeulike-article-id = {12338619},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2074111},
    date-added = {2013-05-12 21:05:15},
    location = {Madison, Wisconsin},
    priority = {2},
    publisher = {Morgan Kaufmann Publishers Inc.},
    title = {Learning the structure of dynamic probabilistic networks},
    x-abstract = {Dynamic probabilistic networks are a compact representation of complex stochastic processes. In this paper we examine how to learn the structure of a {DPN} from data. We extend structure scoring rules for standard probabilistic networks to the dynamic case, and show how to search for structure when some of the variables are hidden. Finally, we examine two applications where such a technology might be useful: predicting and classifying dynamic behaviors, and learning causal orderings in biological processes. We provide empirical results that demonstrate the applicability of our methods in both domains.},
    x-address = {San Francisco, CA, USA},
    x-isbn = {1-55860-555-X},
    x-series = {UAI'98},
    x-url = {http://portal.acm.org/citation.cfm?id=2074111},
    xpages = {139--147},
    year = {1998}
}

@inproceedings{dvanhorn:Ghahramani1998Learning,
    author = {Ghahramani, Zoubin},
    booktitle = {Adaptive Processing of Sequences and Data Structures},
    citeulike-article-id = {4021621},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7874},
    date-added = {2013-05-12 21:02:33},
    priority = {2},
    title = {Learning dynamic Bayesian networks},
    x-abstract = {Bayesian networks are directed acyclic graphs that represent dependencies between variables in a probabilistic model. Many time series models, including the hidden Markov models ({HMMs}) used in speech recognition and Kalman filter models used in filtering and control applications, can be viewed as examples of dynamic Bayesian networks. We first provide a brief tutorial on learning and Bayesian networks. We then present some dynamic Bayesian networks that can capture much richer structure than {HMMs} and Kalman filters, including spatial and temporal multiresolution structure, distributed hidden state representations, and multiple switching linear regimes. While exact probabilistic inference is intractable in these networks, one can obtain tractable variational approximations which call as subroutines the forward-backward and Kalman filter recursions. These approximations can be used to learn the model parameters...},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7874},
    x-volume = {1387},
    xpages = {168--197},
    year = {1998}
}

@article{dvanhorn:DBLP:journals/jmlr/Winn12,
    author = {Winn, John},
    citeulike-article-id = {12338614},
    date-added = {2013-05-12 20:58:39},
    journal = {Journal of Machine Learning Research - Proceedings Track},
    priority = {2},
    title = {Causality with Gates},
    x-volume = {22},
    xpages = {1314--1322},
    year = {2012}
}

@article{dvanhorn:DBLP:journals/corr/abs-1302-2692,
    author = {Liang, Shuying and Might, Matthew and Gilray, Thomas and Van{ }Horn, David},
    citeulike-article-id = {12338574},
    date-added = {2013-05-12 18:47:29},
    journal = {CoRR},
    priority = {2},
    title = {Pushdown {Exception-Flow} Analysis of {Object-Oriented} Programs},
    x-volume = {abs/1302.2692},
    year = {2013}
}

@article{dvanhorn:Johnson2012Correctly,
    author = {Johnson, J. Ian and Labich, Nicholas and Might, Matthew and Van{ }Horn, David},
    citeulike-article-id = {12338571},
    citeulike-linkout-0 = {http://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1211-3722},
    date-added = {2013-05-12 18:29:02},
    journal = {CoRR},
    priority = {2},
    title = {Correctly Optimizing Abstract Abstract Machines},
    x-url = {http://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1211-3722},
    x-volume = {abs/1211.3722},
    year = {2012}
}

@article{dvanhorn:Granger1989Static,
    author = {Granger, Philippe},
    citeulike-article-id = {12336370},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00207168908803778},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/00207168908803778},
    date-added = {2013-05-12 05:21:05},
    day = {1},
    journal = {International Journal of Computer Mathematics},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {Static analysis of arithmetical congruences},
    x-abstract = {In this paper, a new kind of static (or semantic) analysis is defined: congruence analysis, which is conceived to discover the properties of the following type: ?the integer valued variable X is congruent to c modulo m?, where c and m are automatically determined integers. This analysis is then related to an algebraic framework and wholly characterized. Moreover, we show an example how it can be useful for automatic vectorization. Finally, we present some extensions of it, namely its combination with the analysis of bounds, and also some analyses defined when the modulus of congruences is given a priori.},
    x-doi = {10.1080/00207168908803778},
    x-month = jan,
    x-number = {3-4},
    x-url = {http://dx.doi.org/10.1080/00207168908803778},
    x-volume = {30},
    xpages = {165--190},
    year = {1989}
}

@inproceedings{dvanhorn:Cousot1978Automatic,
    author = {Cousot, Patrick and Halbwachs, Nicolas},
    booktitle = {Proceedings of the 5th ACM SIGACT-SIGPLAN symposium on Principles of programming languages},
    citeulike-article-id = {120467},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=512770},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/512760.512770},
    date-added = {2013-05-12 05:20:04},
    location = {Tucson, Arizona},
    priority = {2},
    publisher = {ACM},
    title = {Automatic discovery of linear restraints among variables of a program},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/512760.512770},
    x-series = {POPL '78},
    x-url = {http://dx.doi.org/10.1145/512760.512770},
    xpages = {84--96},
    year = {1978}
}

@inproceedings{dvanhorn:Mine2002Few,
    author = {Min{\'{e}}, Antoine},
    booktitle = {Proceedings of the 9th International Symposium on Static Analysis},
    citeulike-article-id = {12336369},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=647171.718313},
    date-added = {2013-05-12 05:17:08},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {A Few {Graph-Based} Relational Numerical Abstract Domains},
    x-abstract = {This article presents the systematic design of a class of relational numerical abstract domains from non-relational ones. Constructed domains represent sets of invariants of the form (vj - vi \^{A}¿ C), where vj and vi are two variables, and C lives in an abstraction of {P(Z}), {P(Q}), or {P(R}). We will call this family of domains weakly relational domains. The underlying concept allowing this construction is an extension of potential graphs and shortest-path closure algorithms in exotic-like {algebras.Example} constructions are given in order to retrieve well-known domains as well as new ones. Such domains can then be used in the Abstract Interpretation framework in order to design various static analyses. A major benefit of this construction is its modularity, allowing to quickly implement new abstract domains from existing ones.},
    x-address = {London, UK, UK},
    x-isbn = {3-540-44235-9},
    x-series = {SAS '02},
    x-url = {http://portal.acm.org/citation.cfm?id=647171.718313},
    xpages = {117--132},
    year = {2002}
}

@article{dvanhorn:File1996Unifying,
    author = {Fil{\'{e}}, Gilberto and Giacobazzi, Roberto and Ranzato, Francesco},
    citeulike-article-id = {6998540},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=234528.234742},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/234528.234742},
    date-added = {2013-05-12 05:15:58},
    journal = {ACM Comput. Surv.},
    priority = {2},
    publisher = {ACM},
    title = {A unifying view of abstract domain design},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/234528.234742},
    x-issn = {0360-0300},
    x-month = jun,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1145/234528.234742},
    x-volume = {28},
    xpages = {333--336},
    year = {1996}
}

@inproceedings{dvanhorn:Mine2001New,
    author = {Min{\'{e}}, Antoine},
    booktitle = {Proceedings of the Second Symposium on Programs as Data Objects},
    citeulike-article-id = {12336368},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=668110},
    date-added = {2013-05-12 05:14:30},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {A New Numerical Abstract Domain Based on {Difference-Bound} Matrices},
    x-abstract = {This paper presents a new numerical abstract domain for static analysis by abstract interpretation. This domain allows us to represent invariants of the form (x - y ≤ c)an d (±x ≤ c), where x and y are variables values and c is an integer or real constant. Abstract elements are represented by {Difference-Bound} Matrices, widely used by model-checkers, but we had to design new operators to meet the needs of abstract interpretation. The result is a complete lattice of infinite height featuring widening, narrowing and common transfer functions. We focus on giving an efficient O(n2)re presentation and graph-based O(n3) algorithms--where n is the number of variables--and claim that this domain always performs more precisely than the well-known interval domain. To illustrate the precision/cost tradeoff of this domain, we have implemented simple abstract interpreters for toy imperative and parallel languages which allowed us to prove some non-trivial algorithms correct.},
    x-address = {London, UK, UK},
    x-isbn = {3-540-42068-1},
    x-series = {PADO '01},
    x-url = {http://portal.acm.org/citation.cfm?id=668110},
    xpages = {155--172},
    year = {2001}
}

@article{dvanhorn:Mine2006Octagon,
    author = {Min\'{e}, Antoine},
    booktitle = {Higher-Order and Symbolic Computation},
    citeulike-article-id = {2798522},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1145526},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s10990-006-8609-1},
    citeulike-linkout-2 = {http://www.springerlink.com/content/q805711557559810},
    citeulike-linkout-3 = {http://link.springer.com/article/10.1007/s10990-006-8609-1},
    date-added = {2013-05-12 05:12:37},
    day = {1},
    journal = {Higher-Order and Symbolic Computation},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {The octagon abstract domain},
    x-abstract = {This article presents the octagon abstract domain, a relational numerical abstract domain for static analysis by abstract interpretation. It allows representing conjunctions of constraints of the form ± X ± Y ≤ c where X and Y range among program variables and c is a constant in ℤ, ℚ, or ℝ automatically inferred. Abstract elements are represented using modified Difference Bound Matrices and we use a normalization algorithm loosely based on the shortest-path closure to compute canonical representations and construct best-precision abstract transfer functions. We achieve a quadratic memory cost per abstract element and a cubic worst-case time cost per abstract operation, with respect to the number of program variables.
                            In terms of cost and precision, our domain is in between the well-known fast but imprecise interval domain and the costly polyhedron domain. We show that it is precise enough to treat interesting examples requiring relational invariants, and hence, out of the reach of the interval domain. We also present a packing strategy that allows scaling our domain up to large programs by tuning the amount of relationality. The octagon domain was incorporated into the {ASTR\'{E}E} industrial-strength static analyzer and was key in proving the absence of run-time errors in large critical embedded flight control software for Airbus planes.},
    x-address = {Hingham, MA, USA},
    x-doi = {10.1007/s10990-006-8609-1},
    x-issn = {1388-3690},
    x-month = mar,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1007/s10990-006-8609-1},
    x-volume = {19},
    xpages = {31--100},
    year = {2006}
}

@article{dvanhorn:Amato2012Abstract,
    author = {Amato, Gianluca and Scozzari, Francesca},
    citeulike-article-id = {11639434},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.entcs.2012.09.003},
    date-added = {2013-05-12 05:07:20},
    journal = {Electronic Notes in Theoretical Computer Science},
    priority = {2},
    title = {The Abstract Domain of Parallelotopes},
    x-abstract = {We propose a numerical abstract domain based on parallelotopes. A parallelotope is a polyhedron whose constraint matrix is squared and invertible. The domain of parallelotopes is a fully relational abstraction of the Cousot and Halbwachs\^{E}¼ polyhedra abstract domain, and does not use templates. We equip the domain of parallelotopes with all the necessary operations for the analysis of imperative programs, and show optimality results for the abstract operators.},
    x-doi = {10.1016/j.entcs.2012.09.003},
    x-issn = {15710661},
    x-month = nov,
    x-url = {http://dx.doi.org/10.1016/j.entcs.2012.09.003},
    x-volume = {287},
    xpages = {17--28},
    year = {2012}
}

@article{dvanhorn:Cortesi2011Widening,
    author = {Cortesi, Agostino and Zanioli, Matteo},
    citeulike-article-id = {7884628},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1869209},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.cl.2010.09.001},
    date-added = {2013-05-12 04:28:24},
    day = {21},
    journal = {Comput. Lang. Syst. Struct.},
    priority = {2},
    publisher = {Elsevier Science Publishers B. V.},
    title = {Widening and narrowing operators for abstract interpretation},
    x-abstract = {Abstract Interpretation, one of the most applied techniques for semantics based static analysis of software, is based on two main key-concepts: the correspondence between concrete and abstract semantics through Galois connections/insertions, and the feasibility of a fixed point computation of the abstract semantics, through the fast convergence of widening operators. The latter point is crucial to ensure the scalability of the analysis to large software systems. The aim of this paper is to set the ground for a systematic design of widening and narrowing operators, by comparing the different definitions introduced in the literature and by discussing how to tune them in case of domain abstraction and domains' combination through cartesian and reduced products.},
    x-address = {Amsterdam, The Netherlands, The Netherlands},
    x-doi = {10.1016/j.cl.2010.09.001},
    x-issn = {1477-8424},
    x-month = apr,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1016/j.cl.2010.09.001},
    x-volume = {37},
    xpages = {24--42},
    year = {2011}
}

@inproceedings{dvanhorn:furr:esop06,
    author = {Furr, Michael and Foster, Jeffrey S.},
    booktitle = {European Symposium on Programming (ESOP)},
    citeulike-article-id = {12336353},
    date-added = {2013-05-12 03:52:44},
    priority = {2},
    publisher = {Springer},
    title = {{Polymorphic Type Inference for the JNI}},
    x-address = {Vienna, Austria},
    x-month = mar,
    x-series = {Lecture Notes in Computer Science},
    x-volume = {3924},
    xpages = {309--324},
    year = {2006}
}

@inproceedings{dvanhorn:furr:oops09,
    author = {Furr, Michael and hoon David An, Jong and Foster, Jeffrey S. and Hicks, Michael},
    booktitle = {Object-Oriented Program Languages and Systems (OOPS) Track at ACM Symposium on Applied Computing (SAC)},
    citeulike-article-id = {12336352},
    date-added = {2013-05-12 03:52:44},
    priority = {2},
    title = {{Static Type Inference for Ruby}},
    x-address = {Honolulu, Hawaii},
    x-month = mar,
    xpages = {1859--1866},
    year = {2009}
}

@inproceedings{dvanhorn:khoo:pldi10,
    author = {Khoo, Yit P. and Chang, Bor-Yuh E. and Foster, Jeffrey S.},
    booktitle = {Proceedings of the 2010 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
    citeulike-article-id = {12336351},
    date-added = {2013-05-12 03:52:44},
    priority = {2},
    title = {{Mixing Type Checking and Symbolic Execution}},
    x-address = {Toronto, Canada},
    x-month = jun,
    xpages = {436--447},
    year = {2010}
}

@inproceedings{dvanhorn:chaudhuri:ccs10,
    author = {Chaudhuri, Avik and Foster, Jeffrey S.},
    booktitle = {Proceedings of the 17th ACM Conference on Computer and Communications Security (CCS)},
    citeulike-article-id = {12336350},
    date-added = {2013-05-12 03:52:44},
    priority = {2},
    title = {{Symbolic Security Analysis of Ruby-on-Rails Web Applications}},
    x-address = {Chicago, IL, USA},
    x-month = oct,
    xpages = {585--594},
    year = {2010}
}

@inproceedings{dvanhorn:an:popl11,
    author = {hoon David An, Jong and Chaudhuri, Avik and Foster, Jeffrey S. and Hicks, Michael},
    booktitle = {ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL)},
    citeulike-article-id = {12336349},
    date-added = {2013-05-12 03:52:44},
    priority = {2},
    title = {{Dynamic Inference of Static Types for Ruby}},
    x-address = {Austin, TX, USA},
    x-month = jan,
    xpages = {459--472},
    year = {2011}
}

@inproceedings{dvanhorn:jeon:spsm12,
    author = {Jeon, Jinseong and Micinski, Kristopher K. and Vaughan, Jeffrey A. and Fogel, Ari and Reddy, Nikhilesh and Foster, Jeffrey S. and Millstein, Todd},
    booktitle = {ACM CCS Workshop on Security and Privacy in Smartphones and Mobile Devices (SPSM)},
    citeulike-article-id = {12336348},
    date-added = {2013-05-12 03:52:43},
    priority = {2},
    title = {{Dr. Android and Mr. Hide: Fine-grained Permissions in Android Applications}},
    x-address = {Raleigh, NC, USA},
    x-month = oct,
    xpages = {3--14},
    year = {2012}
}

@inproceedings{dvanhorn:Kohlbecker1987Macrobyexample,
    author = {Kohlbecker, E. E. and Wand, M.},
    booktitle = {Proceedings of the 14th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {190436},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=41632},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/41625.41632},
    date-added = {2013-05-12 01:11:38},
    location = {Munich, West Germany},
    priority = {2},
    publisher = {ACM},
    title = {Macro-by-example: Deriving syntactic transformations from their specifications},
    x-abstract = {This paper presents two new developments. First, it describes a  ” macro-by-example” specification language for syntactic abstractions in Lisp and related languages. This specification language allows a more declarative specification of macros than conventional macro facilities do by giving a better treatment of iteration and mapping constructs. Second, it gives a formal semantics for the language and a derivation of a compiler from the semantics. This derivation is a practical application of semantics-directed compiler development methodology.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/41625.41632},
    x-isbn = {0-89791-215-2},
    x-series = {POPL '87},
    x-url = {http://dx.doi.org/10.1145/41625.41632},
    xpages = {77--84},
    year = {1987}
}

@article{dvanhorn:Felleisen2004Building,
    author = {Felleisen, Matthias and Findler, Robert B. and Flatt, Matthew and Krishnamurthi, Shriram},
    citeulike-article-id = {12336323},
    citeulike-linkout-0 = {http://www.drdobbs.com/architecture-and-design/building-little-languages-with-macros/184405618},
    date-added = {2013-05-12 01:05:39},
    journal = {Dr. Dobb's},
    priority = {2},
    title = {Building Little Languages with Macros},
    x-url = {http://www.drdobbs.com/architecture-and-design/building-little-languages-with-macros/184405618},
    year = {2004}
}

@article{dvanhorn:Culpepper2010Debugging,
    author = {Culpepper, Ryan and Felleisen, Matthias},
    citeulike-article-id = {5333767},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1773163},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.scico.2009.06.001},
    date-added = {2013-05-12 01:01:20},
    day = {17},
    journal = {Sci. Comput. Program.},
    priority = {2},
    publisher = {Elsevier North-Holland, Inc.},
    title = {Debugging hygienic macros},
    x-abstract = {Over the past two decades, Scheme macros have evolved into a powerful {API} for the compiler front end. Like Lisp macros, their predecessors, Scheme macros expand source programs into a small core language; unlike Lisp systems, Scheme macro expanders preserve lexical scoping, and advanced Scheme macro systems handle other important properties such as source location. Using such macros, Scheme programmers now routinely develop the ultimate abstraction: embedded domain-specific programming languages. Unfortunately, a typical Scheme programming environment provides little support for macro development. This lack makes it difficult for programmers to debug their macros and for novices to study the behavior of macros. In response, we have developed a stepping debugger specialized to the concerns of macro expansion. This debugger presents the macro expansion process as a linear rewriting sequence of annotated terms; it graphically illustrates the binding structure of the program as expansion reveals it; and it adapts to the programmer's level of abstraction, hiding details of syntactic forms that the programmer considers built-in.},
    x-address = {Amsterdam, The Netherlands, The Netherlands},
    x-doi = {10.1016/j.scico.2009.06.001},
    x-issn = {0167-6423},
    x-month = jul,
    x-number = {7},
    x-url = {http://dx.doi.org/10.1016/j.scico.2009.06.001},
    x-volume = {75},
    xpages = {496--515},
    year = {2010}
}

@article{dvanhorn:Flanagan1999Componential,
    author = {Flanagan, Cormac and Felleisen, Matthias},
    citeulike-article-id = {4155},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=316703},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/316686.316703},
    date-added = {2013-05-12 00:58:51},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {Componential set-based analysis},
    x-abstract = {Set-based analysis ({SBA}) produces good predictions about the behavior of functional and object-oriented programs. The analysis proceeds by inferring constraints that characterize the data flow relationships of the analyzed program. Experiences with {MrSpidey}, a static debugger based on {SBA}, indicate that {SBA} can adequately deal with programs of up to a couple of thousand lines of code. {SBA} fails, however, to cope with larger programs because it generates systems of constraints that are at least linear, and possibility quadratic, in the size of the analyzed program. This article presents theoretical and practical results concerning methods for reducing the size of constraint systems. The theoretical results include of proof-theoretic characterization of the  observable behavior of constraint systems for program components, and a complete algorithm for deciding the observable equivalence of constraint systems. In the course of this development we establish a close connection between the observable equivalence of constraint systems and the equivalence of regular-tree grammars. We then exploit this connection to adapt a variety of algoirthms for simplifying grammars to the problem of simplifying constraint systems. Based on the resulting algorithms, we have developed componential set-based analysis, a modular and polymorphic variant of {SBA}. Experimental results verify the effectiveness of the simplification algorithms and the componential analysis. The simplified constraint systems are typically an order of  magnitude smaller than the original systems. These reductions in size produce significant gains in the speed of the analysis.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/316686.316703},
    x-issn = {0164-0925},
    x-month = mar,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1145/316686.316703},
    x-volume = {21},
    xpages = {370--416},
    year = {1999}
}

@inproceedings{dvanhorn:Flatt2009Scribble,
    author = {Flatt, Matthew and Barzilay, Eli and Findler, Robert B.},
    booktitle = {Proceedings of the 14th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {5724331},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1596550.1596569},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1596550.1596569},
    date-added = {2013-05-12 00:52:57},
    location = {Edinburgh, Scotland},
    priority = {2},
    publisher = {ACM},
    title = {Scribble: closing the book on ad hoc documentation tools},
    x-abstract = {Scribble is a system for writing library documentation, user guides, and tutorials. It builds on {PLT} Scheme's technology for language extension, and at its heart is a new approach to connecting prose references with library bindings. Besides the base system, we have built Scribble libraries for {JavaDoc}-style {API} documentation, literate programming, and conference papers. We have used Scribble to produce thousands of pages of documentation for {PLT} Scheme; the new documentation is more complete, more accessible, and better organized, thanks in large part to Scribble's flexibility and the ease with which we cross-reference information across levels. This paper reports on the use of Scribble and on its design as both an extension and an extensible part of {PLT} Scheme.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1596550.1596569},
    x-isbn = {978-1-60558-332-7},
    x-series = {ICFP '09},
    x-url = {http://dx.doi.org/10.1145/1596550.1596569},
    xpages = {109--120},
    year = {2009}
}

@incollection{dvanhorn:Chang2013Laziness,
    author = {Chang, Stephen},
    booktitle = {Programming Languages and Systems},
    citeulike-article-id = {12336316},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-37036-6\_5},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-37036-6\_5},
    date-added = {2013-05-12 00:50:43},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Laziness by Need},
    x-abstract = {Lazy functional programming has many benefits that strict functional languages can simulate via lazy data constructors. In recognition, {ML}, Scheme, and other strict functional languages have supported lazy stream programming with delaytt and forcett for several decades. Unfortunately, the manual insertion of delaytt and forcett can be tedious and error-prone.
                            We present a semantics-based refactoring that helps strict programmers manage manual lazy programming. The refactoring uses a static analysis to identify where additional delaytts and forcetts might be needed to achieve the desired simplification and performance benefits, once the programmer has added the initial lazy data constructors. The paper presents a correctness argument for the underlying transformations and some preliminary experiences with a prototype tool implementation.},
    x-doi = {10.1007/978-3-642-37036-6\_5},
    x-editor = {Felleisen, Matthias and Gardner, Philippa},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-37036-6\_5},
    x-volume = {7792},
    xpages = {81--100},
    year = {2013}
}

@inproceedings{dvanhorn:StAmour2012Optimization,
    author = {St-Amour, Vincent and Tobin-Hochstadt, Sam and Felleisen, Matthias},
    booktitle = {OOPSLA '12 Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
    citeulike-article-id = {12336314},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2384629},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2398857.2384629},
    date-added = {2013-05-12 00:46:59},
    priority = {2},
    publisher = {ACM},
    title = {Optimization coaching: optimizers learn to communicate with programmers},
    x-abstract = {Optimizing compilers map programs in high-level languages to high-performance target language code. To most programmers, such a compiler constitutes an impenetrable black box whose inner workings are beyond their understanding. Since programmers often must understand the workings of their compilers to achieve their desired performance goals, they typically resort to various forms of reverse engineering, such as examining compiled code or intermediate forms. Instead, optimizing compilers should engage programmers in a dialog. This paper introduces one such possible form of dialog: optimization coaching. An optimization coach watches while a program is compiled, analyzes the results, generates suggestions for enabling further compiler optimization in the source program, and presents a suitable synthesis of its results to the programmer. We present an evaluation based on case studies, which illustrate how an optimization coach can help programmers achieve optimizations resulting in substantial performance improvements.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2398857.2384629},
    x-issn = {0362-1340},
    x-month = oct,
    x-url = {http://dx.doi.org/10.1145/2398857.2384629},
    xpages = {163--178},
    year = {2012}
}

@article{dvanhorn:Fisher2008Building,
    author = {Fisher, David and Shivers, Olin},
    citeulike-article-id = {12336313},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=2519912},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796808006928},
    date-added = {2013-05-12 00:45:14},
    journal = {Journal of Functional Programming},
    priority = {2},
    title = {Building language towers with Ziggurat},
    x-abstract = {Ziggurat is a meta-language system that permits programmers to develop Scheme-like macros for languages with nontrivial static semantics, such as C or Java (suitably encoded in an S-expression concrete syntax). Ziggurat permits language designers to construct 'towers' of language levels with macros; each level in the tower may have its own static semantics, such as type systems or flow analyses. Crucially, the static semantics of the languages at two adjacent levels in the tower can be connected, allowing improved reasoning power at a higher level to be reflected down to the static semantics of the language level below. We demonstrate the utility of the Ziggurat framework by implementing higher level language facilities as macros on top of an assembly language, utilizing static semantics such as termination analysis, a polymorphic type system and higher order flow analysis.},
    x-doi = {10.1017/s0956796808006928},
    x-issn = {1469-7653},
    x-month = aug,
    x-url = {http://dx.doi.org/10.1017/s0956796808006928},
    x-volume = {18},
    xpages = {707--780},
    year = {2008}
}

@inproceedings{dvanhorn:Culpepper2010Fortifying,
    author = {Culpepper, Ryan and Felleisen, Matthias},
    booktitle = {ICFP '10 Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {12336311},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1863577},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1932681.1863577},
    date-added = {2013-05-12 00:40:14},
    priority = {2},
    publisher = {ACM},
    title = {Fortifying macros},
    x-abstract = {Existing macro systems force programmers to make a choice between clarity of specification and robustness. If they choose clarity, they must forgo validating significant parts of the specification and thus produce low-quality language extensions. If they choose robustness, they must write in a style that mingles the implementation with the specification and therefore obscures the latter. This paper introduces a new language for writing macros. With the new macro system, programmers naturally write robust language extensions using easy-to-understand specifications. The system translates these specifications into validators that detect misuses - including violations of context-sensitive constraints - and automatically synthesize appropriate feedback, eliminating the need for ad hoc validation code.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1932681.1863577},
    x-issn = {0362-1340},
    x-month = sep,
    x-url = {http://dx.doi.org/10.1145/1932681.1863577},
    xpages = {235--246},
    year = {2010}
}

@article{dvanhorn:DBLP:journals/jcss/Wand79,
    author = {Wand, Mitchell},
    citeulike-article-id = {12336308},
    date-added = {2013-05-12 00:28:15},
    journal = {J. Comput. Syst. Sci.},
    priority = {2},
    title = {Final Algebra Semantics and Data Type Extensions},
    x-number = {1},
    x-volume = {19},
    xpages = {27--44},
    year = {1979}
}

@article{dvanhorn:DBLP:journals/iandc/CartwrightCF94,
    author = {Cartwright, Robert and Curien, Pierre-Louis and Felleisen, Matthias},
    citeulike-article-id = {12336307},
    date-added = {2013-05-12 00:25:28},
    journal = {Inf. Comput.},
    priority = {2},
    title = {Fully Abstract Semantics for Observably Sequential Languages},
    x-number = {2},
    x-volume = {111},
    xpages = {297--401},
    year = {1994}
}

@incollection{dvanhorn:Matthews2004Visual,
    author = {Matthews, Jacob and Findler, RobertBruce and Flatt, Matthew and Felleisen, Matthias},
    booktitle = {Rewriting Techniques and Applications},
    citeulike-article-id = {12335584},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-25979-4\_21},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-540-25979-4\_21},
    date-added = {2013-05-11 02:26:22},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {A Visual Environment for Developing {Context-Sensitive} Term Rewriting Systems},
    x-abstract = {Over the past decade, researchers have found context-sensitive term-rewriting semantics to be powerful and expressive tools for modeling programming languages, particularly in establishing type soundness proofs. Unfortunately, developing such semantics is an error-prone activity. To address that problem, we have designed {PLT} Redex, an embedded domain-specific language that helps users interactively create and debug context-sensitive term-rewriting systems. We introduce the tool with a series of examples and discuss our experience using it in courses and developing an operational semantics for {R5RS} Scheme.},
    x-doi = {10.1007/978-3-540-25979-4\_21},
    x-editor = {Oostrom, Vincent},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-25979-4\_21},
    x-volume = {3091},
    xpages = {301--311},
    year = {2004}
}

@inproceedings{dvanhorn:Klein2012Run,
    author = {Klein, Casey and Clements, John and Dimoulas, Christos and Eastlund, Carl and Felleisen, Matthias and Flatt, Matthew and McCarthy, Jay A. and Rafkind, Jon and Hochstadt, Sam T. and Findler, Robert B.},
    booktitle = {POPL '12 Proceedings of the 39th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {12335583},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2103691},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2103621.2103691},
    date-added = {2013-05-11 02:22:53},
    priority = {2},
    publisher = {ACM},
    title = {Run Your Research: On the Effectiveness of Lightweight Mechanization},
    x-abstract = {Formal models serve in many roles in the programming language community. In its primary role, a model communicates the idea of a language design; the architecture of a language tool; or the essence of a program analysis. No matter which role it plays, however, a faulty model doesn't serve its purpose. One way to eliminate flaws from a model is to write it down in a mechanized formal language. It is then possible to state theorems about the model, to prove them, and to check the proofs. Over the past nine years, {PLT} has developed and explored a lightweight version of this approach, dubbed Redex. In a nutshell, Redex is a domain-specific language for semantic models that is embedded in the Racket programming language. The effort of creating a model in Redex is often no more burdensome than typesetting it with {LaTeX}; the difference is that Redex comes with tools for the semantics engineering life cycle.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2103621.2103691},
    x-issn = {0362-1340},
    x-month = jan,
    x-url = {http://dx.doi.org/10.1145/2103621.2103691},
    xpages = {285--296},
    year = {2012}
}

@inproceedings{dvanhorn:Blanchet2003Static,
    author = {Blanchet, Bruno and Cousot, Patrick and Cousot, Radhia and Feret, J{\'{e}}rome and Mauborgne, Laurent and Min{\'{e}}, Antoine and Monniaux, David and Rival, Xavier},
    booktitle = {Proceedings of the ACM SIGPLAN 2003 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {2353363},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=781153},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/781131.781153},
    date-added = {2013-05-09 17:14:07},
    journal = {SIGPLAN Not.},
    location = {San Diego, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {A Static Analyzer for Large Safety-critical Software},
    x-abstract = {We show that abstract interpretation-based static program analysis can be made efficient and precise enough to formally verify a class of properties for a family of large programs with few or no false alarms. This is achieved by refinement of a general purpose static analyzer and later adaptation to particular programs of the family by the end-user through parametrization. This is applied to the proof of soundness of data manipulation operations at the machine level for periodic synchronous safety critical embedded {software.The} main novelties are the design principle of static analyzers by refinement and adaptation through parametrization (Sect. 3 and 7), the symbolic manipulation of expressions to improve the precision of abstract transfer functions (Sect. 6.3), the octagon (Sect. 6.2.2), ellipsoid (Sect. 6.2.3), and decision tree (Sect. 6.2.4) abstract domains, all with sound handling of rounding errors in oating point computations, widening strategies (with thresholds: Sect. 7.1.2, delayed: Sect. 7.1.3) and the automatic determination of the parameters (parametrized packing: Sect. 7.2).},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/781131.781153},
    x-isbn = {1-58113-662-5},
    x-issn = {0362-1340},
    x-month = may,
    x-number = {5},
    x-series = {PLDI '03},
    x-url = {http://dx.doi.org/10.1145/781131.781153},
    x-volume = {38},
    xpages = {196--207},
    year = {2003}
}

@incollection{dvanhorn:Monniaux2000Abstract,
    author = {Monniaux, David},
    booktitle = {Static Analysis},
    citeulike-article-id = {12333705},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-45099-3\_17},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-540-45099-3\_17},
    date-added = {2013-05-09 16:02:58},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Abstract Interpretation of Probabilistic Semantics},
    x-abstract = {Following earlier models, we lift standard deterministic and nondeterministic semantics of imperative programs to probabilistic semantics. This semantics allows for random external inputs of known or unknown probability and random number generators.
                            We then propose a method for analysing programs according to this semantics, in the general framework of abstract interpretation. This method lifts an  ” ordinary” abstract lattice, for non-probabilistic programs, to one suitable for probabilistic programs.
                            Our construction is highly generic. We discuss the influence of certain parameters on the precision of the analysis, basing ourselves on experimental results.},
    x-doi = {10.1007/978-3-540-45099-3\_17},
    x-editor = {Palsberg, Jens},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-45099-3\_17},
    x-volume = {1824},
    xpages = {322--339},
    year = {2000}
}

@incollection{dvanhorn:Cousot2012Probabilistic,
    author = {Cousot, Patrick and Monerau, Michael},
    booktitle = {Programming Languages and Systems},
    citeulike-article-id = {12333704},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-28869-2\_9},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-28869-2\_9},
    date-added = {2013-05-09 16:01:49},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Probabilistic Abstract Interpretation},
    x-abstract = {Abstract interpretation has been widely used for verifying properties of computer systems. Here, we present a way to extend this framework to the case of probabilistic systems.
                          The probabilistic abstraction framework that we propose allows us to systematically lift any classical analysis or verification method to the probabilistic setting by separating in the program semantics the probabilistic behavior from the (non-)deterministic behavior. This separation provides new insights for designing novel probabilistic static analyses and verification methods.
                          We define the concrete probabilistic semantics and propose different ways to abstract them. We provide examples illustrating the expressiveness and effectiveness of our approach.},
    x-doi = {10.1007/978-3-642-28869-2\_9},
    x-editor = {Seidl, Helmut},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-28869-2\_9},
    x-volume = {7211},
    xpages = {169--193},
    year = {2012}
}

@inproceedings{dvanhorn:Kiselyov2009Embedded,
    author = {Kiselyov, Oleg and Shan, Chung C.},
    booktitle = {Proceedings of the IFIP TC 2 Working Conference on Domain-Specific Languages},
    chapter = {17},
    citeulike-article-id = {8330350},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1575971},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-642-03034-5\_17},
    citeulike-linkout-2 = {http://www.springerlink.com/content/e03504147589x005},
    date-added = {2013-05-08 21:39:03},
    location = {Oxford, UK},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Embedded Probabilistic Programming},
    x-abstract = {Two general techniques for implementing a domain-specific language ({DSL}) with less overhead are the <em>finally-tagless</em> embedding of object programs and the <em>direct-style</em> representation of side effects. We use these techniques to build a {DSL} for <em>probabilistic programming</em> , for expressing countable probabilistic models and performing exact inference and importance sampling on them. Our language is embedded as an ordinary {OCaml} library and represents probability distributions as ordinary {OCaml} programs. We use delimited continuations to reify probabilistic programs as lazy search trees, which inference algorithms may traverse without imposing any interpretive overhead on deterministic parts of a model. We thus take advantage of the existing {OCaml} implementation to achieve competitive performance and ease of use. Inference algorithms can easily be embedded in probabilistic programs themselves.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-03034-5\_17},
    x-isbn = {978-3-642-03033-8},
    x-series = {DSL '09},
    x-url = {http://dx.doi.org/10.1007/978-3-642-03034-5\_17},
    x-volume = {5658},
    xpages = {360--384},
    year = {2009}
}

@inproceedings{dvanhorn:WSG11,
    author = {Wingate, David and Stuhlm\"{u}ller, Andreas and Goodman, Noah D.},
    booktitle = {Proc. of the 14th Artificial Intelligence and Statistics},
    citeulike-article-id = {12331919},
    citeulike-linkout-0 = {http://stanford.edu/\~{}ngoodman/papers/WSG-AIStats11.pdf},
    date-added = {2013-05-08 21:34:43},
    priority = {2},
    title = {Lightweight Implementations of Probabilistic Programming Languages Via Transformational Compilation},
    x-url = {http://stanford.edu/\~{}ngoodman/papers/WSG-AIStats11.pdf},
    year = {2011}
}

@inproceedings{dvanhorn:Goodman2008Church,
    author = {Goodman, Noah D. and Mansinghka, Vikash K. and Roy, Daniel and Bonawitz, Keith and Tenenbaum, Joshua B.},
    booktitle = {Uncertainty in Artificial Intelligence},
    citeulike-article-id = {2805713},
    citeulike-linkout-0 = {http://web.mit.edu/droy/www/papers/GooManRoyBonTenUAI2008.pdf},
    date-added = {2013-05-08 21:32:05},
    keywords = {church, generative, models, non-parametric},
    priority = {2},
    title = {Church: a language for generative models},
    x-url = {http://web.mit.edu/droy/www/papers/GooManRoyBonTenUAI2008.pdf},
    year = {2008}
}

@inproceedings{dvanhorn:TobinHochstadt2011Languages,
    author = {Tobin-Hochstadt, Sam and St-Amour, Vincent and Culpepper, Ryan and Flatt, Matthew and Felleisen, Matthias},
    booktitle = {Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {9534653},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1993514},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1993498.1993514},
    date-added = {2013-05-08 05:53:42},
    location = {San Jose, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {Languages as libraries},
    x-abstract = {Programming language design benefits from constructs for extending the syntax and semantics of a host language. While C's string-based macros empower programmers to introduce notational shorthands, the parser-level macros of Lisp encourage experimentation with domain-specific languages. The Scheme programming language improves on Lisp with macros that respect lexical scope.  The design of Racket---a descendant of Scheme---goes even further with the introduction of a full-fledged interface to the static semantics of the language. A Racket extension programmer can thus add constructs that are indistinguishable from "native" notation, large and complex embedded domain-specific languages, and even optimizing transformations for the compiler backend. This power to experiment with language design has been used to create a series of sub-languages for programming with first-class classes and modules, numerous languages for implementing the Racket system, and the creation of a complete and fully integrated typed sister language to Racket's untyped base language. This paper explains Racket's language extension {API} via an implementation of a small typed sister language. The new language provides a rich type system that accommodates the idioms of untyped Racket. Furthermore, modules in this typed language can safely exchange values with untyped modules. Last but not least, the implementation includes a type-based optimizer that achieves promising speedups. Although these extensions are complex, their Racket implementation is just a library, like any other library, requiring no changes to the Racket implementation.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1993498.1993514},
    x-isbn = {978-1-4503-0663-8},
    x-issn = {0362-1340},
    x-month = jun,
    x-series = {PLDI},
    x-url = {http://dx.doi.org/10.1145/1993498.1993514},
    xpages = {132--141},
    year = {2011}
}

@book{dvanhorn:Kaufmann2000ComputerAided,
    author = {Kaufmann, Matt and Moore, J. Strother and Manolios, Panagiotis},
    citeulike-article-id = {6014020},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=555902},
    date-added = {2013-04-13 23:29:35},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{Computer-Aided} Reasoning: An Approach},
    x-abstract = {From the {Publisher:An} Approach {Computer-Aided} Reasoning: An Approach is a textbook introduction to computer-aided reasoning. It can be used in graduate and upper-division undergraduate courses on software engineering or formal methods. It is also suitable in conjunction with other books in courses on hardware design, discrete mathematics, or theory, especially courses stressing formalism, rigor, or mechanized support. It is also appropriate for courses on artificial intelligence or automated reasoning and as a reference for business and industry.  Current hardware and software systems are often very complex and the trend is towards increased complexity. Many of these systems are of critical importance; therefore making sure that they behave as expected is also of critical importance. By modeling computing systems mathematically, we obtain models that we can prove behave correctly. The complexity of computing systems makes such proofs very long, complicated, and error-prone. To further increase confidence in our reasoning, we can use a computer program to check our proofs and even to automate some of their construction.  In this book we present:  A practical functional programming language closely related to Common Lisp which is used to define functions (which can model computing systems) and to make assertions about defined functions; A formal logic in which defined functions correspond to axioms; the logic is first-order, includes induction, and allows us to prove theorems about the functions;  The computer-aided reasoning system {ACL2}, which includes the programming language, the logic, and mechanical support for the proof process. The {ACL2} system hasbeen successfully applied to projects of commercial interest, including microprocessor, modeling, hardware verification, microcode verification, and software verification. This book gives a methodology for modeling computing systems formally and for reasoning about those models with mechanized assistance. The practicality of computer-aided reasoning is further demonstrated in the companion book, {Computer-Aided} Reasoning: {ACL2} Case Studies.  Approximately 140 exercises are distributed throughout the book. Additional material is freely available from the {ACL2} home page on the Web, http://www.cs.utexas.edu/users/moore/ac12, including solutions to the exercises, additional exercises, case studies from the companion book, research papers, and the {ACL2} system with detailed documentation.  {ACL2} Case Studies {Computer-Aided} Reasoning: {ACL2} Case Studies illustrates how the computer-aided reasoning system {ACL2} can be used in productive and innovative ways to design, build, and maintain hardware and software systems. Included here are technical papers written by twenty-one contributors that report on self-contained case studies, some of which are sanitized industrial projects. The papers deal with a wide variety of ideas, including floating-point arithmetic, microprocessor simulation, model checking, symbolic trajectory evaluation, compilation, proof checking, real analysis, and several others.  {Computer-Aided} Reasoning: {ACL2} Case Studies is meant for two audiences: those looking for innovative ways to design, build, and maintain hardware and software systems faster and more reliably, and those wishing to learn how to do this. The former audience includes project managers and students in survey-oriented courses. The latter audience includes students and professionals pursuing rigorous approaches to hardware and software engineering or formal methods. {Computer-Aided} Reasoning: {ACL2} Case Studies can be used in graduate and upper-division undergraduate courses on Software Engineering, Formal Methods, Hardware Design, Theory of Computation, Artificial Intelligence, and Automated Reasoning.  The book is divided into two parts. Part I begins with a discussion of the effort involved in using {ACL2}. It also contains a brief introduction to the {ACL2} logic and its mechanization, which is intended to give the reader sufficient background to read the case studies. A more thorough, textbook introduction to {ACL2} may be found in the companion book, {Computer-Aided} Reasoning: An Approach.  The heart of the book is Part {II}, where the case studies are presented. The case studies contain exercises whose solutions are on the Web. In addition, the complete {ACL2} scripts necessary to formalize the models and prove all the properties discussed are on the Web. For example, when we say that one of the case studies formalizes a floating-point multiplier and proves it correct, we mean that not only can you read an English description of the model and how it was proved correct, but you can obtain the entire formal content of the project and replay the proofs, if you wish, with your copy of {ACL2}. {ACL2} may be obtained from its home page, http://www.cs.utexas.edu/users/moore/ac12. The results reported in each case study, as {ACL2} input scripts, as well as exercise solutions for both books, are available from this page.},
    x-address = {Norwell, MA, USA},
    x-isbn = {0792377443},
    x-url = {http://portal.acm.org/citation.cfm?id=555902},
    year = {2000}
}

@inproceedings{dvanhorn:Proulx2006Design,
    author = {Proulx, Viera K. and Gray, Kathryn E.},
    booktitle = {Proceedings of the 37th SIGCSE technical symposium on Computer science education},
    citeulike-article-id = {12268176},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1121341.1121431},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1121341.1121431},
    date-added = {2013-04-13 22:07:37},
    location = {Houston, Texas, USA},
    priority = {2},
    publisher = {ACM},
    title = {Design of class hierarchies: an introduction to {OO} program design},
    x-abstract = {We report on the experience of teaching an introductory second semester computer science course on Fundamentals of Computer Science that uses our curriculum How to Design Class Hierarchies and the {ProfessorJ} programming languages implemented within the {DrScheme} programming {environment.This} comprehensive curriculum for an introductory course focuses on principled design of class based programs in an object-oriented language (Java) with a carefully structured gradual increase in the complexity of the class structure and the programming {language.The} curriculum includes extensive lecture notes, programming assignments, closed lab plans, exams, and the first part of a textbook. The curriculum is supported by a programming environment {ProfessorJ} with a series of gradually more complex teaching languages that support a novice learner. The pedagogy focuses on teaching the students problem solving and design skills that transcend the study of programming. The organization of the topics draws its strength from the theory of programming languages by focusing on the structure of data rather than on algorithms, user interactions, or arcane details of the programming language syntax.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1121341.1121431},
    x-isbn = {1-59593-259-3},
    x-series = {SIGCSE '06},
    x-url = {http://dx.doi.org/10.1145/1121341.1121431},
    xpages = {288--292},
    year = {2006}
}

@article{dvanhorn:Hsia2005Taming,
    author = {Hsia, James I. and Simpson, Elspeth and Smith, Daniel and Cartwright, Robert},
    citeulike-article-id = {12262146},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1047459},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1047124.1047459},
    date-added = {2013-04-12 22:30:09},
    journal = {SIGCSE Bull.},
    priority = {2},
    publisher = {ACM},
    title = {Taming Java for the classroom},
    x-abstract = {Java is the canonical language for teaching introductory programming, but its complex syntax and abundance of constructs are difficult for beginners to learn. This paper shows how object-oriented programming in Java can be made more accessible to beginners through the use of "language levels", a hierarchy of progressively richer subsets of Java. This hierarchy is implemented as an extension of the {DrJava} pedagogic programming environment.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1047124.1047459},
    x-issn = {0097-8418},
    x-month = feb,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1145/1047124.1047459},
    x-volume = {37},
    xpages = {327--331},
    year = {2005}
}

@inproceedings{dvanhorn:Bruce2001Library,
    author = {Bruce, Kim B. and Danyluk, Andrea and Murtagh, Thomas},
    booktitle = {Proceedings of the thirty-second SIGCSE technical symposium on Computer Science Education},
    citeulike-article-id = {2817546},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=364527},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/366413.364527},
    date-added = {2013-04-12 22:29:31},
    journal = {SIGCSE Bull.},
    location = {Charlotte, North Carolina, USA},
    priority = {2},
    publisher = {ACM},
    title = {A library to support a graphics-based object-first approach to {CS} 1},
    x-abstract = {In this paper we describe a library we have developed that supports an "{OO}-from-the-beginning" approach to {CS} 1. The use of real graphics "objects" and event-driven programming are important components of our approach. The design of interactive graphical programs helps students to both use objects and write methods early while designing and implementing interesting programs.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/366413.364527},
    x-isbn = {1-58113-329-4},
    x-issn = {0097-8418},
    x-month = mar,
    x-number = {1},
    x-series = {SIGCSE '01},
    x-url = {http://dx.doi.org/10.1145/366413.364527},
    x-volume = {33},
    xpages = {6--10},
    year = {2001}
}

@inproceedings{dvanhorn:Alphonce2003Using,
    author = {Alphonce, Carl and Ventura, Phil},
    booktitle = {Companion of the 18th annual ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
    citeulike-article-id = {12262145},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=949391},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/949344.949391},
    date-added = {2013-04-12 22:29:16},
    location = {Anaheim, CA, USA},
    priority = {2},
    publisher = {ACM},
    title = {Using graphics to support the teaching of fundamental object-oriented principles in {CS1}},
    x-abstract = {Teaching object-oriented programming in {CS1} is hard. Keeping the attention of {CS1} students is perhaps even harder. In our experience the former can be done successfully with very satisfying results by focusing on the fundamental principles of object-orientation, such as inheritance, polymorphism and encapsulation. The latter can be done by having students create graphical event-driven programs. Care must be taken, however, since teaching graphics can easily distract students and certainly takes time away from the fundamentals being taught. We use Java as a vehicle for {OO} instruction, but rather than expose {CS1} students to the intricacies of Swing we employ an elegant and small graphics package called {NGP}. {NGP} allows students to create event-driven graphical programs using only inheritance and method overriding. We describe how we use {NGP} to enhance rather than detract from our teaching of fundamental {OO} principles.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/949344.949391},
    x-isbn = {1-58113-751-6},
    x-series = {OOPSLA '03},
    x-url = {http://dx.doi.org/10.1145/949344.949391},
    xpages = {156--161},
    year = {2003}
}

@article{dvanhorn:Chakravarty2004Risks,
    author = {Chakravarty, Manuel M. T. and Keller, Gabriele},
    citeulike-article-id = {10035586},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=967497},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/S0956796803004805},
    date-added = {2013-04-12 21:42:51},
    journal = {J. Funct. Program.},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {The risks and benefits of teaching purely functional programming in first year},
    x-abstract = {We argue that teaching purely functional programming as such in freshman courses is detrimental to both the curriculum as well as to promoting the paradigm. Instead, we need to focus on the more general aims of teaching elementary techniques of programming and essential concepts of computing. We support this viewpoint with experience gained during several semesters of teaching large first-year classes (up to 600 students) in Haskell. These classes consisted of computer science students as well as students from other disciplines. We have systematically gathered student feedback by conducting surveys after each semester. This article contributes an approach to the use of modern functional languages in first year courses and, based on this, advocates the use of functional languages in this setting.},
    x-address = {New York, NY, USA},
    x-doi = {10.1017/S0956796803004805},
    x-issn = {0956-7968},
    x-month = jan,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1017/S0956796803004805},
    x-volume = {14},
    xpages = {113--123},
    year = {2004}
}

@inproceedings{dvanhorn:Ragde2008Chilling,
    author = {Ragde, Prabhakar},
    booktitle = {Proceedings of the 2008 international workshop on Functional and declarative programming in education},
    citeulike-article-id = {12262127},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1411263},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1411260.1411263},
    date-added = {2013-04-12 21:39:54},
    location = {Victoria, BC, Canada},
    priority = {2},
    publisher = {ACM},
    title = {The chilling descent: making the transition to a conventional curriculum},
    x-abstract = {The transitional course following an introduction to computer science using functional programming must prepare students to handle a traditional, imperative-based curriculum while ensuring that the lessons of the introductory course are not lost. This paper describes the design of a second course using both Scheme and C, and examines the rationales behind the major design decisions.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1411260.1411263},
    x-isbn = {978-1-60558-068-5},
    x-series = {FDPE '08},
    x-url = {http://dx.doi.org/10.1145/1411260.1411263},
    xpages = {13--20},
    year = {2008}
}

@article{dvanhorn:Bloch2000Scheme,
    author = {Bloch, Stephen A.},
    citeulike-article-id = {12262126},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=364177},
    date-added = {2013-04-12 21:37:51},
    journal = {J. Comput. Sci. Coll.},
    priority = {2},
    publisher = {Consortium for Computing Sciences in Colleges},
    title = {Scheme and Java in the first year},
    x-abstract = {An abstract is not available.},
    x-address = {USA},
    x-issn = {1937-4771},
    x-month = apr,
    x-number = {5},
    x-url = {http://portal.acm.org/citation.cfm?id=364177},
    x-volume = {15},
    xpages = {157--165},
    year = {2000}
}

@article{dvanhorn:Bloch2008Teach,
    author = {Bloch, Stephen},
    citeulike-article-id = {12262125},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1352639},
    date-added = {2013-04-12 21:34:40},
    journal = {J. Comput. Sci. Coll.},
    priority = {2},
    publisher = {Consortium for Computing Sciences in Colleges},
    title = {Teach Scheme, reach Java: introducing object-oriented programming without drowning in syntax},
    x-abstract = {We'll discuss a multi-lingual approach to the first year of programming, starting in a simple, consistent language like Scheme to get across essential concepts (e.g. variables, functions, parameters, data types, composition, testing, conditionals, classes with fields, polymorphism, recursion) and a principled methodology of programming. We'll demonstrate how the same topics can be subsequently covered in a more mainstream, but more complex, language such as Java, taking advantage of students' preparation during the Scheme phase of the course. Participants will be invited to a week-long, {NSF}-funded workshop in Summer 2008, which goes into much more depth on technical, classroom, and curriculum issues [{TSRJ08}].},
    x-address = {USA},
    x-issn = {1937-4771},
    x-month = may,
    x-number = {5},
    x-url = {http://portal.acm.org/citation.cfm?id=1352639},
    x-volume = {23},
    xpages = {65--67},
    year = {2008}
}

@article{dvanhorn:Kolling2003,
    author = {K\"{o}lling, Michael and Quig, Bruce and Patterson, Andrew and Rosenberg, John},
    citeulike-article-id = {493692},
    citeulike-linkout-0 = {http://www.bluej.org/papers/2003-12-CSEd-bluej.pdf},
    date-added = {2013-04-12 15:45:21},
    journal = {Journal of Computer Science Education},
    keywords = {bluej},
    priority = {2},
    title = {The {BlueJ} system and its pedagogy},
    x-month = dec,
    x-number = {4},
    x-url = {http://www.bluej.org/papers/2003-12-CSEd-bluej.pdf},
    x-volume = {13},
    year = {2003}
}

@article{dvanhorn:Allen2002DrJava,
    author = {Allen, Eric and Cartwright, Robert and Stoler, Brian},
    citeulike-article-id = {1894872},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1089197},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/563517.563395},
    date-added = {2013-04-12 15:37:34},
    journal = {SIGCSE Bull.},
    priority = {2},
    publisher = {ACM},
    title = {{DrJava}: a lightweight pedagogic environment for Java},
    x-abstract = {{DrJava} is a pedagogic programming environment for Java that enables students to focus on designing programs, rather than learning how to use the environment. The environment provides a simple interface based on a "read-eval-print loop" that enables a programmer to develop, test, and debug Java programs in an interactive, incremental fashion. This paper gives an overview of {DrJava} including its pedagogic rationale, functionality, and implementation.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/563517.563395},
    x-issn = {0097-8418},
    x-month = feb,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1145/563517.563395},
    x-volume = {34},
    xpages = {137--141},
    year = {2002}
}

@inproceedings{dvanhorn:Gray2003ProfessorJ,
    author = {Gray, Kathryn E. and Flatt, Matthew},
    booktitle = {Companion of the 18th annual ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
    citeulike-article-id = {190418},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=949394},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/949344.949394},
    date-added = {2013-04-12 15:32:37},
    location = {Anaheim, CA, USA},
    priority = {2},
    publisher = {ACM},
    title = {{ProfessorJ}: a gradual introduction to Java through language levels},
    x-abstract = {In the second-semester programming course at the University of Utah, we have observed that our students suffer unnecessarily from a mismatch between the course content and the programming environment. The course is typical, in that it exposes students to Java a little at a time. The programming environments are also typical, in that they report compilation and run-time errors in the jargon of professional programmers who use the full Java language. As a result, students rely heavily on teaching assistants to interpret error messages, and valuable classroom time is wasted on syntactic {diversions.ProfessorJ} is our new programming environment that remedies this problem. Like other pedagogical environments, such as {BlueJ} and {DrJava}, {ProfessorJ} presents the student with a simplified interface to the Java compiler and virtual machine. Unlike existing environments, {ProfessorJ} tailors the Java language and error messages to the students' needs. Since their needs evolve through the course, {ProfessorJ} offers several language levels, from Beginner Java to Full Java.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/949344.949394},
    x-isbn = {1-58113-751-6},
    x-series = {OOPSLA '03},
    x-url = {http://dx.doi.org/10.1145/949344.949394},
    xpages = {170--177},
    year = {2003}
}

@article{dvanhorn:Felleisen2004Structure,
    author = {Felleisen, Matthias and Findler, Robert B. and Flatt, Matthew and Krishnamurthi, Shriram},
    citeulike-article-id = {1398},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=997813},
    citeulike-linkout-1 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=227683},
    citeulike-linkout-2 = {http://dx.doi.org/10.1017/s0956796804005076},
    date-added = {2013-04-12 15:25:50},
    journal = {Journal of Functional Programming},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {The structure and interpretation of the computer science curriculum},
    x-abstract = {Twenty years ago Abelson and Sussman\&apos;s Structure and Interpretation of Computer Programs radically changed the intellectual landscape of introductory computing courses. Instead of teaching some currently fashionable programming language, it employed Scheme and functional programming to teach important ideas. Introductory courses based on the book showed up around the world and made Scheme and functional programming popular. Unfortunately, these courses quickly disappeared again due to shortcomings of the book and the whimsies of Scheme. Worse, the experiment left people with a bad impression of Scheme and functional programming in general. In this pearl, we propose an alternative role for functional programming in the first-year curriculum. Specifically, we present a framework for discussing the first-year curriculum and, based on it, the design rationale for our book and course, dubbed How to Design Programs. The approach emphasizes the systematic design of programs. Experience shows that it works extremely well as a preparation for a course on object-oriented programming.},
    x-address = {New York, NY, USA},
    x-doi = {10.1017/s0956796804005076},
    x-issn = {1469-7653},
    x-month = jun,
    x-number = {4},
    x-url = {http://dx.doi.org/10.1017/s0956796804005076},
    x-volume = {14},
    xpages = {365--378},
    year = {2004}
}

@inproceedings{dvanhorn:Goodman2013Principles,
    author = {Goodman, Noah D.},
    booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {12007845},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429069.2429117},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429117},
    date-added = {2013-02-09 02:45:35},
    location = {Rome, Italy},
    priority = {2},
    publisher = {ACM},
    title = {The principles and practice of probabilistic programming},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429117},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL '13},
    x-url = {http://dx.doi.org/10.1145/2429069.2429117},
    xpages = {399--402},
    year = {2013}
}

@inproceedings{dvanhorn:Fournet2013Fully,
    author = {Fournet, Cedric and Swamy, Nikhil and Chen, Juan and Dagand, Pierre E. and Strub, Pierre Y. and Livshits, Benjamin},
    booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {12007844},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429069.2429114},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429114},
    date-added = {2013-02-09 02:37:57},
    location = {Rome, Italy},
    priority = {2},
    publisher = {ACM},
    title = {Fully abstract compilation to {JavaScript}},
    x-abstract = {Many tools allow programmers to develop applications in high-level languages and deploy them in web browsers via compilation to {JavaScript}. While practical and widely used, these compilers are ad hoc: no guarantee is provided on their correctness for whole programs, nor their security for programs executed within arbitrary {JavaScript} contexts. This paper presents a compiler with such guarantees. We compile an {ML}-like language with higher-order functions and references to {JavaScript}, while preserving all source program properties. Relying on type-based invariants and applicative bisimilarity, we show full abstraction: two programs are equivalent in all source contexts if and only if their wrapped translations are equivalent in all {JavaScript} contexts. We evaluate our compiler on sample programs, including a series of secure libraries.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429114},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL '13},
    x-url = {http://dx.doi.org/10.1145/2429069.2429114},
    xpages = {371--384},
    year = {2013}
}

@inproceedings{dvanhorn:Gaboardi2013Linear,
    author = {Gaboardi, Marco and Haeberlen, Andreas and Hsu, Justin and Narayan, Arjun and Pierce, Benjamin C.},
    booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {12007843},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429069.2429113},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429113},
    date-added = {2013-02-09 02:37:43},
    location = {Rome, Italy},
    priority = {2},
    publisher = {ACM},
    title = {Linear dependent types for differential privacy},
    x-abstract = {Differential privacy offers a way to answer queries about sensitive information while providing strong, provable privacy guarantees, ensuring that the presence or absence of a single individual in the database has a negligible statistical effect on the query's result. Proving that a given query has this property involves establishing a bound on the query's sensitivity---how much its result can change when a single record is added or removed. A variety of tools have been developed for certifying that a given query differentially private. In one approach, Reed and Pierce [34] proposed a functional programming language, Fuzz, for writing differentially private queries. Fuzz uses linear types to track sensitivity and a probability monad to express randomized computation; it guarantees that any program with a certain type is differentially private. Fuzz can successfully verify many useful queries. However, it fails when the sensitivity analysis depends on values that are not known statically. We present {DFuzz}, an extension of Fuzz with a combination of linear indexed types and lightweight dependent types. This combination allows a richer sensitivity analysis that is able to certify a larger class of queries as differentially private, including ones whose sensitivity depends on runtime information. As in Fuzz, the differential privacy guarantee follows directly from the soundness theorem of the type system. We demonstrate the enhanced expressivity of {DFuzz} by certifying differential privacy for a broad class of iterative algorithms that could not be typed previously.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429113},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL '13},
    x-url = {http://dx.doi.org/10.1145/2429069.2429113},
    xpages = {357--370},
    year = {2013}
}

@inproceedings{dvanhorn:Jensen2013Highlevel,
    author = {Jensen, Jonas B. and Benton, Nick and Kennedy, Andrew},
    booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {12007839},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429069.2429105},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429105},
    date-added = {2013-02-09 02:33:52},
    location = {Rome, Italy},
    priority = {2},
    publisher = {ACM},
    title = {High-level separation logic for low-level code},
    x-abstract = {Separation logic is a powerful tool for reasoning about structured, imperative programs that manipulate pointers. However, its application to unstructured, lower-level languages such as assembly language or machine code remains challenging. In this paper we describe a separation logic tailored for this purpose that we have applied to x86 machine-code programs. The logic is built from an assertion logic on machine states over which we construct a specification logic that encapsulates uses of frames and step indexing. The traditional notion of Hoare triple is not applicable directly to unstructured machine code, where code and data are mixed together and programs do not in general run to completion, so instead we adopt a continuation-passing style of specification with preconditions alone. Nevertheless, the range of primitives provided by the specification logic, which include a higher-order frame connective, a novel read-only frame connective, and a 'later' modality, support the definition of derived forms to support structured-programming-style reasoning for common cases, in which standard rules for Hoare triples are derived as lemmas. Furthermore, our encoding of scoped assembly-language labels lets us give definitions and proof rules for powerful assembly-language 'macros' such as while loops, conditionals and procedures. We have applied the framework to a model of sequential x86 machine code built entirely within the Coq proof assistant, including tactic support based on computational reflection.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429105},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL '13},
    x-url = {http://dx.doi.org/10.1145/2429069.2429105},
    xpages = {301--314},
    year = {2013}
}

@inproceedings{dvanhorn:Krishnamurthi2013From,
    author = {Krishnamurthi, Shriram},
    booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {12007838},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429069.2429097},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429097},
    date-added = {2013-02-09 02:26:11},
    location = {Rome, Italy},
    priority = {2},
    publisher = {ACM},
    title = {From principles to programming languages (and back)},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429097},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL '13},
    x-url = {http://dx.doi.org/10.1145/2429069.2429097},
    xpages = {233--234},
    year = {2013}
}

@inproceedings{dvanhorn:Hur2013Power,
    author = {Hur, Chung K. and Neis, Georg and Dreyer, Derek and Vafeiadis, Viktor},
    booktitle = {Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {12007837},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429069.2429093},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429093},
    date-added = {2013-02-09 02:24:13},
    location = {Rome, Italy},
    priority = {2},
    publisher = {ACM},
    title = {The Power of Parameterization in Coinductive Proof},
    x-abstract = {Coinduction is one of the most basic concepts in computer science. It is therefore surprising that the commonly-known lattice-theoretic accounts of the principles underlying coinductive proofs are lacking in two key respects: they do not support compositional reasoning (i.e. breaking proofs into separate pieces that can be developed in isolation), and they do not support incremental reasoning (i.e. developing proofs interactively by starting from the goal and generalizing the coinduction hypothesis repeatedly as necessary). In this paper, we show how to support coinductive proofs that are both compositional and incremental, using a dead simple construction we call the parameterized greatest fixed point. The basic idea is to parameterize the greatest fixed point of interest over the accumulated knowledge of "the proof so far". While this idea has been proposed before, by Winskel in 1989 and by Moss in 2001, neither of the previous accounts suggests its general applicability to improving the state of the art in interactive coinductive proof. In addition to presenting the lattice-theoretic foundations of parameterized coinduction, demonstrating its utility on representative examples, and studying its composition with "up-to" techniques, we also explore its mechanization in proof assistants like Coq and Isabelle. Unlike traditional approaches to mechanizing coinduction (e.g. Coq's cofix), which employ syntactic "guardedness checking", parameterized coinduction offers a semantic account of guardedness. This leads to faster and more robust proof development, as we demonstrate using our new Coq library, Paco.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429093},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL '13},
    x-url = {http://dx.doi.org/10.1145/2429069.2429093},
    xpages = {193--206},
    year = {2013}
}

@inproceedings{dvanhorn:Atkey2013Abstraction,
    author = {Atkey, Robert and Johann, Patricia and Kennedy, Andrew},
    booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {12007836},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429069.2429082},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429082},
    date-added = {2013-02-09 02:21:04},
    location = {Rome, Italy},
    priority = {2},
    publisher = {ACM},
    title = {Abstraction and invariance for algebraically indexed types},
    x-abstract = {Reynolds' relational parametricity provides a powerful way to reason about programs in terms of invariance under changes of data representation. A dazzling array of applications of Reynolds' theory exists, exploiting invariance to yield "free theorems", non-inhabitation results, and encodings of algebraic datatypes. Outside computer science, invariance is a common theme running through many areas of mathematics and physics. For example, the area of a triangle is unaltered by rotation or flipping. If we scale a triangle, then we scale its area, maintaining an invariant relationship between the two. The transformations under which properties are invariant are often organised into groups, with the algebraic structure reflecting the composability and invertibility of transformations. In this paper, we investigate programming languages whose types are indexed by algebraic structures such as groups of geometric transformations. Other examples include types indexed by principals--for information flow security--and types indexed by distances--for analysis of analytic uniform continuity properties. Following Reynolds, we prove a general Abstraction Theorem that covers all these instances. Consequences of our Abstraction Theorem include free theorems expressing invariance properties of programs, type isomorphisms based on invariance properties, and non-definability results indicating when certain algebraically indexed types are uninhabited or only inhabited by trivial programs. We have fully formalised our framework and most examples in Coq.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429082},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL '13},
    x-url = {http://dx.doi.org/10.1145/2429069.2429082},
    xpages = {87--100},
    year = {2013}
}

@inproceedings{dvanhorn:Unno2013Automating,
    author = {Unno, Hiroshi and Terauchi, Tachio and Kobayashi, Naoki},
    booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {12007831},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429069.2429081},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429081},
    date-added = {2013-02-09 02:17:57},
    location = {Rome, Italy},
    priority = {2},
    publisher = {ACM},
    title = {Automating relatively complete verification of higher-order functional programs},
    x-abstract = {We present an automated approach to relatively completely verifying safety (i.e., reachability) property of higher-order functional programs. Our contribution is two-fold. First, we extend the refinement type system framework employed in the recent work on (incomplete) automated higher-order verification by drawing on the classical work on relatively complete "Hoare logic like" program logic for higher-order procedural languages. Then, by adopting the recently proposed techniques for solving constraints over quantified first-order logic formulas, we develop an automated type inference method for the type system, thereby realizing an automated relatively complete verification of higher-order programs.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429081},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL '13},
    x-url = {http://dx.doi.org/10.1145/2429069.2429081},
    xpages = {75--86},
    year = {2013}
}

@inproceedings{dvanhorn:Tate2013Sequential,
    author = {Tate, Ross},
    booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {12007828},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429069.2429074},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429074},
    date-added = {2013-02-09 02:03:58},
    location = {Rome, Italy},
    priority = {2},
    publisher = {ACM},
    title = {The sequential semantics of producer effect systems},
    x-abstract = {Effects are fundamental to programming languages. Even the lambda calculus has effects, and consequently the two famous evaluation strategies produce different semantics. As such, much research has been done to improve our understanding of effects. Since Moggi introduced monads for his computational lambda calculus, further generalizations have been designed to formalize increasingly complex computational effects, such as indexed monads followed by layered monads followed by parameterized monads. This succession prompted us to determine the most general formalization possible. In searching for this formalization we came across many surprises, such as the insufficiencies of arrows, as well as many unexpected insights, such as the importance of considering an effect as a small component of a whole system rather than just an isolated feature. In this paper we present our semantic formalization for producer effect systems, which we call a productor, and prove its maximal generality by focusing on only sequential composition of effectful computations, consequently guaranteeing that the existing monadic techniques are specializations of productors.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429074},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL '13},
    x-url = {http://dx.doi.org/10.1145/2429069.2429074},
    xpages = {15--26},
    year = {2013}
}

@inproceedings{dvanhorn:DBLP:conf/vmcai/Ranzato13,
    author = {Ranzato, Francesco},
    booktitle = {VMCAI},
    citeulike-article-id = {12007825},
    date-added = {2013-02-09 01:59:48},
    priority = {2},
    title = {Complete Abstractions Everywhere},
    xpages = {15--26},
    year = {2013}
}

@inproceedings{dvanhorn:DBLP:conf/vmcai/MouraJ13,
    author = {de Moura, Leonardo M. and Jovanovic, Dejan},
    booktitle = {VMCAI},
    citeulike-article-id = {12007824},
    date-added = {2013-02-09 01:59:38},
    priority = {2},
    title = {A {Model-Constructing} Satisfiability Calculus},
    xpages = {1--12},
    year = {2013}
}

@inproceedings{dvanhorn:DBLP:conf/vmcai/Pearce13,
    author = {Pearce, David J.},
    booktitle = {VMCAI},
    citeulike-article-id = {12007819},
    date-added = {2013-02-09 01:28:44},
    priority = {2},
    title = {Sound and Complete Flow Typing with Unions, Intersections and Negations},
    xpages = {335--354},
    year = {2013}
}

@inproceedings{dvanhorn:DBLP:conf/vmcai/ZhuJ13,
    author = {Zhu, He and Jagannathan, Suresh},
    booktitle = {Conference on Verification, Model-Checking and Abstract Interpretation},
    citeulike-article-id = {12007818},
    date-added = {2013-02-09 01:15:27},
    priority = {2},
    title = {Compositional and Lightweight Dependent Type Inference for {ML}},
    xpages = {295--314},
    year = {2013}
}

@proceedings{dvanhorn:DBLP:conf/vmcai/2013,
    booktitle = {VMCAI},
    citeulike-article-id = {12007817},
    date-added = {2013-02-09 01:06:59},
    priority = {2},
    publisher = {Springer},
    title = {Verification, Model Checking, and Abstract Interpretation, 14th International Conference, {VMCAI} 2013, Rome, Italy, January 20-22, 2013. Proceedings},
    x-editor = {Giacobazzi, Roberto and Berdine, Josh and Mastroeni, Isabella},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {7737},
    year = {2013}
}

@inproceedings{dvanhorn:DBLP:conf/vmcai/CousotCFL13,
    author = {Cousot, Patrick and Cousot, Radhia and F{\"{a}}hndrich, Manuel and Logozzo, Francesco},
    booktitle = {VMCAI},
    citeulike-article-id = {12007816},
    date-added = {2013-02-09 01:06:59},
    priority = {2},
    publisher = {Springer},
    title = {Automatic Inference of Necessary Preconditions},
    x-editor = {Giacobazzi, Roberto and Berdine, Josh and Mastroeni, Isabella},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {7737},
    xpages = {128--148},
    year = {2013}
}

@inproceedings{dvanhorn:Guha2009Static,
    author = {Guha, Arjun and Krishnamurthi, Shriram and Jim, Trevor},
    booktitle = {In International World Wide Web Conference},
    citeulike-article-id = {11975596},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.186.4892},
    date-added = {2013-01-31 02:17:14},
    priority = {2},
    title = {Static analysis for Ajax intrusion detection},
    x-abstract = {We present a static control-flow analysis for {JavaScript} programs running in a web browser. Our analysis tackles numerous challenges posed by modern web applications including asynchronous communication, frameworks, and dynamic code generation. We use our analysis to extract a model of expected client behavior as seen from the server, and build an intrusion-prevention proxy for the server: the proxy intercepts client requests and disables those that do not meet the expected behavior. We insert random asynchronous requests to foil mimicry attacks. Finally, we evaluate our technique against several real applications and show that it protects against an attack in a widely-used web application.},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.186.4892},
    year = {2009}
}

@inproceedings{dvanhorn:Vytiniotis2013HALO,
    author = {Vytiniotis, Dimitrios and {Peyton Jones}, Simon and Claessen, Koen and Ros\'{e}n, Dan},
    booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {11975564},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2429121},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2429069.2429121},
    date-added = {2013-01-31 01:53:01},
    location = {Rome, Italy},
    priority = {0},
    publisher = {ACM},
    title = {HALO: {H}askell to logic through denotational semantics},
    x-abstract = {Even well-typed programs can go wrong in modern functional languages, by encountering a pattern-match failure, or simply returning the wrong answer. An increasingly-popular response is to allow programmers to write contracts that express semantic properties, such as crash-freedom or some useful post-condition. We study the static verification of such contracts. Our main contribution is a novel translation to first-order logic of both Haskell programs, and contracts written in Haskell, all justified by denotational semantics. This translation enables us to prove that functions satisfy their contracts using an off-the-shelf first-order logic theorem prover.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2429069.2429121},
    x-isbn = {978-1-4503-1832-7},
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/2429069.2429121},
    xpages = {431--442},
    year = {2013}
}

@incollection{dvanhorn:Alur2004Temporal,
    author = {Alur, Rajeev and Etessami, Kousha and Madhusudan, P.},
    booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
    citeulike-article-id = {11975561},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-24730-2\_35},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-540-24730-2\_35},
    date-added = {2013-01-31 01:50:42},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {A Temporal Logic of Nested Calls and Returns},
    x-abstract = {Model checking of linear temporal logic ({LTL}) specifications with respect to pushdown systems has been shown to be a useful tool for analysis of programs with potentially recursive procedures. {LTL}, however, can specify only regular properties, and properties such as correctness of procedures with respect to pre and post conditions, that require matching of calls and returns, are not regular. We introduce a temporal logic of calls and returns ({CaRet}) for specification and algorithmic verification of correctness requirements of structured programs. The formulas of {CaRet}  are interpreted over sequences of propositional valuations tagged with special symbols call and ret. Besides the standard global temporal modalities, {CaRet}  admits the abstract-next operator that allows a path to jump from a call to the matching return. This operator can be used to specify a variety of non-regular properties such as partial and total correctness of program blocks with respect to pre and post conditions. The abstract versions of the other temporal modalities can be used to specify regular properties of local paths within a procedure that skip over calls to other procedures. {CaRet}  also admits the caller modality that jumps to the most recent pending call, and such caller modalities allow specification of a variety of security properties that involve inspection of the call-stack. Even though verifying context-free properties of pushdown systems is undecidable, we show that model checking {CaRet}  formulas against a pushdown model is decidable. We present a tableau construction that reduces our model checking problem to the emptiness problem for a B\"{u}chi pushdown system. The complexity of model checking {CaRet}  formulas is the same as that of checking {LTL} formulas, namely, polynomial in the model and singly exponential in the size of the specification.},
    x-doi = {10.1007/978-3-540-24730-2\_35},
    x-editor = {Jensen, Kurt and Podelski, Andreas},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-24730-2\_35},
    x-volume = {2988},
    xpages = {467--481},
    year = {2004}
}

@incollection{dvanhorn:Scott1975Data,
    author = {Scott, Dana},
    booktitle = {⊨ISILC Logic Conference},
    citeulike-article-id = {5212385},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/bfb0079432},
    citeulike-linkout-1 = {http://www.springerlink.com/content/1g4802177006m187},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/BFb0079432},
    date-added = {2013-01-30 18:28:54},
    journal = {?ISILC Logic Conference},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Data types as lattices},
    x-abstract = {Without Abstract},
    x-doi = {10.1007/bfb0079432},
    x-editor = {M\"{u}ller, GertH and Oberschelp, Arnold and Potthoff, Klaus},
    x-series = {Lecture Notes in Mathematics},
    x-url = {http://dx.doi.org/10.1007/bfb0079432},
    x-volume = {499},
    xpages = {579--651},
    year = {1975}
}

@inproceedings{dvanhorn:Findler2006Contracts,
    author = {Findler, Robert B. and Blume, Matthias},
    booktitle = {Proceedings of the 8th International Conference on Functional and Logic Programming},
    citeulike-article-id = {11973864},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2100094},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/11737414\_16},
    date-added = {2013-01-30 18:28:04},
    location = {Fuji-Susono, Japan},
    priority = {0},
    publisher = {Springer-Verlag},
    title = {Contracts as pairs of projections},
    x-abstract = {Assertion-based contracts provide a powerful mechanism for stating invariants at module boundaries and for enforcing them uniformly. In 2002, Findler and Felleisen showed how to add contracts to higher-order functional languages, allowing programmers to assert invariants about functions as values. Following up in 2004, Blume and {McAllester} provided a quotient model for contracts. Roughly speaking, their model equates a contract with the set of values that cannot violate the contract. Their studies raised interesting questions about the nature of contracts and, in particular, the nature of the any contract. In this paper, we develop a model for software contracts that follows Dana Scott's program by interpreting contracts as projections. The model has already improved our implementation of contracts. We also demonstrate how it increases our understanding of contract-oriented programming and design. In particular, our work provides a definitive answer to the questions raised by Blume and {McAllester}'s work. The key insight from our model that resolves those questions is that a contract that puts no obligation on either party is not the same as the most permissive contract for just one of the parties.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/11737414\_16},
    x-isbn = {3-540-33438-6, 978-3-540-33438-5},
    x-series = {FLOPS'06},
    x-url = {http://dx.doi.org/10.1007/11737414\_16},
    xpages = {226--241},
    year = {2006}
}

@inproceedings{dvanhorn:Gordon1994Tutorial,
    author = {Gordon, Andrew D.},
    booktitle = {IN GLASGOW FUNCTIONAL PROGRAMMING WORKSHOP},
    citeulike-article-id = {11973862},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.3914},
    date-added = {2013-01-30 18:27:15},
    priority = {0},
    title = {A Tutorial on Co-induction and Functional Programming},
    x-abstract = {Co-induction is an important tool for reasoning about unbounded structures. This tutorial explains the foundations of co-induction, and shows how it justifies intuitive arguments about lazy streams, of central importance to lazy functional programmers. We explain from first principles a theory based on a new formulation of bisimilarity for functional programs, which coincides exactly with Morris-style contextual equivalence. We show how to prove properties of lazy streams by co-induction and derive Bird and Wadler's Take Lemma, a well-known proof technique for lazy streams.},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.3914},
    xpages = {78--95},
    year = {1994}
}

@article{dvanhorn:Alur2009Adding,
    author = {Alur, Rajeev and Madhusudan, P.},
    citeulike-article-id = {9726460},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1516518},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1516512.1516518},
    date-added = {2012-11-30 23:52:11},
    day = {01},
    journal = {J. ACM},
    priority = {2},
    publisher = {ACM},
    title = {Adding nesting structure to words},
    x-abstract = {We propose the model of nested words for representation of data with both a linear ordering and a hierarchically nested matching of items. Examples of data with such dual linear-hierarchical structure include executions of structured programs, annotated linguistic data, and {HTML}/{XML} documents. Nested words generalize both words and ordered trees, and allow both word and tree operations. We define nested word automata—finite-state acceptors for nested words, and show that the resulting class of regular languages of nested words has all the appealing theoretical properties that the classical regular word languages enjoys: deterministic nested word automata are as expressive as their nondeterministic counterparts; the class is closed under union, intersection, complementation, concatenation, Kleene-\&ast;, prefixes, and language homomorphisms; membership, emptiness, language inclusion, and language equivalence are all decidable; and definability in monadic second order logic corresponds exactly to finite-state recognizability. We also consider regular languages of infinite nested words and show that the closure properties, {MSO}-characterization, and decidability of decision problems carry over. The linear encodings of nested words give the class of visibly pushdown languages of words, and this class lies between balanced languages and deterministic context-free languages. We argue that for algorithmic verification of structured programs, instead of viewing the program as a context-free language over words, one should view it as a regular language of nested words (or equivalently, a visibly pushdown language), and this would allow model checking of many properties (such as stack inspection, pre-post conditions) that are not expressible in existing specification logics. We also study the relationship between ordered trees and nested words, and the corresponding automata: while the analysis complexity of nested word automata is the same as that of classical tree automata, they combine both bottom-up and top-down traversals, and enjoy expressiveness and succinctness benefits over tree automata.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1516512.1516518},
    x-issn = {0004-5411},
    x-month = may,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1145/1516512.1516518},
    x-volume = {56},
    xpages = {1--43},
    year = {2009}
}

@article{dvanhorn:Landin1966Next,
    author = {Landin, P. J.},
    citeulike-article-id = {221703},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=365257},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/365230.365257},
    date-added = {2012-11-14 07:39:17},
    journal = {Commun. ACM},
    priority = {2},
    publisher = {ACM},
    title = {The Next 700 Programming Languages},
    x-abstract = {A family of unimplemented computing languages is described that is intended to span differences of application area by a unified framework. This framework dictates the rules about the uses of user-coined names, and the conventions about characterizing functional relationships. Within this framework the design of a specific language splits into two independent parts. One is the choice of written appearances of programs (or more generally, their physical representation). The other is the choice of the abstract entities (such as numbers, character-strings, list of them, functional relations among them) that can be referred to in the {language.The} system is biased towards  ” expressions” rather than  ” statements.” It includes a nonprocedural (purely functional) subsystem that aims to expand the class of users' needs that can be met by a single print-instruction, without sacrificing the important properties that make conventional right-hand-side expressions easy to construct and understand.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/365230.365257},
    x-issn = {0001-0782},
    x-month = mar,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1145/365230.365257},
    x-volume = {9},
    xpages = {157--166},
    year = {1966}
}

@inproceedings{dvanhorn:Cousot1979Systematic,
    author = {Cousot, Patrick and Cousot, Radhia},
    booktitle = {Proceedings of the 6th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {225306},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=567778},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/567752.567778},
    date-added = {2012-11-14 06:04:21},
    location = {San Antonio, Texas},
    priority = {2},
    publisher = {ACM},
    title = {Systematic design of program analysis frameworks},
    x-abstract = {Semantic analysis of programs is essential in optimizing
compilers and program verification systems. It encompasses data
flow analysis, data type determination, generation of approximate
invariant assertions, etc.

Several recent papers (among others Cousot \& Cousot[77a],
Graham \& Wegman[76], Kam \& Ullman[76], Kildall[73],
Rosen[78], Tarjan[76], Wegbreit[75]) have introduced abstract
approaches to program analysis which are tantamount to the use of a
program analysis framework (A,t,\~{a}) where A is a
lattice of (approximate) assertions, t is an (approximate)
predicate transformer and \~{a} is an often implicit function
specifying the meaning of the elements of A. This paper is devoted
to the systematic and correct design of program analysis frameworks
with respect to a formal semantics.

Preliminary definitions are given in Section 2 concerning the
merge over all paths and (least) fixpoint program-wide analysis
methods. In Section 3 we briefly define the (forward and backward)
deductive semantics of programs which is later used as a formal
basis in order to prove the correctness of the approximate program
analysis frameworks. Section 4 very shortly recall the main
elements of the lattice theoretic approach to approximate semantic
analysis of programs.

The design of a space of approximate assertions A is studied in
Section 5. We first justify the very reasonable assumption that A
must be chosen such that the exact invariant assertions of any
program must have an upper approximation in A and that the
approximate analysis of any program must be performed using a
deterministic process. These assumptions are shown to imply that A
is a Moore family, that the approximation operator (wich defines
the least upper approximation of any assertion) is an upper closure
operator and that A is necessarily a complete lattice. We next show
that the connection between a space of approximate assertions and a
computer representation is naturally made using a pair of isotone
adjoined functions. This type of connection between two complete
lattices is related to Galois connections thus making available
classical mathematical results. Additional results are proved, they
hold when no two approximate assertions have the same meaning.

In Section 6 we study and examplify various methods which can be
used in order to define a space of approximate assertions or
equivalently an approximation function. They include the
characterization of the least Moore family containing an arbitrary
set of assertions, the construction of the least closure operator
greater than or equal to an arbitrary approximation function, the
definition of closure operators by composition, the definition of a
space of approximate assertions by means of a complete join
congruence relation or by means of a family of principal
ideals.

Section 7 is dedicated to the design of the approximate
predicate transformer induced by a space of approximate assertions.
First we look for a reasonable definition of the correctness of
approximate predicate transformers and show that a local
correctness condition can be given which has to be verified for
every type of elementary statement. This local correctness
condition ensures that the (merge over all paths or fixpoint)
global analysis of any program is correct. Since isotony is not
required for approximate predicate transformers to be correct it is
shown that non-isotone program analysis frameworks are manageable
although it is later argued that the isotony hypothesis is natural.
We next show that among all possible approximate predicate
transformers which can be used with a given space of approximate
assertions there exists a best one which provides the maximum
information relative to a program-wide analysis method. The best
approximate predicate transformer induced by a space of approximate
assertions turns out to be isotone. Some interesting consequences
of the existence of a best predicate transformer are examined. One
is that we have in hand a formal specification of the programs
which have to be written in order to implement a program analysis
framework once a representation of the space of approximate
assertions has been chosen. Examples are given, including ones
where the semantics of programs is formalized using Hoare[78]'s
sets of traces.

In Section 8 we show that a hierarchy of approximate analyses
can be defined according to the fineness of the approximations
specified by a program analysis framework. Some elements of the
hierarchy are shortly exhibited and related to the relevant
literature.

In Section 9 we consider global program analysis methods. The
distinction between "distributive" and "non-distributive" program
analysis frameworks is studied. It is shown that when the best
approximate predicate transformer is considered the coincidence or
not of the merge over all paths and least fixpoint global analyses
of programs is a consequence of the choice of the space of
approximate assertions. It is shown that the space of approximate
assertions can always be refined so that the merge over all paths
analysis of a program can be defined by means of a least fixpoint
of isotone equations.

Section 10 is devoted to the combination of program analysis
frameworks. We study and examplify how to perform the "sum",
"product" and "power" of program analysis frameworks. It is shown
that combined analyses lead to more accurate information than the
conjunction of the corresponding separate analyses but this can
only be achieved by a new design of the approximate predicate
transformer induced by the combined program analysis
frameworks.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/567752.567778},
    x-series = {POPL '79},
    x-url = {http://dx.doi.org/10.1145/567752.567778},
    xpages = {269--282},
    year = {1979}
}

@article{dvanhorn:Wright1997Practical,
    author = {Wright, Andrew K. and Cartwright, Robert},
    citeulike-article-id = {1400},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=239917},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/239912.239917},
    date-added = {2012-11-14 05:22:32},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {A practical soft type system for {Scheme}},
    x-abstract = {A soft type system infers types for the procedures and data structures of dynamically typed programs. Like conventional static types, soft types express program invariants and thereby provide valuable information for program optimization and debugging. A soft type checker uses the types inferred by a soft type system to eliminate run-time checks that are provably unnecessary; any remaining run-time checks are flagged as potential program errors. Soft Scheme is a practical soft type checker for {R4RS} Scheme. Its underlying type system generalizes conventional {Hindley-Milner} type inference by incorporating recursive types and a limited form of union type. Soft Scheme accommodates all of {R4RS} Scheme including uncurried procedures of  fixed and variable arity, assignment, and continuations.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/239912.239917},
    x-issn = {0164-0925},
    x-month = jan,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1145/239912.239917},
    x-volume = {19},
    xpages = {87--152},
    year = {1997}
}

@inproceedings{dvanhorn:Might2009Posteriori,
    author = {Might, Matthew and Manolios, Panagiotis},
    booktitle = {Proceedings of the 10th International Conference on Verification, Model Checking, and Abstract Interpretation},
    citeulike-article-id = {4838377},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1505362.1505387},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-93900-9\_22},
    date-added = {2012-11-14 05:08:56},
    location = {Savannah, GA},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {A Posteriori Soundness for Non-deterministic Abstract Interpretations},
    x-abstract = {An abstract interpretation's resource-allocation policy (<em>e.g.</em> , one heap summary node per allocation site) largely determines both its speed and precision. Historically, context has driven allocation policies, and as a result, these policies are said to determine the "context-sensitivity" of the analysis. This work gives analysis designers newfound freedom to manipulate speed and precision by severing the link between allocation policy and context-sensitivity: abstract allocation policies may be unhinged not only from context, but also from even a predefined correspondence with a concrete allocation policy. We do so by proving that abstract allocation policies can be made non-deterministic without sacrificing correctness; this non-determinism permits precision-guided allocation policies previously assumed to be unsafe. To prove correctness, we introduce the notion of <em>a posteriori</em> soundness for an analysis. A proof of <em>a posteriori</em> soundness differs from a standard proof of soundness in that the abstraction maps used in an <em>a posteriori</em> proof cannot be constructed until <em>after</em> an analysis has been run. Delaying construction allows them to be built so as to justify the decisions made by non-determinism. The crux of the <em>a posteriori</em> soundness theorem is to demonstrate that a justifying abstraction map can <em>always</em> be constructed.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-93900-9\_22},
    x-isbn = {978-3-540-93899-6},
    x-series = {VMCAI '09},
    x-url = {http://dx.doi.org/10.1007/978-3-540-93900-9\_22},
    xpages = {260--274},
    year = {2009}
}

@article{dvanhorn:Hartel1996Benchmarking,
    author = {Hartel, Pieter H. and Feeley, Marc and Alt, Martin and Augustsson, Lennart and Baumann, Peter and Beemster, Marcel and Chailloux, Emmanuel and Flood, Christine H. and Grieskamp, Wolfgang and Van Groningen, John H. G. and Hammond, Kevin and Hausman, Bogumil and Ivory, Melody Y. and Jones, Richard E. and Kamperman, Jasper and Lee, Peter and Leroy, Xavier and Lins, Rafael D. and Loosemore, Sandra and R\"{o}jemo, Niklas and Serrano, Manuel and Talpin, Jean P. and Thackray, Jon and Thomas, Stephen and Walters, Pum and Weis, Pierre and Wentworth, Peter},
    citeulike-article-id = {11678765},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=1349904},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796800001891},
    date-added = {2012-11-12 20:57:35},
    journal = {Journal of Functional Programming},
    priority = {2},
    title = {Benchmarking implementations of functional languages with ``Pseudoknot'', a float-intensive benchmark},
    x-abstract = {Over 25 implementations of different functional languages are benchmarked using the same program, a floating-point intensive application taken from molecular biology. The principal aspects studied are compile time and execution time for the various implementations that were benchmarked. An important consideration is how the program can be modified and tuned to obtain maximal performance on each language implementation. With few exceptions, the compilers take a significant amount of time to compile this program, though most compilers were faster than the then current {GNU} C compiler ({GCC} version 2.5.8). Compilers that generate C or Lisp are often slower than those that generate native code directly: the cost of compiling the intermediate form is normally a large fraction of the total compilation time. There is no clear distinction between the runtime performance of eager and lazy implementations when appropriate annotations are used: lazy implementations have clearly come of age when it comes to implementing largely strict applications, such as the Pseudoknot program. The speed of C can be approached by some implementations, but to achieve this performance, special measures such as strictness annotations are required by non-strict implementations. The benchmark results have to be interpreted with care. Firstly, a benchmark based on a single program cannot cover a wide spectrum of \^{a}typical\^{a} applications. Secondly, the compilers vary in the kind and level of optimisations offered, so the effort required to obtain an optimal version of the program is similarly varied.},
    x-doi = {10.1017/s0956796800001891},
    x-number = {04},
    x-url = {http://dx.doi.org/10.1017/s0956796800001891},
    x-volume = {6},
    xpages = {621--655},
    year = {1996}
}

@inproceedings{dvanhorn:Might2011Family,
    author = {Might, Matthew and Van Horn, David},
    booktitle = {Static Analysis},
    chapter = {16},
    citeulike-article-id = {11642508},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-23702-7\_16},
    citeulike-linkout-1 = {http://www.springerlink.com/content/j272827h5r088h78},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-642-23702-7\_16},
    date-added = {2012-11-09 04:07:30},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {A Family of Abstract Interpretations for Static Analysis of Concurrent {Higher-Order} Programs},
    x-abstract = {We develop a framework for computing two foundational analyses for concurrent higher-order programs: (control-)flow analysis ({CFA}) and may-happen-in-parallel analysis ({MHP}). We pay special attention to the unique challenges posed by the unrestricted mixture of first-class continuations and dynamically spawned threads. To set the stage, we formulate a concrete model of concurrent higher-order programs: the {P(CEK}*)S machine. We find that the systematic abstract interpretation of this machine is capable of computing both flow and {MHP} analyses. Yet, a closer examination finds that the precision for {MHP} is poor. As a remedy, we adapt a shape analytic technique—singleton abstraction—to dynamically spawned threads (as opposed to objects in the heap). We then show that if {MHP} analysis is not of interest, we can substantially accelerate the computation of flow analysis alone by collapsing thread interleavings with a second layer of abstraction.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-23702-7\_16},
    x-editor = {Yahav, Eran},
    x-isbn = {978-3-642-23701-0},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-23702-7\_16},
    x-volume = {6887},
    xpages = {180--197},
    year = {2011}
}

@inproceedings{dvanhorn:TobinHochstadt2012Higherorder,
    author = {Tobin-Hochstadt, Sam and {Van Horn}, David},
    booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
    citeulike-article-id = {11642456},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2384616.2384655},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2384616.2384655},
    date-added = {2012-11-09 03:59:55},
    location = {Tucson, Arizona, USA},
    priority = {2},
    publisher = {ACM},
    title = {Higher-order symbolic execution via contracts},
    x-abstract = {We present a new approach to automated reasoning about higher-order programs by extending symbolic execution to use behavioral contracts as symbolic values, thus enabling symbolic approximation of higher-order behavior. Our approach is based on the idea of an abstract reduction semantics that gives an operational semantics to programs with both concrete and symbolic components. Symbolic components are approximated by their contract and our semantics gives an operational interpretation of contracts-as-values. The result is an executable semantics that soundly predicts program behavior, including contract failures, for all possible instantiations of symbolic components. We show that our approach scales to an expressive language of contracts including arbitrary programs embedded as predicates, dependent function contracts, and recursive contracts. Supporting this rich language of specifications leads to powerful symbolic reasoning using existing program constructs. We then apply our approach to produce a verifier for contract correctness of components, including a sound and computable approximation to our semantics that facilitates fully automated contract verification. Our implementation is capable of verifying contracts expressed in existing programs, and of justifying contract-elimination optimizations.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2384616.2384655},
    x-isbn = {978-1-4503-1561-6},
    x-series = {OOPSLA},
    x-url = {http://dx.doi.org/10.1145/2384616.2384655},
    xpages = {537--554},
    year = {2012}
}

@inproceedings{dvanhorn:eli/stxparam,
    author = {Barzilay, Eli and Culpepper, Ryan and Flatt, Matthew},
    booktitle = {Workshop on Scheme and Functional Programming},
    citeulike-article-id = {11599100},
    date-added = {2012-11-09 03:52:34},
    keywords = {macros, racket, syntax},
    priority = {2},
    title = {Keeping it Clean with Syntax Parameters},
    year = {2011}
}

@inproceedings{dvanhorn:Earl2012Introspective,
    author = {Earl, Christopher and Sergey, Ilya and Might, Matthew and Van{ }Horn, David},
    booktitle = {Proceedings of the 17th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {11463048},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2364576},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2364527.2364576},
    date-added = {2012-10-14 18:58:47},
    location = {Copenhagen, Denmark},
    priority = {2},
    publisher = {ACM},
    title = {Introspective pushdown analysis of higher-order programs},
    x-abstract = {In the static analysis of functional programs, pushdown flow analysis and abstract garbage collection skirt just inside the boundaries of soundness and decidability. Alone, each method reduces analysis times and boosts precision by orders of magnitude. This work illuminates and conquers the theoretical challenges that stand in the way of combining the power of these techniques. The challenge in marrying these techniques is not subtle: computing the reachable control states of a pushdown system relies on limiting access during transition to the top of the stack; abstract garbage collection, on the other hand, needs full access to the entire stack to compute a root set, just as concrete collection does. Introspective pushdown systems resolve this conflict. Introspective pushdown systems provide enough access to the stack to allow abstract garbage collection, but they remain restricted enough to compute control-state reachability, thereby enabling the sound and precise product of pushdown analysis and abstract garbage collection. Experiments reveal synergistic interplay between the techniques, and the fusion demonstrates "better-than-both-worlds" precision.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2364527.2364576},
    x-isbn = {978-1-4503-1054-3},
    x-series = {ICFP '12},
    x-url = {http://dx.doi.org/10.1145/2364527.2364576},
    xpages = {177--188},
    year = {2012}
}

@article{dvanhorn:VanHorn2012Systematic,
    author = {Van{ }Horn, David and Might, Matthew},
    citeulike-article-id = {11463031},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=8669075},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796812000238},
    date-added = {2012-10-14 18:56:08},
    journal = {Journal of Functional Programming},
    priority = {2},
    title = {Systematic abstraction of abstract machines},
    x-doi = {10.1017/s0956796812000238},
    x-number = {Special Issue 4-5},
    x-url = {http://dx.doi.org/10.1017/s0956796812000238},
    x-volume = {22},
    xpages = {705--746},
    year = {2012}
}

@article{dvanhorn:Feeley1987Using,
    author = {Feeley, Marc and Lapalme, Guy},
    citeulike-article-id = {11462978},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=27476},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/0096-0551(87)90012-9},
    date-added = {2012-10-14 18:47:33},
    journal = {Comput. Lang.},
    priority = {2},
    publisher = {Pergamon Press, Inc.},
    title = {Using closures for code generation},
    x-abstract = {An abstract is not available.},
    x-address = {Tarrytown, NY, USA},
    x-doi = {10.1016/0096-0551(87)90012-9},
    x-issn = {0096-0551},
    x-month = jan,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1016/0096-0551(87)90012-9},
    x-volume = {12},
    xpages = {47--66},
    year = {1987}
}

@inproceedings{dvanhorn:Boucher1996Abstract,
    author = {Boucher, Dominique and Feeley, Marc},
    booktitle = {Compiler Construction: 6th International Conference, CC'96 Link\"{o}ping, Sweden},
    citeulike-article-id = {11462900},
    citeulike-linkout-0 = {http://link.springer.com/chapter/10.1007/3-540-61053-7\_62},
    date-added = {2012-10-14 18:36:36},
    priority = {0},
    title = {Abstract compilation: A new implementation paradigm for static analysis},
    x-editor = {Gyim\'{o}thy, Tibor},
    x-url = {http://link.springer.com/chapter/10.1007/3-540-61053-7\_62},
    xpages = {192--207},
    year = {1996}
}

@inproceedings{dvanhorn:Pnueli1977Temporal,
    author = {Pnueli, Amir},
    booktitle = {Foundations of Computer Science, 1977., 18th Annual Symposium on},
    citeulike-article-id = {4406307},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1382534},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/SFCS.1977.32},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/sfcs.1977.32},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4567924},
    date-added = {2012-07-07 07:13:56},
    day = {18},
    journal = {Foundations of Computer Science, Annual IEEE Symposium on},
    location = {Providence, RI, USA},
    priority = {2},
    publisher = {IEEE},
    title = {The temporal logic of programs},
    x-abstract = {A unified approach to program verification is suggested, which applies to both sequential and parallel programs. The main proof method suggested is that of temporal reasoning in which the time dependence of events is the basic concept. Two formal systems are presented for providing a basis for temporal reasoning. One forms a formalization of the method of intermittent assertions, while the other is an adaptation of the tense logic system Kb, and is particularly suitable for reasoning about concurrent programs.},
    x-address = {Washington, DC, USA},
    x-doi = {10.1109/sfcs.1977.32},
    x-issn = {0272-5428},
    x-month = oct,
    x-series = {SFCS '77},
    x-url = {http://dx.doi.org/10.1109/sfcs.1977.32},
    x-volume = {0},
    xpages = {46--57},
    year = {1977}
}

@inproceedings{dvanhorn:Rondon2008Liquid,
    author = {Rondon, Patrick M. and Kawaguci, Ming and Jhala, Ranjit},
    booktitle = {Proceedings of the 2008 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {10857337},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1375581.1375602},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1375581.1375602},
    date-added = {2012-07-04 21:31:01},
    location = {Tucson, AZ, USA},
    priority = {2},
    publisher = {ACM},
    title = {Liquid types},
    x-abstract = {We present Logically Qualified Data Types, abbreviated to Liquid Types, a system that combines {Hindley-Milner} type inference with Predicate Abstraction to automatically infer dependent types precise enough to prove a variety of safety properties. Liquid types allow programmers to reap many of the benefits of dependent types, namely static verification of critical properties and the elimination of expensive run-time checks, without the heavy price of manual annotation. We have implemented liquid type inference in {DSOLVE}, which takes as input an {OCAML} program and a set of logical qualifiers and infers dependent types for the expressions in the {OCAML} program. To demonstrate the utility of our approach, we describe experiments using {DSOLVE} to statically verify the safety of array accesses on a set of {OCAML} benchmarks that were previously annotated with dependent types as part of the {DML} project. We show that when used in conjunction with a fixed set of array bounds checking qualifiers, {DSOLVE} reduces the amount of manual annotation required for proving safety from 31\% of program text to under 1\%.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1375581.1375602},
    x-isbn = {978-1-59593-860-2},
    x-series = {PLDI},
    x-url = {http://dx.doi.org/10.1145/1375581.1375602},
    xpages = {159--169},
    year = {2008}
}

@inproceedings{dvanhorn:Kobayashi2009Types,
    author = {Kobayashi, Naoki},
    booktitle = {Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5154855},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1480881.1480933},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1480881.1480933},
    date-added = {2012-07-04 21:21:43},
    location = {Savannah, GA, USA},
    priority = {2},
    publisher = {ACM},
    title = {Types and higher-order recursion schemes for verification of higher-order programs},
    x-abstract = {We propose a new verification method for temporal properties of higher-order functional programs, which takes advantage of Ong's recent result on the decidability of the model-checking problem for higher-order recursion schemes ({HORS}'s). A program is transformed to an {HORS} that generates a tree representing all the possible event sequences of the program, and then the {HORS} is model-checked. Unlike most of the previous methods for verification of higher-order programs, our verification method is sound and complete. Moreover, this new verification framework allows a smooth integration of abstract model checking techniques into verification of higher-order programs. We also present a type-based verification algorithm for {HORS}'s. The algorithm can deal with only a fragment of the properties expressed by modal mu-calculus, but the algorithm and its correctness proof are (arguably) much simpler than those of Ong's game-semantics-based algorithm. Moreover, while the {HORS} model checking problem is {n-EXPTIME} in general, our algorithm is linear in the size of {HORS}, under the assumption that the sizes of types and specification formulas are bounded by a constant.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1480881.1480933},
    x-isbn = {978-1-60558-379-2},
    x-issn = {0362-1340},
    x-month = jan,
    x-number = {1},
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/1480881.1480933},
    x-volume = {44},
    xpages = {416--428},
    year = {2009}
}

@inproceedings{dvanhorn:Xu2012Hybrid,
    author = {Xu, Dana N.},
    booktitle = {Proceedings of the ACM SIGPLAN 2012 Workshop on Partial Evaluation and Program Manipulation},
    citeulike-article-id = {10365708},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2103767},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2103746.2103767},
    date-added = {2012-07-04 21:08:20},
    location = {Philadelphia, Pennsylvania, USA},
    priority = {2},
    publisher = {ACM},
    title = {Hybrid contract checking via symbolic simplification},
    x-abstract = {Program errors are hard to detect or prove absent. Allowing programmers to write formal and precise specifications, especially in the form of contracts, is a popular approach to program verification and error discovery. We formalize and implement a hybrid (static and dynamic) contract checker for a subset of {OCaml}. The key technique is symbolic simplification, which makes integrating static and dynamic contract checking easy and effective. Our technique statically checks contract satisfaction or blames the function violating the contract. When a contract satisfaction is undecidable, it leaves residual code for dynamic contract checking.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2103746.2103767},
    x-isbn = {978-1-4503-1118-2},
    x-series = {PEPM},
    x-url = {http://dx.doi.org/10.1145/2103746.2103767},
    xpages = {107--116},
    year = {2012}
}

@article{dvanhorn:Plotkin1977LCF,
    author = {Plotkin, G. D.},
    citeulike-article-id = {5392255},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0304-3975(77)90044-5},
    date-added = {2012-02-18 18:56:57},
    journal = {Theoretical Computer Science},
    priority = {0},
    title = {{LCF} considered as a programming language},
    x-abstract = {The paper studies connections between denotational and operational semantics for a simple programming language based on {LCF}. It begins with the connection between the behaviour of a program and its denotation. It turns out that a program denotes ⊥ in any of several possible semantics if it does not terminate. From this it follows that if two terms have the same denotation in one of these semantics, they have the same behaviour in all contexts. The converse fails for all the semantics. If, however, the language is extended to allow certain parallel facilities behavioural equivalence does coincide with denotational equivalence in one of the semantics considered, which may therefore be called  ” fully abstract”. Next a connection is given which actually determines the semantics up to isomorphism from the behaviour alone. Conversely, by allowing further parallel facilities, every r.e. element of the fully abstract semantics becomes definable, thus characterising the programming language, up to interdefinability, from the set of r.e. elements of the domains of the semantics.},
    x-doi = {10.1016/0304-3975(77)90044-5},
    x-issn = {03043975},
    x-month = dec,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1016/0304-3975(77)90044-5},
    x-volume = {5},
    xpages = {223--255},
    year = {1977}
}

@inproceedings{dvanhorn:Felleisen2009Functional,
    author = {Felleisen, Matthias and Findler, Robert B. and Flatt, Matthew and Krishnamurthi, Shriram},
    booktitle = {ICFP '09 Proceedings of the 14th ACM SIGPLAN International Conference on Functional programming},
    citeulike-article-id = {10143246},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1596561},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1631687.1596561},
    date-added = {2011-12-19 16:14:53},
    priority = {2},
    publisher = {ACM},
    title = {A functional {I/O} system or, fun for freshman kids},
    x-abstract = {Functional programming languages ought to play a central role in mathematics education for middle schools (age range: 10-14). After all, functional programming is a form of algebra and programming is a creative activity about problem solving. Introducing it into mathematics courses would make pre-algebra course come alive. If input and output were invisible, students could implement fun simulations, animations, and even interactive and distributed games all while using nothing more than plain mathematics. We have implemented this vision with a simple framework for purely functional {I/O}. Using this framework, students design, implement, and test plain mathematical functions over numbers, booleans, string, and images. Then the framework wires them up to devices and performs all the translation from external information to internal data (and vice versa)--just like every other operating system. Once middle school students are hooked on this form of programming, our curriculum provides a smooth path for them from pre-algebra to freshman courses in college on object-oriented design and theorem proving.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1631687.1596561},
    x-issn = {0362-1340},
    x-month = aug,
    x-url = {http://dx.doi.org/10.1145/1631687.1596561},
    xpages = {47--58},
    year = {2009}
}

@inproceedings{dvanhorn:Sheard2004Languages,
    author = {Sheard, Tim},
    booktitle = {Companion to the 19th annual ACM SIGPLAN conference on Object-oriented programming systems, languages, and applications},
    citeulike-article-id = {891157},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1028711},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1028664.1028711},
    date-added = {2011-12-18 14:21:04},
    location = {Vancouver, BC, CANADA},
    priority = {2},
    publisher = {ACM},
    title = {Languages of the future},
    x-abstract = {This paper explores a new point in the design space of formal reasoning systems - part programming language, part logical framework. The system is built on a programming language where the user expresses equality constraints between types and the type checker then enforces these constraints. This simple extension to the type system allows the programmer to describe properties of his program in the types of witness objects which can be thought of as concrete evidence that the program has the property desired. These techniques and two other rich typing mechanisms, {rank-N} polymorphism and extensible kinds, create a powerful new programming idiom for writing programs whose types enforce semantic properties. This kind of synthesis between a practical programming language <i>and</i> a logic creates a foundation for the design of languages of the future.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1028664.1028711},
    x-isbn = {1-58113-833-4},
    x-series = {OOPSLA '04},
    x-url = {http://dx.doi.org/10.1145/1028664.1028711},
    xpages = {116--119},
    year = {2004}
}

@article{dvanhorn:McBride2004View,
    author = {McBride, Conor and McKinna, James},
    citeulike-article-id = {271357},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=967496},
    citeulike-linkout-1 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=192403},
    citeulike-linkout-2 = {http://dx.doi.org/10.1017/s0956796803004829},
    date-added = {2011-12-18 14:18:52},
    journal = {J. Funct. Program.},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {The view from the left},
    x-abstract = {Pattern matching has proved an extremely powerful and durable notion in functional programming. This paper contributes a new programming notation for type theory which elaborates the notion in various ways. First, as is by now quite well-known in the type theory community, definition by pattern matching becomes a more discriminating tool in the presence of dependent types, since it refines the explanation of types as well as values. This becomes all the more true in the presence of the rich class of datatypes known as inductive families (Dybjer, 1991). Secondly, as proposed by Peyton Jones (1997) for Haskell, and independently rediscovered by us, subsidiary case analyses on the results of intermediate computations, which commonly take place on the right-hand side of definitions by pattern matching, should rather be handled on the left. In simply-typed languages, this subsumes the trivial case of Boolean guards; in our setting it becomes yet more powerful. Thirdly, elementary pattern matching decompositions have a well-defined interface given by a dependent type; they correspond to the statement of an induction principle for the datatype. More general, user-definable decompositions may be defined which also have types of the same general form. Elementary pattern matching may therefore be recast in abstract form, with a semantics given by translation. Such abstract decompositions of data generalize Wadler's (1987) notion of 'view'. The programmer wishing to introduce a new view of a type \$\mathit{T}\$, and exploit it directly in pattern matching, may do so via a standard programming idiom. The type theorist, looking through the Curry–Howard lens, may see this as proving a theorem, one which establishes the validity of a new induction principle for \$\mathit{T}\$. We develop enough syntax and semantics to account for this high-level style of programming in dependent type theory. We close with the development of a typechecker for the simply-typed lambda calculus, which furnishes a view of raw terms as either being well-typed, or containing an error. The implementation of this view is ipso facto a proof that typechecking is decidable.},
    x-address = {New York, NY, USA},
    x-doi = {10.1017/s0956796803004829},
    x-issn = {0956-7968},
    x-month = jan,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1017/s0956796803004829},
    x-volume = {14},
    xpages = {69--111},
    year = {2004}
}

@inproceedings{dvanhorn:Augustsson1998Cayennea,
    author = {Augustsson, Lennart},
    booktitle = {ICFP '98 Proceedings of the third ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {10140986},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=291251.289451},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/291251.289451},
    date-added = {2011-12-18 14:10:23},
    priority = {2},
    publisher = {ACM},
    title = {Cayenne---a language with dependent types},
    x-abstract = {Cayenne is a Haskell-like language. The main difference between Haskell and Cayenne is that Cayenne has dependent types, i.e., the result type of a function may depend on the argument value, and types of record components (which can be types or values) may depend on other components. Cayenne also combines the syntactic categories for value expressions and type expressions; thus reducing the number of language {concepts.Having} dependent types and combined type and value expressions makes the language very powerful. It is powerful enough that a special module concept is unnecessary; ordinary records suffice. It is also powerful enough to encode predicate logic at the type level, allowing types to be used as specifications of programs. However, this power comes at a cost: type checking of Cayenne is undecidable. While this may appear to be a steep price to pay, it seems to work well in practice.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/291251.289451},
    x-issn = {0362-1340},
    x-month = sep,
    x-url = {http://dx.doi.org/10.1145/291251.289451},
    x-volume = {34},
    xpages = {239--250},
    year = {1998}
}

@inproceedings{dvanhorn:Vardoulakis2011Pushdown,
    author = {Vardoulakis, Dimitrios and Shivers, Olin},
    booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {9814174},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2034785},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2034773.2034785},
    date-added = {2011-12-17 22:09:40},
    location = {Tokyo, Japan},
    priority = {2},
    publisher = {ACM},
    title = {Pushdown flow analysis of first-class control},
    x-abstract = {Pushdown models are better than control-flow graphs for higher-order flow analysis. They faithfully model the call/return structure of a program, which results in fewer spurious flows and increased precision. However, pushdown models require that calls and returns in the analyzed program nest properly. As a result, they cannot be used to analyze language constructs that break call/return nesting such as generators, coroutines, call/cc, etc. In this paper, we extend the {CFA2} flow analysis to create the first pushdown flow analysis for languages with first-class control. We modify the abstract semantics of {CFA2} to allow continuations to escape to, and be restored from, the heap. We then present a summarization algorithm that handles escaping continuations via a new kind of summary edge. We prove that the algorithm is sound with respect to the abstract semantics.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2034773.2034785},
    x-isbn = {978-1-4503-0865-6},
    x-series = {ICFP '11},
    x-url = {http://dx.doi.org/10.1145/2034773.2034785},
    xpages = {69--80},
    year = {2011}
}

@inproceedings{dvanhorn:Ahmed2011Blame,
    author = {Ahmed, Amal and Findler, Robert B. and Siek, Jeremy G. and Wadler, Philip},
    booktitle = {POPL '11 Proceedings of the 38th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {9338783},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1925844.1926409},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1925844.1926409},
    date-added = {2011-12-03 22:17:37},
    journal = {SIGPLAN Not.},
    priority = {2},
    publisher = {ACM},
    title = {Blame for all},
    x-abstract = {Several programming languages are beginning to integrate static and dynamic typing, including Racket (formerly {PLT} Scheme), Perl 6, and C\# 4.0 and the research languages Sage (Gronski, Knowles, Tomb, Freund, and Flanagan, 2006) and Thorn (Wrigstad, Eugster, Field, Nystrom, and Vitek, 2009). However, an important open question remains, which is how to add parametric polymorphism to languages that combine static and dynamic typing. We present a system that permits a value of dynamic type to be cast to a polymorphic type and vice versa, with relational parametricity enforced by a kind of dynamic sealing along the lines proposed by Matthews and Ahmed (2008) and Neis, Dreyer, and Rossberg (2009). Our system includes a notion of blame, which allows us to show that when casting between a more-precise type and a less-precise type, any cast failures are due to the less-precisely-typed portion of the program. We also show that a cast from a subtype to its supertype cannot fail.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1925844.1926409},
    x-issn = {0362-1340},
    x-month = jan,
    x-url = {http://dx.doi.org/10.1145/1925844.1926409},
    x-volume = {46},
    xpages = {201--214},
    year = {2011}
}

@inproceedings{dvanhorn:Guha2007Relationallyparametric,
    author = {Guha, Arjun and Matthews, Jacob and Findler, Robert B. and Krishnamurthi, Shriram},
    booktitle = {Proceedings of the 2007 symposium on Dynamic languages},
    citeulike-article-id = {6414694},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1297081.1297089},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1297081.1297089},
    date-added = {2011-12-03 22:12:17},
    location = {Montreal, Quebec, Canada},
    priority = {2},
    publisher = {ACM},
    title = {Relationally-parametric polymorphic contracts},
    x-abstract = {The analogy between types and contracts raises the question of how many features of static type systems can be expressed as dynamic contracts. An important feature missing in prior work on contracts is parametricity, as represented by the polymorphic types in languages like Standard {ML}. We present a contract counterpart to parametricity. We explore multiple designs for such a system and present one that is simple and incurs minimal execution overhead. We show how to extend the notion of contract blame to our definition. We present a form of inference that can often save programmers from having to explicitly instantiate many parametric contracts. Finally, we present several examples that illustrate how this system mimics the feel and properties of parametric polymorphism in typed languages.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1297081.1297089},
    x-isbn = {978-1-59593-868-8},
    x-series = {DLS '07},
    x-url = {http://dx.doi.org/10.1145/1297081.1297089},
    xpages = {29--40},
    year = {2007}
}

@inproceedings{dvanhorn:Flanagan2006Hybrid,
    author = {Flanagan, Cormac},
    booktitle = {POPL '06: Conference record of the 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {638089},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1111059},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1111037.1111059},
    date-added = {2011-12-03 22:04:15},
    location = {Charleston, South Carolina, USA},
    priority = {2},
    publisher = {ACM},
    title = {Hybrid type checking},
    x-abstract = {Traditional static type systems are very effective for verifying basic interface specifications, but are somewhat limited in the kinds specifications they support. Dynamically-checked contracts can enforce more precise specifications, but these are not checked until run time, resulting in incomplete detection of {defects.Hybrid} type checking is a synthesis of these two approaches that enforces precise interface specifications, via static analysis where possible, but also via dynamic checks where necessary. This paper explores the key ideas and implications of hybrid type checking, in the context of the simply-typed λ-calculus with arbitrary refinements of base types.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1111037.1111059},
    x-isbn = {1-59593-027-2},
    x-issn = {0362-1340},
    x-month = jan,
    x-number = {1},
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/1111037.1111059},
    x-volume = {41},
    xpages = {245--256},
    year = {2006}
}

@incollection{dvanhorn:Findler2008Implementation,
    author = {Findler, Robert B. and Guo, Shu Y. and Rogers, Anne},
    booktitle = {Implementation and Application of Functional Languages },
    chapter = {Lazy Contract Checking for Immutable Data Structures},
    citeulike-article-id = {6500117},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1425825},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-85373-2\_7},
    citeulike-linkout-2 = {http://www.springerlink.com/content/650xm483h1w14381},
    date-added = {2011-12-03 21:44:00},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Implementation and Application of Functional Languages},
    x-abstract = {Existing contract checkers for data structures force programmers to choose between poor alternatives. Contracts are either built into the functions that construct the data structure, meaning that each object can only be used with a single contract and that a data structure with an invariant cannot be viewed as a subtype of the data structure without the invariant (thus inhibiting abstraction) or contracts are checked eagerly when an operation on the data structure is invoked, meaning that many redundant checks are performed, potentially even changing the program's asymptotic {complexity.We} explore the idea of adding a small, controlled amount of laziness to contract checkers so that the contracts on a data structure are only checked as the program inspects the data structure. Unlike contracts on the constructors, our lazy contracts allow subtyping and thus preserve the potential for abstraction. Unlike eagerly-checked contracts, our contracts do not affect the asymptotic behavior of the {program.This} paper presents our implementation of these ideas, an optimization in our implementation, performance measurements, and a discussion of an extension to our implementation that admits more expressive contracts by loosening the strict asymptotic guarantees and only preserving the amortized asymptotic complexity.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-85373-2\_7},
    x-editor = {Chitil, Olaf and Horv\'{a}th, Zolt\'{a}n and Zs\'{o}k, Vikt\'{o}ria},
    x-isbn = {978-3-540-85372-5},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-85373-2\_7},
    xpages = {111--128},
    year = {2008}
}

@inproceedings{dvanhorn:Dimoulas2011Correct,
    author = {Dimoulas, Christos and Findler, Robert B. and Flanagan, Cormac and Felleisen, Matthias},
    booktitle = {Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {9525496},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1926410},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1925844.1926410},
    date-added = {2011-12-03 20:50:36},
    journal = {SIGPLAN Not.},
    location = {Austin, Texas, USA},
    priority = {2},
    publisher = {ACM},
    title = {Correct blame for contracts: no more scapegoating},
    x-abstract = {Behavioral software contracts supplement interface information with logical assertions. A rigorous enforcement of contracts provides useful feedback to developers if it signals contract violations as soon as they occur and if it assigns blame to violators with preciseexplanations. Correct blame assignment gets programmers started with the debugging process and can significantly decrease the time needed to discover and fix bugs. Sadly the literature on contracts lacks a framework for making statements about the correctness of blame assignment and for validating such statements. This paper fills the gap and uses the framework to demonstrate how one of the proposed semantics for higher-order contracts satisfies this criteria and another semantics occasionally assigns blame to the wrong module. Concretely, the paper applies the framework to the lax enforcement of dependent higher-order contracts and the picky one. A higher-order dependent contract specifies constraints for the domain and range of higher-order functions and also relates arguments and results in auxiliary assertions. The picky semantics ensures that the use of arguments in the auxiliary assertion satisfies the domain contracts and the lax one does not. While the picky semantics discovers more contract violations than the lax one, it occasionally blames the wrong module. Hence the paper also introduces a third semantics, dubbed indy, which fixes the problems of the picky semantics without giving up its advantages.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1925844.1926410},
    x-isbn = {978-1-4503-0490-0},
    x-issn = {0362-1340},
    x-month = jan,
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/1925844.1926410},
    x-volume = {46},
    xpages = {215--226},
    year = {2011}
}

@article{dvanhorn:Dimoulas2011Contract,
    author = {Dimoulas, Christos and Felleisen, Matthias},
    citeulike-article-id = {10091473},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2039348},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2039346.2039348},
    date-added = {2011-12-03 20:49:52},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {On contract satisfaction in a higher-order world},
    x-abstract = {Behavioral software contracts have become a popular mechanism for specifying and ensuring logical claims about a program's flow of values. While contracts for first-order functions come with a natural interpretation and are well understood, the various incarnations of higher-order contracts adopt, implicitly or explicitly, different views concerning the meaning of contract satisfaction. In this article, we define various notions of contract satisfaction in terms of observational equivalence and compare them with each other and notions in the literature. Specifically, we introduce a small model language with higher-order contracts and use it to formalize different notions of contract satisfaction. Each of them demands that the contract parties satisfy certain observational equivalences.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2039346.2039348},
    x-issn = {0164-0925},
    x-month = nov,
    x-url = {http://dx.doi.org/10.1145/2039346.2039348},
    x-volume = {33},
    year = {2011}
}

@inproceedings{dvanhorn:Disney2011Temporal,
    author = {Disney, Tim and Flanagan, Cormac and McCarthy, Jay},
    booktitle = {ICFP '11 Proceeding of the 16th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {10091438},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2034800},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2034574.2034800},
    date-added = {2011-12-03 20:44:50},
    priority = {2},
    publisher = {ACM},
    title = {Temporal Higher-order Contracts},
    x-abstract = {Behavioral contracts are embraced by software engineers because they document module interfaces, detect interface violations, and help identify faulty modules (packages, classes, functions, etc). This paper extends prior higher-order contract systems to also express and enforce temporal properties, which are common in software systems with imperative state, but which are mostly left implicit or are at best informally specified. The paper presents both a programmatic contract {API} as well as a temporal contract language, and reports on experience and performance results from implementing these contracts in Racket. Our development formalizes module behavior as a trace of events such as function calls and returns. Our contract system provides both non-interference (where contracts cannot influence correct executions) and also a notion of completeness (where contracts can enforce any decidable, prefix-closed predicate on event traces).},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2034574.2034800},
    x-issn = {0362-1340},
    x-month = sep,
    x-number = {9},
    x-series = {ICFP},
    x-url = {http://dx.doi.org/10.1145/2034574.2034800},
    xpages = {176--188},
    year = {2011}
}

@incollection{dvanhorn:Chitil2005Lazy,
    author = {Chitil, Olaf and McNeill, Dan and Runciman, Colin},
    chapter = {1},
    citeulike-article-id = {10091423},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-27861-0\_1},
    citeulike-linkout-1 = {http://www.springerlink.com/content/vbqnja1exd9be0qu},
    date-added = {2011-12-03 20:39:30},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Lazy Assertions Implementation of Functional Languages},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-27861-0\_1},
    x-editor = {Trinder, Phil and Michaelson, Greg and Pe\~{n}a, Ricardo},
    x-isbn = {978-3-540-23727-3},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-27861-0\_1},
    x-volume = {3145},
    xpages = {1--19},
    year = {2005}
}

@inproceedings{dvanhorn:Austin2011Virtual,
    author = {Austin, Thomas H. and Disney, Tim and Flanagan, Cormac},
    booktitle = {Proceedings of the 2011 ACM International Conference on Object Oriented Programming Systems Languages and Applications},
    citeulike-article-id = {10091422},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2048136},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2048066.2048136},
    date-added = {2011-12-03 20:36:31},
    journal = {SIGPLAN Not.},
    location = {Portland, Oregon, USA},
    priority = {2},
    publisher = {ACM},
    title = {Virtual values for language extension},
    x-abstract = {This paper focuses on extensibility, the ability of a programmer using a particular language to extend the expressiveness of that language. This paper explores how to provide an interesting notion of extensibility by virtualizing the interface between code and data. A virtual value is a special value that supports behavioral intercession. When a primitive operation is applied to a virtual value, it invokes a trap on that virtual value. A virtual value contains multiple traps, each of which is a user-defined function that describes how that operation should behave on that value. This paper formalizes the semantics of virtual values, and shows how they enable the definition of a variety of language extensions, including additional numeric types; delayed evaluation; taint tracking; contracts; revokable membranes; and units of measure. We report on our experience implementing virtual values for Javascript within an extension for the Firefox browser.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/2048066.2048136},
    x-isbn = {978-1-4503-0940-0},
    x-issn = {0362-1340},
    x-month = oct,
    x-series = {OOPSLA},
    x-url = {http://dx.doi.org/10.1145/2048066.2048136},
    x-volume = {46},
    xpages = {921--938},
    year = {2011}
}

@article{dvanhorn:Parnas1972Technique,
    author = {Parnas, D. L.},
    citeulike-article-id = {7021330},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=361309},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/355602.361309},
    date-added = {2011-12-03 19:40:14},
    journal = {Commun. ACM},
    priority = {2},
    publisher = {ACM},
    title = {A technique for software module specification with examples},
    x-abstract = {This paper presents an approach to writing specifications for parts of software systems. The main goal is to provide specifications sufficiently precise and complete that other pieces of software can be written to interact with the piece specified without additional information. The secondary goal is to include in the specification no more information than necessary to meet the first goal. The technique is illustrated by means of a variety of examples from a tutorial system.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/355602.361309},
    x-issn = {0001-0782},
    x-month = may,
    x-number = {5},
    x-url = {http://dx.doi.org/10.1145/355602.361309},
    x-volume = {15},
    xpages = {330--336},
    year = {1972}
}

@incollection{dvanhorn:America1991Designing,
    author = {America, Pierre},
    booktitle = {Foundations of Object-Oriented Languages},
    chapter = {2},
    citeulike-article-id = {10091302},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/bfb0019440},
    citeulike-linkout-1 = {http://www.springerlink.com/content/w025h3gr7gh65q01},
    date-added = {2011-12-03 19:34:44},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Designing an object-oriented programming language with behavioural subtyping Foundations of {Object-Oriented} Languages},
    x-abstract = {This paper describes the design of the parallel object-oriented programming language {POOL}-I. We concentrate on the type system of the language and specifically on the aspects of subtyping and genericity. {POOL}-I is the first language we know of that includes subtyping and inheritance as completely separate language mechanisms. By decoupling these two, which have been strongly tied together in other statically typed object-oriented languages with inheritance, a much cleaner language design can be obtained and a much more flexible use of both mechanisms can be made in actual programs.},
    x-address = {Berlin/Heidelberg},
    x-doi = {10.1007/bfb0019440},
    x-editor = {de Bakker, J. and de Roever, W. and Rozenberg, G.},
    x-isbn = {3-540-53931-X},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/bfb0019440},
    x-volume = {489},
    xpages = {60--90},
    year = {1991}
}

@inproceedings{dvanhorn:Flanagan2002Extended,
    author = {Flanagan, Cormac and Rustan and Lillibridge, Mark and Nelson, Greg and Saxe, James B. and Stata, Raymie},
    booktitle = {PLDI '02 Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {514997},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=543552.512558},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/543552.512558},
    date-added = {2011-08-29 21:55:55},
    priority = {2},
    publisher = {ACM},
    title = {Extended static checking for {J}ava},
    x-abstract = {Software development and maintenance are costly endeavors. The cost can be reduced if more software defects are detected earlier in the development cycle. This paper introduces the Extended Static Checker for Java ({ESC}/Java), an experimental compile-time program checker that finds common programming errors. The checker is powered by verification-condition generation and automatic theorem-proving techniques. It provides programmers with a simple annotation language with which programmer design decisions can be expressed formally. {ESC}/Java examines the annotated software and warns of inconsistencies between the design decisions recorded in the annotations and the actual code, and also warns of potential runtime errors in the code. This paper gives an overview of the checker architecture and annotation language and describes our experience applying the checker to tens of thousands of lines of Java programs.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/543552.512558},
    x-isbn = {1581134630},
    x-issn = {0362-1340},
    x-month = may,
    x-number = {5},
    x-url = {http://dx.doi.org/10.1145/543552.512558},
    x-volume = {37},
    xpages = {234--245},
    year = {2002}
}

@incollection{dvanhorn:Findler2004Semantic,
    author = {Findler, Robert B. and Flatt, Matthew and Felleisen, Matthias},
    booktitle = {ECOOP 2004 – Object-Oriented Programming},
    chapter = {17},
    citeulike-article-id = {8063104},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-24851-4\_17},
    citeulike-linkout-1 = {http://www.springerlink.com/content/3fj7h458njr0768k},
    date-added = {2011-08-29 21:54:14},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Semantic Casts: Contracts and Structural Subtyping in a Nominal World},
    x-abstract = {Nominal subtyping forces programmers to explicitly state all of the subtyping relationships in the program. This limits component reuse, because programmers cannot anticipate all of the contexts in which a particular class might be used. In contrast, structural subtyping implicitly allows any type with appropriate structure to be used in a given context. Languagues with contracts exacerbate the problem. Since contracts are typically expressed as refinements of types, contracts in nominally typed languages introduce additional obstacles to reuse. To overcome this problem we show how to extend a nominally typed language with semantic casts that introduce a limited form of structural subtyping. The new language must dynamically monitor contracts, as new subtyping relationships are exploited via semantic casts. In addition, it must also track the casts to properly assign blame in case interface contract are violated.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-24851-4\_17},
    x-editor = {Odersky,, Martin},
    x-isbn = {978-3-540-22159-3},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-24851-4\_17},
    x-volume = {3086},
    xpages = {614--639},
    year = {2004}
}

@techreport{dvanhorn:plt-tr2009-reference-v4.2.1,
    author = {Flatt, Matthew and Pl, T.},
    citeulike-article-id = {5917463},
    citeulike-linkout-0 = {http://download.plt-scheme.org/doc/4.2.1/pdf/reference.pdf},
    date-added = {2011-08-29 21:46:33},
    institution = {PLT Scheme Inc.},
    priority = {2},
    title = {Reference: {PLT} Scheme},
    type = {Reference Manual},
    x-month = jul,
    x-number = {PLT-TR2009-reference-v4.2.1},
    x-url = {http://download.plt-scheme.org/doc/4.2.1/pdf/reference.pdf},
    year = {2009}
}

@book{dvanhorn:meyer-eiffel,
    author = {Meyer, Bertrand},
    citeulike-article-id = {9524408},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0132479257},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0132479257},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0132479257},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0132479257},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0132479257/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0132479257},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0132479257},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0132479257},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0132479257\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0132479257},
    date-added = {2011-08-29 21:38:20},
    day = {01},
    howpublished = {Paperback},
    priority = {2},
    publisher = {Prentice Hall},
    title = {Eiffel : The Language},
    x-isbn = {0132479257},
    x-month = oct,
    x-url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0132479257},
    year = {1991}
}

@article{dvanhorn:VanHorn2011Abstracting,
    author = {Van{ }Horn, David and Might, Matthew},
    citeulike-article-id = {9723179},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1995400},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1995376.1995400},
    date-added = {2011-08-28 21:53:26},
    journal = {Communications of the ACM},
    priority = {2},
    publisher = {ACM},
    title = {Abstracting abstract machines: a systematic approach to higher-order program analysis},
    x-abstract = {Predictive models are fundamental to engineering reliable software systems. However, designing conservative, computable approximations for the behavior of programs (static analyses) remains a difficult and error-prone process for modern high-level programming languages. What analysis designers need is a principled method for navigating the gap between semantics and analytic models: analysis designers need a method that tames the interaction of complex languages features such as higher-order functions, recursion, exceptions, continuations, objects and dynamic allocation. We contribute a systematic approach to program analysis that yields novel and transparently sound static analyses. Our approach relies on existing derivational techniques to transform high-level language semantics into low-level deterministic state-transition systems (with potentially infinite state spaces). We then perform a series of simple machine refactorings to obtain a sound, computable approximation, which takes the form of a non-deterministic state-transition systems with finite state spaces. The approach scales up uniformly to enable program analysis of realistic language features, including higher-order functions, tail calls, conditionals, side effects, exceptions, first-class continuations, and even garbage collection.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1995376.1995400},
    x-issn = {0001-0782},
    x-month = sep,
    x-url = {http://dx.doi.org/10.1145/1995376.1995400},
    x-volume = {54},
    xpages = {101--109},
    year = {2011}
}

@inproceedings{dvanhorn:TobinHochstadt2011Semantic,
    archivePrefix = {arXiv},
    author = {Tobin-Hochstadt, Sam and Van Horn, David},
    booktitle = {FIT Session, The ACM SIGPLAN 2011 Conference on Programming Language Design and Implementation (PLDI'11)},
    citeulike-article-id = {9723173},
    citeulike-linkout-0 = {http://arxiv.org/abs/1105.0106},
    citeulike-linkout-1 = {http://arxiv.org/pdf/1105.0106},
    date-added = {2011-08-28 21:40:55},
    day = {30},
    eprint = {1105.0106},
    location = {San Jose, California},
    priority = {2},
    title = {Semantic Solutions to Program Analysis Problems},
    x-abstract = {Problems in program analysis can be solved by developing novel program
semantics and deriving abstractions conventionally. For over thirty years,
higher-order program analysis has been sold as a hard problem. Its solutions
have required ingenuity and complex models of approximation. We claim that this
difficulty is due to premature focus on abstraction and propose a new approach
that emphasizes semantics. Its simplicity enables new analyses that are beyond
the current state of the art.},
    x-month = jun,
    x-url = {http://arxiv.org/abs/1105.0106},
    year = {2011}
}

@inproceedings{dvanhorn:Findler2001Contract,
    author = {Findler, Robert B. and Felleisen, Matthias},
    booktitle = {Proceedings of the 16th ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications},
    citeulike-article-id = {4868},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=504283},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/504282.504283},
    date-added = {2011-08-27 17:20:11},
    location = {Tampa Bay, FL, USA},
    priority = {2},
    publisher = {ACM},
    title = {Contract Soundness for object-oriented languages},
    x-abstract = {Checking pre- and post-conditions of procedures and methods at runtime helps improve software reliability. In the procedural world, pre- and post-conditions have a straightforward interpretation. If a procedure's pre-condition doesn't hold, the caller failed to establish the proper context. If a post-condition doesn't hold, the caller failed to establish the proper context. If a post-condition doesn't hold, the procedure failed to compute the expected result. In the object-oriented world, checking pre- and post-conditions for methods, often called contracts in this context, poses complex problems. Because methods may be overridden, it is not sufficient to check only pre- and post-conditions. In addition, the contract hierarchy must be checked to ensure that the contracts on overridden methods are properly related to the contracts on overriding methods. Otherwise, a class hierarchy may violate the substitution principle, that is, it may no longer be true that an instance of a class is substitutable for objects of the super-class. In this paper, we study the problem of contract enforcement in an object-oriented world from a foundational perspective. More specifically, we study contracts as refinements of types. Pushing the analogy further, we state and prove a contract soundness theorem that captures the essential properties of contract enforcement. We use the theorem to illustrate how most existing tools suffer from a fundamental flaw and how they can be improved.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/504282.504283},
    x-isbn = {1-58113-335-9},
    x-month = nov,
    x-number = {11},
    x-series = {OOPSLA '01},
    x-url = {http://dx.doi.org/10.1145/504282.504283},
    x-volume = {36},
    xpages = {1--15},
    year = {2001}
}

@inproceedings{dvanhorn:Findler2001Behavioral,
    author = {Findler, Robert B. and Latendresse, Mario and Felleisen, Matthias},
    booktitle = {Proceedings of the 8th European Software Engineering Conference held jointly with 9th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
    citeulike-article-id = {4865},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=503240},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/503209.503240},
    date-added = {2011-08-27 17:18:41},
    location = {Vienna, Austria},
    priority = {2},
    publisher = {ACM},
    title = {Behavioral contracts and behavioral subtyping},
    x-abstract = {Component-based software manufacturing has the potential to bring division-of-labor benefits to the world of software engineering. In order to make a market of software components viable, however, producers and consumers must agree on enforceable software contracts. In this paper, we show how to enforce contracts if components are manufactured from class and interface hierarchies. In particular, we focus on one style of contract: pre- and post-conditions. Programmers annotate class and interface methods with pre- and post-conditions and the run-time system checks these conditions during evaluation. These contracts guarantee that methods are called properly and provide appropriate results. In procedural languages, the use of pre- and post-condition contracts is well-established and studies have demonstrated its value. In object-oriented languages, however, assigning blame for pre- and post-condition failures poses subtle and complex problems. Specifically, assigning blame for malformed class and interface hierarchies is so difficult that none of the existing contract monitoring tools correctly assign blame for these failures. In this paper, we show how to overcome these problems in the context of Java. Our work is based on the notion of behavioral subtyping.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/503209.503240},
    x-isbn = {1-58113-390-1},
    x-month = sep,
    x-number = {5},
    x-series = {ESEC/FSE-9},
    x-url = {http://dx.doi.org/10.1145/503209.503240},
    x-volume = {26},
    xpages = {229--236},
    year = {2001}
}

@inproceedings{dvanhorn:Kobayashi2011Predicate,
    author = {Kobayashi, Naoki and Sato, Ryosuke and Unno, Hiroshi},
    booktitle = {Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {9524695},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1993525},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1993316.1993525},
    date-added = {2011-07-12 22:26:41},
    priority = {2},
    publisher = {ACM},
    title = {Predicate abstraction and {CEGAR} for higher-order model checking},
    x-abstract = {Higher-order model checking (more precisely, the model checking of higher-order recursion schemes) has been extensively studied recently, which can automatically decide properties of programs written in the simply-typed λ-calculus with recursion and finite data domains. This paper formalizes predicate abstraction and counterexample-guided abstraction refinement ({CEGAR}) for higher-order model checking, enabling automatic verification of programs that use infinite data domains such as integers. A prototype verifier for higher-order functional programs based on the formalization has been implemented and tested for several programs.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1993316.1993525},
    x-issn = {0362-1340},
    x-month = jun,
    x-number = {6},
    x-series = {PLDI},
    x-url = {http://dx.doi.org/10.1145/1993316.1993525},
    xpages = {222--233},
    year = {2011}
}

@inproceedings{dvanhorn:Fahndrich2011Static,
    author = {F\"{a}hndrich, Manuel and Logozzo, Francesco},
    booktitle = {Proceedings of the 2010 international conference on Formal verification of object-oriented software},
    citeulike-article-id = {9539828},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1949305},
    date-added = {2011-07-12 21:23:10},
    location = {Paris, France},
    priority = {2},
    publisher = {Springer},
    title = {Static contract checking with abstract interpretation},
    x-abstract = {We present an overview of Clousot, our current tool to statically check {CodeContracts}. {CodeContracts} enable a compiler and language-independent specification of Contracts (precondition, postconditions and object invariants). Clousot checks every method in isolation using an assume/guarantee reasoning: For each method under analysis Clousot assumes its precondition and asserts the postcondition. For each invoked method, Clousot asserts its precondition and assumes the postcondition. Clousot also checks the absence of common runtime errors, such as null-pointer errors, buffer or array overruns, divisions by zero, as well as less common ones such as checked integer overflows or floating point precision mismatches in comparisons. At the core of Clousot there is an abstract interpretation engine which infers program facts. Facts are used to discharge the assertions. The use of abstract interpretation (vs usual weakest precondition-based checkers) has two main advantages: (i) the checker automatically infers loop invariants letting the user focus only on boundary specifications; (ii) the checker is deterministic in its behavior (which abstractly mimics the flowof the program) and it can be tuned for precision and cost. Clousot embodies other techniques, such as iterative domain refinement, goal-directed backward propagation, precondition and postcondition inference, and message prioritization.},
    x-address = {Berlin, Heidelberg},
    x-isbn = {3-642-18069-8, 978-3-642-18069-9},
    x-series = {FoVeOOS},
    x-url = {http://portal.acm.org/citation.cfm?id=1949305},
    xpages = {10--30},
    year = {2011}
}

@inproceedings{dvanhorn:Hinze2006Typed,
    author = {Hinze, Ralf and Jeuring, Johan and L\"{o}h, Andres},
    booktitle = {FLOPS'10},
    booktitle = {Proceedings of the 8th international conference on Functional and Logic Programming},
    chapter = {15},
    citeulike-article-id = {661450},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2100093},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/11737414\_15},
    citeulike-linkout-2 = {http://www.springerlink.com/content/w01115742074578r},
    date-added = {2011-07-12 21:05:09},
    journal = {Lecture Notes in Computer Science},
    location = {Fuji-Susono, Japan},
    priority = {2},
    publisher = {Springer},
    title = {Typed contracts for functional programming},
    x-abstract = {A robust software component fulfills a contract: it expects data satisfying a certain property and promises to return data satisfying another property. The object-oriented community uses the design-by-contract approach extensively. Proposals for language extensions that add contracts to higher-order functional programming have appeared recently. In this paper we propose an embedded domain-specific language for typed, higher-order and first-class contracts, which is both more expressive than previous proposals, and allows for a more informative blame assignment. We take some first steps towards an algebra of contracts, and we show how to define a generic contract combinator for arbitrary algebraic data types. The contract language is implemented as a library in Haskell using the concept of generalised algebraic data types.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/11737414\_15},
    x-editor = {Hagiya, Masami and Wadler, Philip},
    x-isbn = {3-540-33438-6, 978-3-540-33438-5},
    x-month = jan,
    x-series = {LNCS},
    x-url = {http://dx.doi.org/10.1007/11737414\_15},
    x-volume = {3945},
    xpages = {208--225},
    year = {2006}
}

@article{dvanhorn:Vardoulakis2011CFA2,
    author = {Vardoulakis, Dimitrios and Shivers, Olin},
    citeulike-article-id = {9468449},
    citeulike-linkout-0 = {http://www.lmcs-online.org/ojs/viewarticle.php?id=705},
    date-added = {2011-06-28 04:38:52},
    day = {1},
    journal = {Logical Methods in Computer Science},
    priority = {2},
    title = {{CFA2}: a {Context-Free} Approach to {Control-Flow} Analysis},
    x-month = may,
    x-number = {2},
    x-url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=705},
    x-volume = {7},
    year = {2011}
}

@inproceedings{dvanhorn:Morrisett1995Abstract,
    author = {Morrisett, Greg and Felleisen, Matthias and Harper, Robert},
    booktitle = {Proceedings of the Seventh International Conference on Functional Programming Languages and Computer Architecture},
    citeulike-article-id = {103133},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=224182},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/224164.224182},
    date-added = {2011-06-14 00:49:26},
    location = {La Jolla, California, United States},
    priority = {0},
    publisher = {ACM},
    title = {Abstract models of memory management},
    x-abstract = {An abstract is not available.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/224164.224182},
    x-isbn = {0-89791-719-7},
    x-series = {FPCA '95},
    x-url = {http://dx.doi.org/10.1145/224164.224182},
    xpages = {66--77},
    year = {1995}
}

@article{dvanhorn:TobinHochstadt2012HigherorderArXiv,
    archivePrefix = {arXiv},
    author = {Tobin-Hochstadt, Sam and Van Horn, David},
    citeulike-article-id = {9268598},
    citeulike-linkout-0 = {http://arxiv.org/abs/1103.1362},
    citeulike-linkout-1 = {http://arxiv.org/pdf/1103.1362},
    date-added = {2011-05-09 17:19:43},
    day = {26},
    eprint = {1103.1362},
    priority = {2},
    title = {{Higher-Order} Symbolic Execution via Contracts},
    x-abstract = {We present a new approach to automated reasoning about higher-order programs
by extending symbolic execution to use behavioral contracts as symbolic values,
enabling symbolic approximation of higher-order behavior.


Our approach is based on the idea of an abstract reduction semantics that
gives an operational semantics to programs with both concrete and symbolic
components. Symbolic components are approximated by their contract and our
semantics gives an operational interpretation of contracts-as-values. The
result is a executable semantics that soundly predicts program behavior,
including contract failures, for all possible instantiations of symbolic
components. We show that our approach scales to an expressive language of
contracts including arbitrary programs embedded as predicates, dependent
function contracts, and recursive contracts. Supporting this feature-rich
language of specifications leads to powerful symbolic reasoning using existing
program assertions.


We then apply our approach to produce a verifier for contract correctness of
components, including a sound and computable approximation to our semantics
that facilitates fully automated contract verification. Our implementation is
capable of verifying contracts expressed in existing programs, and of
justifying valuable contract-elimination optimizations.},
    x-month = apr,
    x-url = {http://arxiv.org/abs/1103.1362},
    year = {2012}
}

@article{dvanhorn:Spoonhower2010Space,
    author = {Spoonhower, Daniel and Blelloch, Guy E. and Harper, Robert and Gibbons, Phillip B.},
    citeulike-article-id = {9217818},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=8209504},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796810000146},
    date-added = {2011-04-27 22:05:30},
    journal = {Journal of Functional Programming},
    priority = {2},
    title = {Space profiling for parallel functional programs},
    x-abstract = {We present a semantic space profiler for parallel functional programs. Building on previous work in sequential profiling, our tools help programmers to relate runtime resource use back to program source code. Unlike many profiling tools, our profiler is based on a cost semantics. This provides a means to reason about performance without requiring a detailed understanding of the compiler or runtime system. It also provides a specification for language implementers. This is critical in that it enables us to separate cleanly the performance of the application from that of the language implementation. Some aspects of the implementation can have significant effects on performance. Our cost semantics enables programmers to understand the impact of different scheduling policies while hiding many of the details of their implementations. We show applications where the choice of scheduling policy has asymptotic effects on space use. We explain these use patterns through a demonstration of our tools. We also validate our methodology by observing similar performance in our implementation of a parallel extension of Standard {ML}.},
    x-doi = {10.1017/s0956796810000146},
    x-number = {Special Issue 5-6},
    x-url = {http://dx.doi.org/10.1017/s0956796810000146},
    x-volume = {20},
    xpages = {417--461},
    year = {2010}
}

@inproceedings{dvanhorn:Kodumal2004Set,
    author = {Kodumal, John and Aiken, Alex},
    booktitle = {PLDI '04: Proceedings of the ACM SIGPLAN 2004 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {6938153},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=996841.996867},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/996841.996867},
    date-added = {2011-04-14 16:50:47},
    location = {Washington DC, USA},
    priority = {2},
    publisher = {ACM},
    title = {The set {constraint/CFL} reachability connection in practice},
    x-abstract = {Many program analyses can be reduced to graph reachability problems involving a limited form of context-free language reachability called {Dyck-CFL} reachability. We show a new reduction from {Dyck-CFL} reachability to set constraints that can be used in practice to solve these problems. Our reduction is much simpler than the general reduction from context-free language reachability to set constraints. We have implemented our reduction on top of a set constraints toolkit and tested its performance on a substantial polymorphic flow analysis application.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/996841.996867},
    x-isbn = {1-58113-807-5},
    x-issn = {0362-1340},
    x-month = jun,
    x-url = {http://dx.doi.org/10.1145/996841.996867},
    xpages = {207--218},
    year = {2004}
}

@article{dvanhorn:Schmidt2007Statetransition,
    author = {Schmidt, David A.},
    citeulike-article-id = {9122654},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1325150},
    date-added = {2011-04-08 19:31:12},
    journal = {Higher Order Symbol. Comput.},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {State-transition machines, revisited},
    x-abstract = {History and context are given regarding the development of the {WNF}-machine, the first example of a Krivine machine.},
    x-address = {Hingham, MA, USA},
    x-issn = {1388-3690},
    x-month = sep,
    x-url = {http://portal.acm.org/citation.cfm?id=1325150},
    x-volume = {20},
    xpages = {333--335},
    year = {2007}
}

@article{dvanhorn:Wallach2000SAFKASI,
    author = {Wallach, Dan S. and Appel, Andrew W. and Felten, Edward W.},
    citeulike-article-id = {1403630},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=363520},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/363516.363520},
    date-added = {2011-04-07 02:13:09},
    journal = {ACM Trans. Softw. Eng. Methodol.},
    priority = {2},
    publisher = {ACM},
    title = {{SAFKASI}: a security mechanism for language-based systems},
    x-abstract = {In order to run untrusted code in the same process as trusted code, there must be a mechanism to allow dangerous calls to determine if their caller is authorized to exercise the privilege of using the dangerous routine. Java systems have adopted a technique called stack inspection to address this concern. But its original definition, in terms of searching stack frames, had an unclear relationship to the actual achievement of security, overconstrained the implementation of a Java system, limited many desirable optimizations such as method inlining and tail recursion, and generally interfered with interprocedural optimization. We present a new semantics for stack inspection based on a belief logic and its implementation using the calculus of security-passing style  which addresses the concerns of traditional stack inspection. With security-passing style, we can efficiently represent the security context for any method activation, and we can build a new implementation strictly by rewriting the Java bytecodes before they are loaded by the system. No changes to the {JVM} or bytecode semantics are necessary. With a combination of static analysis and runtime optimizations, our prototype implementation showes reasonable performance (although traditional stack inspection is still faster), and is easier to consider for languages beyond Java. We call our system {SAFKASI} (the Security Architecture Formerly Known as Stack Inspection).},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/363516.363520},
    x-issn = {1049-331X},
    x-month = oct,
    x-number = {4},
    x-url = {http://dx.doi.org/10.1145/363516.363520},
    x-volume = {9},
    xpages = {341--378},
    year = {2000}
}

@inproceedings{dvanhorn:Clinger1998Proper,
    author = {Clinger, William D.},
    booktitle = {Proceedings of the ACM SIGPLAN 1998 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {1350},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=277719},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/277650.277719},
    date-added = {2011-04-07 02:00:26},
    priority = {2},
    publisher = {ACM},
    title = {Proper tail recursion and space efficiency},
    x-abstract = {The {IEEE}/{ANSI} standard for Scheme requires implementations to be properly tail recursive. This ensures that portable code can rely upon the space efficiency of continuation-passing style and other idioms. On its face, proper tail recursion concerns the efficiency of procedure calls that occur within a tail context. When examined closely, proper tail recursion also depends upon the fact that garbage collection can be asymptotically more space-efficient than Algol-like stack {allocation.Proper} tail recursion is not the same as ad hoc tail call optimization in stack-based languages. Proper tail recursion often precludes stack allocation of variables, but yields a well-defined asymptotic space complexity that can be relied upon by portable {programs.This} paper offers a formal and implementation-independent definition of proper tail recursion for Scheme. It also shows how an entire family of reference implementations can be used to characterize related safe-for-space properties, and proves the asymptotic inequalities that hold between them.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/277650.277719},
    x-issn = {0362-1340},
    x-month = may,
    x-url = {http://dx.doi.org/10.1145/277650.277719},
    xpages = {174--185},
    year = {1998}
}

@inproceedings{dvanhorn:Agesen1995Cartesian,
    author = {Agesen, Ole},
    booktitle = {Proceedings of the 9th European Conference on Object-Oriented Programming},
    citeulike-article-id = {276694},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=679533},
    date-added = {2011-04-06 21:52:29},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {The Cartesian Product Algorithm: Simple and Precise Type Inference Of Parametric Polymorphism},
    x-abstract = {Concrete types and abstract types are different and serve different purposes. Concrete types, the focus of this paper, are essential to support compilation, application delivery, and debugging in object-oriented environments. Concrete types should not be obtained from explicit type declarations because their presence limits polymorphism unacceptably. This leaves us with type inference. Unfortunately, while polymorphism demands the use of type inference, it has also been the hardest challenge for type {inference.We} review previous type inference algorithms that analyze code with parametric polymorphism and then present a new one: the cartesian product algorithm. It improves precision and efficiency over previous algorithms and deals directly with inheritance, rather than relying on a preprocessor to expand it away. Last, but not least, it is conceptually {simple.The} cartesian product algorithm has been used in the Self system since late 1993. We present measurements to document its performance and compare it against several previous algorithms.},
    x-address = {London, UK, UK},
    x-isbn = {3-540-60160-0},
    x-series = {ECOOP '95},
    x-url = {http://portal.acm.org/citation.cfm?id=679533},
    xpages = {2--26},
    year = {1995}
}

@article{dvanhorn:Curien1991Abstract,
    author = {Curien, P. L.},
    citeulike-article-id = {9103710},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0304-3975(91)90230-y},
    date-added = {2011-04-06 07:17:15},
    day = {31},
    journal = {Theoretical Computer Science},
    priority = {2},
    title = {An abstract framework for environment machines},
    x-doi = {10.1016/0304-3975(91)90230-y},
    x-issn = {03043975},
    x-month = may,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1016/0304-3975(91)90230-y},
    x-volume = {82},
    xpages = {389--402},
    year = {1991}
}

@misc{dvanhorn:1999ECMAScript,
    citeulike-article-id = {9095178},
    date-added = {2011-04-04 03:51:16},
    edition = {3},
    priority = {2},
    title = {{ECMAScript} language specification, Stardard {ECMA}-262},
    year = {1999}
}

@inproceedings{dvanhorn:Maffeis2008Operational,
    author = {Maffeis, Sergio and Mitchell, John C. and Taly, Ankur},
    booktitle = {Proceedings of the 6th Asian Symposium on Programming Languages and Systems},
    citeulike-article-id = {3775653},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1485368},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-89330-1\_22},
    citeulike-linkout-2 = {http://www.springerlink.com/content/q54rt98v8374h9k1},
    date-added = {2011-04-04 03:21:42},
    journal = {Programming Languages and Systems},
    location = {Bangalore, India},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {An Operational Semantics for {JavaScript}},
    x-abstract = {We define a small-step operational semantics for the {ECMAScript} standard language corresponding to {JavaScript}, as a basis for analyzing security properties of web applications and mashups. The semantics is based on the language standard and a number of experiments with different implementations and browsers. Some basic properties of the semantics are proved, including a soundness theorem and a characterization of the reachable portion of the heap.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-89330-1\_22},
    x-isbn = {978-3-540-89329-5},
    x-series = {APLAS '08},
    x-url = {http://dx.doi.org/10.1007/978-3-540-89330-1\_22},
    xpages = {307--325},
    year = {2008}
}

@incollection{dvanhorn:Balakrishnan2006RecencyAbstraction,
    author = {Balakrishnan, Gogul and Reps, Thomas},
    booktitle = {Proceedings of the 13th international conference on Static Analysis},
    chapter = {15},
    citeulike-article-id = {5154774},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2090894},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/11823230\_15},
    citeulike-linkout-2 = {http://www.springerlink.com/content/g857n7xn2751624q},
    date-added = {2011-04-04 02:53:29},
    journal = {Static Analysis},
    location = {Seoul, Korea},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {{Recency-Abstraction} for {Heap-Allocated} Storage Static Analysis},
    x-abstract = {In this paper, we present an abstraction for heap-allocated storage, called the recency-abstraction, that allows abstract-interpretation algorithms to recover some non-trivial information for heap-allocated data objects. As an application of the recency-abstraction, we show how it can resolve virtual-function calls in stripped executables (i.e., executables from which debugging information has been removed). This approach succeeded in resolving 55\% of virtual-function call-sites, whereas previous tools for analyzing executables fail to resolve any of the virtual-function call-sites.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/11823230\_15},
    x-editor = {Yi, Kwangkeun},
    x-isbn = {978-3-540-37756-6},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/11823230\_15},
    x-volume = {4134},
    xpages = {221--239},
    year = {2006}
}

@article{dvanhorn:Biernacka2007Syntactic,
    author = {Biernacka, Magorzata and Danvy, Olivier},
    citeulike-article-id = {9080306},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1236111},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.tcs.2006.12.028},
    date-added = {2011-03-30 16:44:35},
    journal = {Theor. Comput. Sci.},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {A syntactic correspondence between context-sensitive calculi and abstract machines},
    x-abstract = {We present a systematic construction of environment-based abstract machines from context-sensitive calculi of explicit substitutions, and we illustrate it with ten calculi and machines for applicative order with an abort operation, normal order with generalized reduction and call/cc, the lambda-mu-calculus, delimited continuations, stack inspection, proper tail-recursion, and lazy evaluation. Most of the machines already exist but they have been obtained independently and are only indirectly related to the corresponding calculi. All of the calculi are new and they make it possible directly to reason about the execution of the corresponding machines.},
    x-address = {Essex, UK},
    x-doi = {10.1016/j.tcs.2006.12.028},
    x-issn = {0304-3975},
    x-month = apr,
    x-number = {1-3},
    x-url = {http://dx.doi.org/10.1016/j.tcs.2006.12.028},
    x-volume = {375},
    xpages = {76--108},
    year = {2007}
}

@proceedings{dvanhorn:AFP:08,
    booktitle = {Advanced Functional Programming, Sixth International School},
    citeulike-article-id = {9073949},
    date-added = {2011-03-29 02:41:00},
    priority = {2},
    publisher = {Springer},
    title = {Advanced Functional Programming, Sixth International School},
    x-address = {Nijmegen, The Netherlands},
    x-editor = {Koopman, Pieter and Plasmeijer, Rinus and Swierstra, Doaitse},
    x-month = may,
    x-number = {5382},
    year = {2008}
}

@inproceedings{dvanhorn:Danvy:AFP08,
    author = {Danvy, Olivier},
    booktitle = {Advanced Functional Programming, Sixth International School},
    booktitle = {Lecture notes including 70+ exercises},
    citeulike-article-id = {9073948},
    date-added = {2011-03-29 02:41:00},
    priority = {2},
    publisher = {Springer},
    title = {From {Reduction-Based} to {Reduction-Free} Normalization},
    x-address = {Nijmegen, The Netherlands},
    x-editor = {Koopman, Pieter and Plasmeijer, Rinus and Swierstra, Doaitse},
    x-month = may,
    x-number = {5382},
    xpages = {66--164},
    year = {2008}
}

@inproceedings{dvanhorn:Chugh2009Staged,
    author = {Chugh, Ravi and Meister, Jeffrey A. and Jhala, Ranjit and Lerner, Sorin},
    booktitle = {Proceedings of the 2009 ACM SIGPLAN conference on Programming language design and implementation},
    citeulike-article-id = {8322026},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1542483},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1543135.1542483},
    date-added = {2011-03-29 02:18:38},
    journal = {PLDI '09 Proceedings of the 2009 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    location = {Dublin, Ireland},
    priority = {2},
    publisher = {ACM},
    title = {Staged information flow for {JavaScript}},
    x-abstract = {Modern websites are powered by {JavaScript}, a flexible dynamic scripting language that executes in client browsers. A common paradigm in such websites is to include third-party {JavaScript} code in the form of libraries or advertisements. If this code were malicious, it could read sensitive information from the page or write to the location bar, thus redirecting the user to a malicious page, from which the entire machine could be compromised. We present an information-flow based approach for inferring the effects that a piece of {JavaScript} has on the website in order to ensure that key security properties are not violated. To handle dynamically loaded and generated {JavaScript}, we propose a framework for staging information flow properties. Our framework propagates information flow through the currently known code in order to compute a minimal set of syntactic residual checks that are performed on the remaining code when it is dynamically loaded. We have implemented a prototype framework for staging information flow. We describe our techniques for handling some difficult features of {JavaScript} and evaluate our system's performance on a variety of large real-world websites. Our experiments show that static information flow is feasible and efficient for {JavaScript}, and that our technique allows the enforcement of information-flow policies with almost no run-time overhead.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1543135.1542483},
    x-isbn = {978-1-60558-392-1},
    x-issn = {0362-1340},
    x-month = jun,
    x-series = {PLDI '09},
    x-url = {http://dx.doi.org/10.1145/1543135.1542483},
    xpages = {50--62},
    year = {2009}
}

@inproceedings{dvanhorn:Richards2010Analysis,
    author = {Richards, Gregor and Lebresne, Sylvain and Burg, Brian and Vitek, Jan},
    booktitle = {Proceedings of the 2010 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {7560428},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1806598},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1806596.1806598},
    date-added = {2011-03-29 02:07:26},
    location = {Toronto, Ontario, Canada},
    priority = {2},
    publisher = {ACM},
    title = {An analysis of the dynamic behavior of {JavaScript} programs},
    x-abstract = {The {JavaScript} programming language is widely used for web programming and, increasingly, for general purpose computing. As such, improving the correctness, security and performance of {JavaScript} applications has been the driving force for research in type systems, static analysis and compiler techniques for this language. Many of these techniques aim to reign in some of the most dynamic features of the language, yet little seems to be known about how programmers actually utilize the language or these features. In this paper we perform an empirical study of the dynamic behavior of a corpus of widely-used {JavaScript} programs, and analyze how and why the dynamic features are used. We report on the degree of dynamism that is exhibited by these {JavaScript} programs and compare that with assumptions commonly made in the literature and accepted industry benchmark suites.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1806596.1806598},
    x-isbn = {978-1-4503-0019-3},
    x-series = {PLDI '10},
    x-url = {http://dx.doi.org/10.1145/1806596.1806598},
    xpages = {1--12},
    year = {2010}
}

@inproceedings{dvanhorn:Guha2009Using,
    author = {Guha, Arjun and Krishnamurthi, Shriram and Jim, Trevor},
    booktitle = {Proceedings of the 18th international conference on World wide web},
    citeulike-article-id = {5310250},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1526709.1526785},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1526709.1526785},
    date-added = {2011-03-29 02:06:46},
    location = {Madrid, Spain},
    priority = {2},
    publisher = {ACM},
    title = {Using static analysis for Ajax intrusion detection},
    x-abstract = {We present a static control-flow analysis for {JavaScript} programs running in a web browser. Our analysis tackles numerous challenges posed by modern web applications including asynchronous communication, frameworks, and dynamic code generation. We use our analysis to extract a model of expected client behavior as seen from the server, and build an intrusion-prevention proxy for the server: the proxy intercepts client requests and disables those that do not meet the expected behavior. We insert random asynchronous requests to foil mimicry attacks. Finally, we evaluate our technique against several real applications and show that it protects against an attack in a widely-used web application.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1526709.1526785},
    x-isbn = {978-1-60558-487-4},
    x-series = {WWW '09},
    x-url = {http://dx.doi.org/10.1145/1526709.1526785},
    xpages = {561--570},
    year = {2009}
}

@incollection{dvanhorn:Jensen2011Interprocedural,
    author = {Jensen, Simon and M{\o}ller, Anders and Thiemann, Peter},
    booktitle = {Static Analysis},
    chapter = {20},
    citeulike-article-id = {9073897},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-15769-1\_20},
    citeulike-linkout-1 = {http://www.springerlink.com/content/a72x80355r124764},
    date-added = {2011-03-29 02:03:14},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Interprocedural Analysis with Lazy Propagation},
    x-abstract = {We propose lazy propagation as a technique for flow- and context-sensitive interprocedural analysis of programs with objects and first-class functions where transfer functions may not be distributive. The technique is described formally as a systematic modification of a variant of the monotone framework and its theoretical properties are shown. It is implemented in a type analysis tool for {JavaScript} where it results in a significant improvement in performance.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-15769-1\_20},
    x-editor = {Cousot, Radhia and Martel, Matthieu},
    x-isbn = {978-3-642-15768-4},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-15769-1\_20},
    x-volume = {6337},
    xpages = {320--339},
    year = {2011}
}

@inproceedings{dvanhorn:Jensen2009Type,
    author = {Jensen, Simon H. and M{\o}ller, Anders and Thiemann, Peter},
    booktitle = {Proceedings of the 16th International Symposium on Static Analysis},
    chapter = {17},
    citeulike-article-id = {7228966},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1615441.1615460},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-642-03237-0\_17},
    citeulike-linkout-2 = {http://www.springerlink.com/content/yv60v168w42k2484},
    date-added = {2011-03-29 01:56:46},
    location = {Los Angeles, CA},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Type Analysis for {JavaScript}},
    x-abstract = {{JavaScript} is the main scripting language for Web browsers, and it is essential to modern Web applications. Programmers have started using it for writing complex applications, but there is still little tool support available during development. We present a static program analysis infrastructure that can infer detailed and sound type information for {JavaScript} programs using abstract interpretation. The analysis is designed to support the full language as defined in the {ECMAScript} standard, including its peculiar object model and all built-in functions. The analysis results can be used to detect common programming errors --- or rather, prove their absence, and for producing type information for program comprehension. Preliminary experiments conducted on real-life {JavaScript} code indicate that the approach is promising regarding analysis precision on small and medium size programs, which constitute the majority of {JavaScript} applications. With potential for further improvement, we propose the analysis as a foundation for building tools that can aid {JavaScript} programmers.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-03237-0\_17},
    x-isbn = {978-3-642-03236-3},
    x-series = {SAS '09},
    x-url = {http://dx.doi.org/10.1007/978-3-642-03237-0\_17},
    x-volume = {5673},
    xpages = {238--255},
    year = {2009}
}

@incollection{dvanhorn:Thiemann2005Towards,
    author = {Thiemann, Peter},
    booktitle = {Programming Languages and Systems},
    chapter = {28},
    citeulike-article-id = {2973885},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-31987-0\_28},
    citeulike-linkout-1 = {http://www.springerlink.com/content/nudp8rmw194glhqc},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-540-31987-0\_28},
    date-added = {2011-03-29 01:54:53},
    journal = {Programming Languages and Systems},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Towards a Type System for Analyzing {JavaScript} Programs},
    x-abstract = {{JavaScript} is a popular language for client-side web scripting. It has a dubious reputation among programmers for two reasons. First, many {JavaScript} programs are written against a rapidly evolving {API} whose implementations are sometimes contradictory and idiosyncratic. Second, the language is only weakly typed and comes virtually without development tools.
                          The present work is a first attempt to address the second point. It does so by defining a type system that tracks the possible traits of an object and flags suspicious type conversions. Because {JavaScript} is a classless, object-based language with first-class functions, the type system must include singleton types, subtyping, and first class record labels. The type system covers a representative subset of the language and there is a type soundness proof with respect to an operational semantics.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-31987-0\_28},
    x-editor = {Sagiv, Mooly},
    x-isbn = {978-3-540-25435-5},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-31987-0\_28},
    x-volume = {3444},
    xpages = {408--422},
    year = {2005}
}

@incollection{dvanhorn:Heidegger2010Recency,
    author = {Heidegger, Phillip and Thiemann, Peter},
    booktitle = {ECOOP 2010 – Object-Oriented Programming},
    chapter = {10},
    citeulike-article-id = {9073874},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-14107-2\_10},
    citeulike-linkout-1 = {http://www.springerlink.com/content/13845531617t1083},
    date-added = {2011-03-29 01:48:25},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Recency Types for Analyzing Scripting Languages},
    x-abstract = {With the current surge of scripting technologies, large programs are being built with dynamically typed languages. As these programs grow in size, semantics-based tools gain importance for detecting programming errors as well as for program understanding.   As a basis for such tools, we propose a descriptive type system for an imperative call-by-value lambda calculus with objects. The calculus models essential features of {JavaScript}, a widely used dynamically-typed language: first-class functions, objects as property maps, and prototypes.    Our type system infers precise singleton object types for recently allocated objects. These object types are handled flow-sensitively and change during the objects' initialization phase. The notion of recency provides an automatic criterion to subsume these precise object types to summary object types, which are handled flow-insensitively. The criterion applies on a per-object basis. Thus, the type system identifies a generalized initialization phase for each object during which the change of its value is precisely reflected in the change of its type. Unlike with linear types, summary types may refer to singleton types and vice versa.    We prove the soundness of the type system and present a constraint-based inference algorithm. An implementation is available on the web.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-14107-2\_10},
    x-editor = {D'Hondt, Theo},
    x-isbn = {978-3-642-14106-5},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-14107-2\_10},
    x-volume = {6183},
    xpages = {200--224},
    year = {2010}
}

@article{dvanhorn:Queinnec2004Continuations,
    author = {Queinnec, Christian},
    citeulike-article-id = {116706},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10990-004-4866-z},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/klu/lisp/2004/00000017/00000004/00004866},
    date-added = {2011-03-26 20:17:57},
    journal = {Higher-Order and Symbolic Computation},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Continuations and Web Servers},
    x-doi = {10.1007/s10990-004-4866-z},
    x-issn = {1388-3690},
    x-month = dec,
    x-number = {4},
    x-url = {http://dx.doi.org/10.1007/s10990-004-4866-z},
    x-volume = {17},
    xpages = {277--295},
    year = {2004}
}

@techreport{dvanhorn:Danvy-Nielsen:RS-04-26,
    author = {Danvy, Olivier and Nielsen, Lasse R.},
    booktitle = {A preliminary version appeared in the informal proceedings of the Second International Workshop on Rule-Based Programming (RULE 2001), Electronic Notes in Theoretical Computer Science, Vol.\~{}59.4},
    citeulike-article-id = {9028092},
    date-added = {2011-03-19 17:01:00},
    institution = {Department of Computer Science, Aarhus University},
    priority = {2},
    title = {Refocusing in Reduction Semantics},
    type = {Research Report},
    x-address = {Aarhus, Denmark},
    x-month = nov,
    x-number = {BRICS RS-04-26},
    year = {2004}
}

@book{dvanhorn:Neilson:1999,
    author = {Nielson, Flemming and Nielson, Hanne R. and Hankin, Chris},
    citeulike-article-id = {9026861},
    date-added = {2011-03-19 07:14:25},
    keywords = {cfa},
    priority = {0},
    publisher = {Springer-Verlag},
    title = {Principles of Program Analysis},
    x-address = {Secaucus, NJ, USA},
    x-isbn = {3540654100},
    year = {1999}
}

@book{dvanhorn:Sperber2010Revised,
    author = {Sperber, Michael and Dybvig, R. Kent and Flatt, Matthew and van Straaten, Anton and Findler, Robby and Matthews, Jacob},
    citeulike-article-id = {9026826},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1830448},
    date-added = {2011-03-19 05:55:09},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Revised [6] Report on the Algorithmic Language Scheme},
    x-abstract = {Programming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary. Scheme demonstrates that a very small number of rules for forming expressions, with no restrictions on how they are composed, are enough to form a practical and efficient programming language that is flexible enough to support most of the major programming paradigms in use today. This book contains the three parts comprising '{R6RS}', the sixth revision of a series of reports describing the programming language Scheme. The book is divided into parts: a description of the language itself, a description of the standard libraries and non-normative appendices. Early chapters introduce Scheme and later chapters act as a reference manual. This is an important report for programmers that work with or want to learn about the Scheme language.},
    x-address = {New York, NY, USA},
    x-isbn = {0521193990, 9780521193993},
    x-url = {http://portal.acm.org/citation.cfm?id=1830448},
    year = {2010}
}

@article{dvanhorn:TobinHochstadt2011Modular,
    archivePrefix = {arXiv},
    author = {Tobin-Hochstadt, Sam and Van{ }Horn, David},
    citeulike-article-id = {8997639},
    citeulike-linkout-0 = {http://arxiv.org/abs/1103.1362v1},
    citeulike-linkout-1 = {http://arxiv.org/pdf/1103.1362v1},
    date-added = {2011-03-15 20:38:25},
    day = {7},
    eprint = {1103.1362v1},
    priority = {2},
    title = {Modular Analysis via Abstract Reduction Semantics},
    x-abstract = {Modular static analysis requires treating some portion of the program
opaquely. To enable such analysis, we introduce a notion of abstract reduction
semantics. Opaque components are approximated by their specifications, which in
turn are treated as abstract values during reduction. We demonstrate the
technique by applying it to two kinds of specifications for higher-order
languages: types and first-class contracts, showing that each soundly
approximates opaque components. Finally, we derive modular static analyzers
from these semantics, soundly predicting evaluation, contract violations, and
blame assignment.},
    x-month = mar,
    x-url = {http://arxiv.org/abs/1103.1362v1},
    year = {2011}
}

@inproceedings{dvanhorn:Guha2010Javascript,
    author = {Guha, Arjun and Saftoiu, Claudiu and Krishnamurthi, Shriram},
    booktitle = {Proceedings of the 24th European conference on Object-oriented programming},
    citeulike-article-id = {8499950},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1883988},
    date-added = {2011-02-27 22:07:23},
    location = {Maribor, Slovenia},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {The essence of {J}ava{S}cript},
    x-abstract = {We reduce {JavaScript} to a core calculus structured as a small-step operational semantics. We present several peculiarities of the language and show that our calculus models them. We explicate the desugaring process that turns {JavaScript} programs into ones in the core. We demonstrate faithfulness to {JavaScript} using real-world test suites. Finally, we illustrate utility by defining a security property, implementing it as a type system on the core, and extending it to the full language.},
    x-address = {Berlin, Heidelberg},
    x-isbn = {3-642-14106-4, 978-3-642-14106-5},
    x-series = {ECOOP'10},
    x-url = {http://portal.acm.org/citation.cfm?id=1883988},
    xpages = {126--150},
    year = {2010}
}

@article{dvanhorn:BarnettEA10,
    author = {Barnett, M. and F\"{a}hndrich, M. and Leino, K. R. M. and M\"{u}ller, P. and Schulte, W. and Venter, H.},
    booktitle = {To appear},
    citeulike-article-id = {7965335},
    date-added = {2010-10-09 01:52:55},
    journal = {Comm. of the ACM},
    priority = {2},
    publisher = {ACM},
    title = {Specification and Verification: The {S}pec\# Experience},
    year = {2010}
}

@article{dvanhorn:Barnett2004Verification,
    author = {Barnett, Mike and DeLine, Robert and F\"{a}hndrich, Manuel and Leino and Schulte, Wolfram},
    citeulike-article-id = {7965276},
    date-added = {2010-10-09 01:43:11},
    journal = {Journal of Object Technology},
    priority = {2},
    title = {Verification of object-oriented programs with invariants},
    x-month = jun,
    x-number = {6},
    x-volume = {3},
    xpages = {27--56},
    year = {2004}
}

@inbook{dvanhorn:Barnett2005Spec,
    author = {Barnett, Mike and Leino and Schulte, Wolfram},
    booktitle = {Construction and Analysis of Safe, Secure, and Interoperable Smart Devices},
    chapter = {3},
    citeulike-article-id = {1550097},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-30569-9\_3},
    citeulike-linkout-1 = {http://www.springerlink.com/content/0m789xre652nuv06},
    date-added = {2010-10-09 01:36:02},
    journal = {Construction and Analysis of Safe, Secure, and Interoperable Smart Devices},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {The Spec\# Programming System: An Overview},
    x-abstract = {The Spec\# programming system is a new attempt at a more cost effective way to develop and maintain high-quality software. This paper describes the goals and architecture of the Spec\# programming system, consisting of the object-oriented Spec\# programming language, the Spec\# compiler, and the Boogie static program verifier. The language includes constructs for writing specifications that capture programmer intentions about how methods and data are to be used, the compiler emits run-time checks to enforce these specifications, and the verifier can check the consistency between a program and its specifications.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-30569-9\_3},
    x-editor = {Barthe, Gilles and Burdy, Lilian and Huisman, Marieke and Lanet, Jean-Louis and Muntean, Traian},
    x-isbn = {978-3-540-24287-1},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-30569-9\_3},
    x-volume = {3362},
    xpages = {49--69},
    year = {2005}
}

@inproceedings{dvanhorn:Fahndrich2010Embedded,
    author = {F\"{a}hndrich, Manuel and Barnett, Michael and Logozzo, Francesco},
    booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
    booktitle = {SAC'10},
    citeulike-article-id = {7965240},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1774531},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1774088.1774531},
    date-added = {2010-10-09 01:25:44},
    location = {Sierre, Switzerland},
    priority = {2},
    publisher = {ACM},
    title = {Embedded contract languages},
    x-abstract = {Specifying application interfaces ({APIs}) with information that goes beyond method argument and return types is a long-standing quest of programming language researchers and practitioners. The number of type system extensions or specification languages is a testament to that. Unfortunately, the number of such systems is also roughly equal to the number of tools that consume them. In other words, every tool comes with its own specification language. In this paper we argue that for modern object-oriented languages, using an embedding of contracts as code is a better approach. We exemplify our embedding of Code Contracts on the Microsoft managed execution platform (.{NET}) using the C\# programming language. The embedding works as well in Visual Basic. We discuss the numerous advantages of our approach and the technical challenges, as well as the status of tools that consume the embedded contracts.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1774088.1774531},
    x-isbn = {978-1-60558-639-7},
    x-series = {\},
    x-url = {http://dx.doi.org/10.1145/1774088.1774531},
    xpages = {2103--2110},
    year = {2010}
}

@inproceedings{dvanhorn:VanHorn2010Abstracting,
    author = {Van{ }Horn, David and Might, Matthew},
    booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {7956643},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1863543.1863553},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1863543.1863553},
    date-added = {2010-10-07 22:11:30},
    location = {Baltimore, Maryland, USA},
    priority = {2},
    publisher = {ACM},
    title = {Abstracting Abstract Machines},
    x-abstract = {We describe a derivational approach to abstract interpretation that yields novel and transparently sound static analyses when applied to well-established abstract machines. To demonstrate the technique and support our claim, we transform the {CEK} machine of Felleisen and Friedman, a lazy variant of Krivine's machine, and the stack-inspecting {CM} machine of Clements and Felleisen into abstract interpretations of themselves. The resulting analyses bound temporal ordering of program events; predict return-flow and stack-inspection behavior; and approximate the flow and evaluation of by-need parameters. For all of these machines, we find that a series of well-known concrete machine refactorings, plus a technique we call store-allocated continuations, leads to machines that abstract into static analyses simply by bounding their stores. We demonstrate that the technique scales up uniformly to allow static analysis of realistic language features, including tail calls, conditionals, side effects, exceptions, first-class continuations, and even garbage collection.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1863543.1863553},
    x-isbn = {978-1-60558-794-3},
    x-issn = {0362-1340},
    x-month = sep,
    x-series = {ICFP},
    x-url = {http://dx.doi.org/10.1145/1863543.1863553},
    xpages = {51--62},
    year = {2010}
}

@inproceedings{dvanhorn:Xu2009Static,
    author = {Xu, Dana N. and {Peyton Jones}, Simon and Claessen, Simon},
    booktitle = {POPL '09: Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {6647620},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1480881.1480889},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1480881.1480889},
    date-added = {2010-10-06 23:27:55},
    location = {Savannah, GA, USA},
    priority = {2},
    publisher = {ACM},
    title = {Static contract checking for {H}askell},
    x-abstract = {Program errors are hard to detect and are costly both to programmers who spend significant efforts in debugging, and for systems that are guarded by runtime checks. Static verification techniques have been applied to imperative and object-oriented languages, like Java and C\#, but few have been applied to a higher-order lazy functional language, like Haskell. In this paper, we describe a sound and automatic static verification framework for Haskell, that is based on contracts and symbolic execution. Our approach is modular and gives precise blame assignments at compile-time in the presence of higher-order functions and laziness.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1480881.1480889},
    x-isbn = {978-1-60558-379-2},
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/1480881.1480889},
    xpages = {41--52},
    year = {2009}
}

@incollection{dvanhorn:Tov2010Stateful,
    author = {Tov, Jesse and Pucella, Riccardo},
    booktitle = {Programming Languages and Systems},
    chapter = {},
    citeulike-article-id = {7952300},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-11957-6\_29},
    citeulike-linkout-1 = {http://www.springerlink.com/content/bx1885218203p580},
    date-added = {2010-10-06 13:02:59},
    priority = {2},
    publisher = {Springer},
    title = {Stateful Contracts for Affine Types},
    x-abstract = {Affine type systems manage resources by preventing some values from being used more than once. This offers expressiveness and performance benefits, but difficulty arises in interacting with components written in a conventional language whose type system provides no way to maintain the affine type system\^{a}s aliasing invariants. We propose and implement a technique that uses behavioral contracts to mediate between code written in an affine language and code in a conventional typed language. We formalize our approach via a typed calculus with both affine-typed and conventionally-typed modules. We show how to preserve the guarantees of both type systems despite both languages being able to call into each other and exchange higher-order values.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-11957-6\_29},
    x-editor = {Gordon, Andrew},
    x-isbn = {978-3-642-11956-9},
    x-series = {LNCS},
    x-url = {http://dx.doi.org/10.1007/978-3-642-11957-6\_29},
    x-volume = {6012},
    xpages = {550--569},
    year = {2010}
}

@incollection{dvanhorn:Birkedal2008Simple,
    author = {Birkedal, Lars and Reus, Bernhard and Schwinghammer, Jan and Yang, Hongseok},
    booktitle = {Automata, Languages and Programming},
    citeulike-article-id = {7943640},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1427987.1428024},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-70583-3\_29},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-540-70583-3\_29},
    date-added = {2010-10-04 01:30:39},
    location = {Reykjavik, Iceland},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {A Simple Model of Separation Logic for {Higher-Order} Store},
    x-abstract = {Separation logic is a Hoare-style logic for reasoning about pointer-manipulating programs. Its core ideas have recently been extended from low-level to richer, high-level languages. In this paper we develop a new semantics of the logic for a programming language where code can be stored (i.e., with higher-order store). The main improvement on previous work is the simplicity of the model. As a consequence, several restrictions imposed by the semantics are removed, leading to a considerably more natural assertion language with a powerful specification logic.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-70583-3\_29},
    x-editor = {Aceto, Luca and Damg\r{a}rd, Ivan and Goldberg, LeslieAnn and Halld\'{o}rsson, Magn\'{u}sM and Ing\'{o}lfsd\'{o}ttir, Anna and Walukiewicz, Igor},
    x-isbn = {978-3-540-70582-6},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-70583-3\_29},
    x-volume = {5126},
    xpages = {348--360},
    year = {2008}
}

@article{dvanhorn:Streicher1998Classical,
    author = {Streicher, Thomas and Reus, Bernhard},
    citeulike-article-id = {7943637},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=969601},
    citeulike-linkout-1 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=44197},
    citeulike-linkout-2 = {http://dx.doi.org/10.1017/s0956796898003141},
    date-added = {2010-10-04 01:25:35},
    journal = {J. Funct. Program.},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Classical logic, continuation semantics and abstract machines},
    x-abstract = {One of the goals of this paper is to demonstrate that denotational semantics is useful for operational issues like implementation of functional languages by abstract machines. This is exemplified in a tutorial way by studying the case of extensional untyped call-by-name λ-calculus with Felleisen's control operator \&Cscr;. We derive the transition rules for an abstract machine from a continuation semantics which appears as a generalization of the ¬¬-translation known from logic. The resulting abstract machine appears as an extension of Krivine's machine implementing head reduction. Though the result, namely Krivine's machine, is well known our method of deriving it from continuation semantics is new and applicable to other languages (as e.g. call-by-value variants). Further new results are that Scott's  D ∞ -models are all instances of continuation models. Moreover, we extend our continuation semantics to Parigot's λμ-calculus from which we derive an extension of Krivine's machine for λμ-calculus. The relation between continuation semantics and the abstract machines is made precise by proving computational adequacy results employing an elegant method introduced by Pitts.},
    x-address = {New York, NY, USA},
    x-doi = {10.1017/s0956796898003141},
    x-issn = {0956-7968},
    x-number = {6},
    x-url = {http://dx.doi.org/10.1017/s0956796898003141},
    x-volume = {8},
    xpages = {543--572},
    year = {1998}
}

@inproceedings{dvanhorn:Greenberg2010Contracts,
    author = {Greenberg, Michael and Pierce, Benjamin C. and Weirich, Stephanie},
    booktitle = {POPL '10: Proceedings of the 37th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    booktitle = {POPL '10},
    citeulike-article-id = {7937685},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1706299.1706341},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1706299.1706341},
    date-added = {2010-10-01 22:32:44},
    location = {Madrid, Spain},
    priority = {2},
    publisher = {ACM},
    title = {Contracts made manifest},
    x-abstract = {Since Findler and Felleisen introduced higher-order contracts , many variants have been proposed. Broadly, these fall into two groups: some follow Findler and Felleisen in using latent  contracts, purely dynamic checks that are transparent to the type system; others use manifest  contracts, where refinement  types record the most recent check that has been applied to each value. These two approaches are commonly assumed to be equivalent---different ways of implementing the same idea, one retaining a simple type system, and the other providing more static information. Our goal is to formalize and clarify this folklore understanding. Our work extends that of Gronski and Flanagan, who defined a latent calculus λ C  and a manifest calculus λ H , gave a translation φ from λ C  to λ H , and proved that, if a λ C  term reduces to a constant, then so does its φ-image. We enrich their account with a translation Ψ from λ H  to λ C  and prove an analogous theorem. We then generalize the whole framework to dependent contracts , whose predicates can mention free variables. This extension is both pragmatically crucial, supporting a much more interesting range of contracts, and theoretically challenging. We define dependent versions of λ H  and two dialects ("lax" and "picky") of λ C , establish type soundness---a substantial result in itself, for λ H ---and extend φ and Ψ accordingly. Surprisingly, the intuition that the latent and manifest systems are equivalent now breaks down: the extended translations preserve behavior in one direction but, in the other, sometimes yield terms that blame more.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1706299.1706341},
    x-isbn = {978-1-60558-479-9},
    x-series = {POPL '10},
    x-url = {http://dx.doi.org/10.1145/1706299.1706341},
    xpages = {353--364},
    year = {2010}
}

@article{dvanhorn:Biernacka2007Concrete,
    author = {Biernacka, Malgorzata and Danvy, Olivier},
    citeulike-article-id = {7916623},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1297658.1297664},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1297658.1297664},
    date-added = {2010-09-28 16:20:35},
    journal = {ACM Trans. Comput. Logic},
    priority = {2},
    publisher = {ACM},
    title = {A concrete framework for environment machines},
    x-abstract = {We materialize the common understanding that calculi with explicit substitutions provide an intermediate step between an abstract specification of substitution in the lambda-calculus and its concrete implementations. To this end, we go back to Curien's original calculus of closures (an early calculus with explicit substitutions), we extend it minimally so that it can also express one-step reduction strategies, and we methodically derive a series of environment machines from the specification of two one-step reduction strategies for the lambda-calculus: normal order and applicative order. The derivation extends Danvy and Nielsen's refocusing-based construction of abstract machines with two new steps: one for coalescing two successive transitions into one, and the other for unfolding a closure into a term and an environment in the resulting abstract machine. The resulting environment machines include both the Krivine machine and the original version of Krivine's machine, Felleisen et al.'s {CEK} machine, and Leroy's Zinc abstract machine.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1297658.1297664},
    x-issn = {1529-3785},
    x-number = {1},
    x-url = {http://dx.doi.org/10.1145/1297658.1297664},
    x-volume = {9},
    xpages = {1--30},
    year = {2007}
}

@book{dvanhorn:RalphJohan1998Refinement,
    author = {Ralph Johan and Akademi, Abo and Von Wright, J.},
    citeulike-article-id = {3574348},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=551462},
    date-added = {2010-09-23 17:06:51},
    priority = {2},
    publisher = {Springer-Verlag New York, Inc.},
    title = {Refinement Calculus: A Systematic Introduction},
    x-abstract = {From the Publisher: The authors begin with a presentation of a new foundation for the refinement calculus based on lattice theory and higher order logic, together with a simple theory of program variables. The second part of the book describes the predicate transformer approach to programming logic and program semantics as well as the refinement calculus. The authors examine contracts, games, and program statements and show how their operational semantics is related to their predicate transformer interpretation. The third part of the book shows how to handle recursion and iteration in the refinement calculus and also describes how to use the calculus to reason about two-person games. Also presented are case studies of program refinement. In the final part, the book addresses specific issues related to program refinement, such as implementing specification statements, making refinements in context, and transforming iterative structures in a correctness preserving way. The book is intended for graduate and advanced undergraduate students interested in the mathematics and logic of systematic program construction as well as for programmers and researchers interested in a deeper understanding of these issues.},
    x-address = {Secaucus, NJ, USA},
    x-editor = {Schneider, F. B. and Gries, D.},
    x-isbn = {0387984178},
    x-url = {http://portal.acm.org/citation.cfm?id=551462},
    year = {1998}
}

@book{dvanhorn:milner97:ml-definition,
    author = {Milner, Robin and Tofte, Mads and Harper, Robert and MacQueen, David},
    citeulike-article-id = {113339},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262631814},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262631814},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262631814},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262631814},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262631814/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262631814},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262631814},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262631814},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262631814\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262631814},
    date-added = {2010-09-22 21:51:18},
    day = {15},
    edition = {Revised},
    howpublished = {Paperback},
    priority = {2},
    publisher = {The MIT Press},
    title = {The Definition of Standard {ML}},
    x-abstract = {Standard {ML} is a general-purpose programming language designed for large projects. This book provides a formal definition of Standard {ML} for the benefit of all concerned with the language, including users and implementers. Because computer programs are increasingly required to withstand rigorous analysis, it is all the more important that the language in which they are written be defined with full {rigor.One} purpose of a language definition is to establish a theory of meanings upon which the understanding of particular programs may rest. To properly define a programming language, it is necessary to use some form of notation other than a programming language. Given a concern for rigor, mathematical notation is an obvious choice. The authors have defined their semantic objects in mathematical notation that is completely independent of Standard {ML}.In defining a language one must also define the rules of evaluation precisely--that is, define what meaning results from evaluating any phrase of the language. The definition thus constitutes a formal specification for an implementation. The authors have developed enough of their theory to give sense to their rules of {evaluation.The} Definition of Standard {ML} is the essential point of reference for Standard {ML}. Since its publication in 1990, the implementation technology of the language has advanced enormously and the number of users has grown. The revised edition includes a number of new features, omits little-used features, and corrects mistakes of definition.},
    x-isbn = {0262631814},
    x-month = may,
    x-url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262631814},
    year = {1997}
}

@techreport{dvanhorn:plt-tr1,
    author = {Flatt, Matthew and {PLT}},
    booktitle = {\url{http://racket-lang.org/tr1/}},
    citeulike-article-id = {7870581},
    date-added = {2010-09-21 19:30:32},
    institution = {PLT Inc.},
    priority = {2},
    title = {Reference: Racket},
    x-number = {PLT-TR-2010-1},
    year = {2010}
}

@book{dvanhorn:StoyDenotational,
    author = {Stoy, Joseph},
    citeulike-article-id = {542159},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262191474},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262191474},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262191474},
    citeulike-linkout-3 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262191474/citeulike00-21},
    citeulike-linkout-4 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262191474},
    citeulike-linkout-5 = {http://www.worldcat.org/isbn/262191474},
    citeulike-linkout-6 = {http://books.google.com/books?vid=ISBN262191474},
    citeulike-linkout-7 = {http://www.amazon.com/gp/search?keywords=262191474\&index=books\&linkCode=qs},
    citeulike-linkout-8 = {http://www.librarything.com/isbn/262191474},
    date-added = {2010-09-13 21:11:49},
    howpublished = {{Unknown Binding}},
    priority = {2},
    publisher = {{MIT Press}},
    title = {Denotational semantics: The {Scott-Strachey} approach to programming language theory},
    x-abstract = {{"First book-length exposition of the denotational (or `mathematical' or `functional') approach to the formal semantics of programming languages (in contrast to `operational' and `axiomatic' approaches). Treats various kinds of languages, beginning with the pure-lambda-calculus and progressing through languages with states, commands, jumps, and assignments. This somewhat discursive account is a valuable compilation of results not otherwise available in a single source."<br /> -- <i>American Mathematical Monthly</i>}},
    x-isbn = {262191474},
    x-url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262191474}
}

@techreport{dvanhorn:Plotkin1981Structural,
    author = {Plotkin, G. D.},
    citeulike-article-id = {1437},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/plotkin81structural.html},
    citeulike-linkout-1 = {http://citeseer.lcs.mit.edu/plotkin81structural.html},
    citeulike-linkout-2 = {http://citeseer.ifi.unizh.ch/plotkin81structural.html},
    citeulike-linkout-3 = {http://citeseer.comp.nus.edu.sg/plotkin81structural.html},
    date-added = {2010-09-13 21:07:15},
    priority = {2},
    title = {A Structural Approach to Operational Semantics},
    x-abstract = {Syntax of a very simple programming language called L. What is
abstract about it will be discussed a little here and later at greater length. For us syntax is a
collection of syntactic sets of phrases; each set corresponds to a different type of phrase. Some
of these sets are very simple and can be taken as given:

Truthvalues This is the set T = ftt; ffg and is ranged over by (the metavariable) t (and
we also happily employ for this (and any other) metavariable sub- and super-scripts
to...},
    x-address = {University of Aarhus},
    x-number = {DAIMI FN-19},
    x-url = {http://citeseer.ist.psu.edu/plotkin81structural.html},
    year = {1981}
}

@phdthesis{dvanhorn:Felleisen1987Calculi,
    author = {Felleisen, Matthias},
    citeulike-article-id = {7818882},
    date-added = {2010-09-13 21:02:44},
    priority = {2},
    school = {Indiana University},
    title = {The Calculi of {Lambda-v-CS} Conversion: A Syntactic Theory of Control and State in Imperative {Higher-Order} Programming Languages},
    year = {1987}
}

@inproceedings{dvanhorn:Felleisen1986Control,
    author = {Felleisen, Matthias and Friedman, Daniel P.},
    booktitle = {Proc. of the IFIP TC 2/WG2. 2 Working Conf. on Formal Description of Programming Concepts Part III},
    citeulike-article-id = {7818856},
    date-added = {2010-09-13 20:58:16},
    location = {Ebberup, Denmark},
    priority = {2},
    title = {Control Operators, the {SECD}-Machine, and the {Lambda-Calculus}},
    x-month = aug,
    xpages = {193--219},
    year = {1986}
}

@inproceedings{dvanhorn:Klein2009Randomized,
    author = {Klein, Casey and Findler, Robert B.},
    booktitle = {Workshop on Scheme and Functional Programming},
    citeulike-article-id = {7801538},
    date-added = {2010-09-08 22:05:52},
    priority = {2},
    title = {Randomized Testing in {PLT} Redex},
    year = {2009}
}

@book{dvanhorn:Krishnamurthi2007Programming,
    author = {Krishnamurthi, Shriram},
    citeulike-article-id = {7801512},
    date-added = {2010-09-08 21:50:55},
    priority = {2},
    title = {Programming Languages: Application and Interpretation},
    x-month = apr,
    year = {2007}
}

@book{dvanhorn:Felleisen2001How,
    author = {Felleisen, Matthias and Findler, Robert B. and Flatt, Matthew and Krishnamurthi, Shriram},
    citeulike-article-id = {1396},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=369273},
    date-added = {2010-09-08 21:48:55},
    priority = {0},
    publisher = {MIT Press},
    title = {How to design programs: an introduction to programming and computing},
    x-address = {Cambridge, MA, USA},
    x-isbn = {0-262-06218-6},
    x-url = {http://portal.acm.org/citation.cfm?id=369273},
    year = {2001}
}

@inproceedings{dvanhorn:Krishnaswami2010Verifying,
    author = {Krishnaswami, Neel R. and Birkedal, Lars and Aldrich, Jonathan},
    booktitle = {TLDI '10: Proceedings of the 5th ACM SIGPLAN Workshop on Types in Language Design and Implementation},
    citeulike-article-id = {7801150},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1708016.1708025},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1708016.1708025},
    date-added = {2010-09-08 16:50:16},
    location = {Madrid, Spain},
    priority = {2},
    publisher = {ACM},
    title = {Verifying event-driven programs using ramified frame properties},
    x-abstract = {Interactive programs, such as {GUIs} or spreadsheets, often maintain dependency information over dynamically-created networks of objects. That is, each imperative object tracks not only the objects its own invariant depends on, but also all of the objects which depend upon it, in order to notify them when it changes.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1708016.1708025},
    x-isbn = {978-1-60558-891-9},
    x-url = {http://dx.doi.org/10.1145/1708016.1708025},
    xpages = {63--76},
    year = {2010}
}

@article{dvanhorn:Biering2007BIhyperdoctrines,
    author = {Biering, Bodil and Birkedal, Lars and Smith, Noah T.},
    citeulike-article-id = {2424543},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1275499},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1275497.1275499},
    date-added = {2010-09-08 16:47:20},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {{BI}-hyperdoctrines, higher-order separation logic, and abstraction},
    x-abstract = {We present a precise correspondence between separation logic and a simple notion of  predicate  {BI}, extending the earlier correspondence given between part of separation logic and  propositional  {BI}. Moreover, we introduce the notion of a {BI} hyperdoctrine, show that it soundly models classical and intuitionistic first- and higher-order predicate {BI}, and use it to show that we may easily extend separation logic to  higher-order . We also demonstrate that this extension is important for program proving, since it provides sound reasoning principles for data abstraction in the presence of aliasing.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1275497.1275499},
    x-issn = {0164-0925},
    x-month = aug,
    x-number = {5},
    x-url = {http://dx.doi.org/10.1145/1275497.1275499},
    x-volume = {29},
    xpages = {24+},
    year = {2007}
}

@inproceedings{dvanhorn:Turon2010Separation,
    author = {Turon, Aaron and Wand, Mitchell},
    booktitle = {Submitted to POPL '11},
    citeulike-article-id = {7800775},
    citeulike-linkout-0 = {http://www.ccs.neu.edu/home/turon/sepref/},
    date-added = {2010-09-08 15:02:18},
    priority = {2},
    title = {A separation logic for refining concurrent objects},
    x-url = {http://www.ccs.neu.edu/home/turon/sepref/},
    year = {2010}
}

@article{dvanhorn:Findler2002DrScheme,
    author = {Findler, Robert B. and Clements, John and Flanagan, Cormac and Flatt, Matthew and Krishnamurthi, Shriram and Steckler, Paul and Felleisen, Matthias},
    citeulike-article-id = {1383},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=968413.968416},
    citeulike-linkout-1 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=100085},
    citeulike-linkout-2 = {http://dx.doi.org/10.1017/s0956796801004208},
    date-added = {2010-09-08 07:17:47},
    journal = {JFP},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {DrScheme: a programming environment for {S}cheme},
    x-abstract = {{DrScheme} is a programming environment for Scheme. It fully integrates a graphics-enriched editor, a parser for multiple variants of Scheme, a functional read-eval-print loop, and an algebraic printer. The environment is especially useful for students, because it has a tower of syntactically restricted variants of Scheme that are designed to catch typical student mistakes and explain them in terms the students understand. The environment is also useful for professional programmers, due to its sophisticated programming tools, such as the static debugger, and its advanced language features, such as units and mixins. Beyond the ordinary programming environment tools, {DrScheme} provides an algebraic stepper, a context-sensitive syntax checker, and a static debugger. The stepper reduces Scheme programs to values, according to the reduction semantics of Scheme. It is useful for explaining the semantics of linguistic facilities and for studying the behavior of small programs. The syntax checker annotates programs with font and color changes based on the syntactic structure of the program. On demand, it draws arrows that point from bound to binding occurrences of identifiers. It also supports α-renaming. Finally, the static debugger provides a type inference system that explains specific inferences in terms of a value-flow graph, selectively overlaid on the program text.},
    x-doi = {10.1017/s0956796801004208},
    x-issn = {0956-7968},
    x-month = mar,
    x-number = {02},
    x-url = {http://dx.doi.org/10.1017/s0956796801004208},
    x-volume = {12},
    xpages = {159--182},
    year = {2002}
}

@inproceedings{dvanhorn:Bourdoncle1993Abstract,
    author = {Bourdoncle, Fran\c{c}ois},
    booktitle = {PLDI '93: Proceedings of the ACM SIGPLAN 1993 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {7796677},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=155090.155095},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/155090.155095},
    date-added = {2010-09-08 07:11:28},
    location = {Albuquerque, New Mexico, United States},
    priority = {2},
    publisher = {ACM},
    title = {Abstract debugging of higher-order imperative languages},
    x-abstract = {Abstract interpretation is a formal method that enables the static determination (i.e. at compile-time) of the dynamic properties (i.e. at run-time) of programs. We present an abstract interpretation-based method, called  abstract debugging , which enables the static and formal debugging of programs, prior to their execution, by finding the origin of potential bugs as well as necessary conditions for these bugs not to occur at run-time. We show how  invariant assertions  and  intermittent assertions , such as termination, can be used to formally debug programs. Finally, we show how abstract debugging can be effectively and efficiently applied to higher-order imperative programs with exceptions and jumps to non-local labels, and present the  Syntox  system that enables the abstract debugging of the  Pascal  language by the determination of the range of the scalar variables of programs.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/155090.155095},
    x-isbn = {0-89791-598-4},
    x-url = {http://dx.doi.org/10.1145/155090.155095},
    xpages = {46--55},
    year = {1993}
}

@inproceedings{dvanhorn:Flanagan1996Catching,
    author = {Flanagan, Cormac and Flatt, Matthew and Krishnamurthi, Shriram and Weirich, Stephanie and Felleisen, Matthias},
    booktitle = {PLDI '96: Proceedings of the ACM SIGPLAN 1996 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {4156},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=231387},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/231379.231387},
    date-added = {2010-09-08 06:52:44},
    location = {Philadelphia, Pennsylvania, United States},
    priority = {2},
    publisher = {ACM},
    title = {Catching bugs in the web of program invariants},
    x-abstract = {{MrSpidey} is a user-friendly, interactive static debugger for Scheme. A static debugger supplements the standard debugger by analyzing the program and pinpointing those program operations that may cause run-time errors such as dereferencing the null pointer or applying non-functions. The program analysis of {MrSpidey} computes value set descriptions for each term in the program and constructs a value flow graph connecting the set descriptions. Using the set descriptions, {MrSpidey} can identify and highlight potentially erroneous program operations, whose cause the programmer can then explore by selectively exposing portions of the value flow graph.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/231379.231387},
    x-isbn = {0-89791-795-2},
    x-issn = {0362-1340},
    x-month = may,
    x-series = {PLDI},
    x-url = {http://dx.doi.org/10.1145/231379.231387},
    xpages = {23--32},
    year = {1996}
}

@inproceedings{dvanhorn:Jackson2000Finding,
    author = {Jackson, Daniel and Vaziri, Mandana},
    booktitle = {ISSTA '00: Proceedings of the 2000 ACM SIGSOFT International Symposium on Software Testing and Analysis},
    citeulike-article-id = {801513},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=383378},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/347324.383378},
    date-added = {2010-09-08 06:47:42},
    location = {Portland, Oregon, United States},
    priority = {2},
    publisher = {ACM},
    title = {Finding bugs with a constraint solver},
    x-abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/347324.383378},
    x-isbn = {1-58113-266-2},
    x-url = {http://dx.doi.org/10.1145/347324.383378},
    xpages = {14--25},
    year = {2000}
}

@inproceedings{dvanhorn:Wrigstad2010Integrating,
    author = {Wrigstad, Tobias and Nardelli, Francesco Z. and Lebresne, Sylvain and \"{O}stlund, Johan and Vitek, Jan},
    booktitle = {POPL '10: Proceedings of the 37th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {6614670},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1706299.1706343},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1706299.1706343},
    date-added = {2010-09-08 06:24:27},
    location = {Madrid, Spain},
    priority = {2},
    publisher = {ACM},
    title = {Integrating typed and untyped code in a scripting language},
    x-abstract = {Many large software systems originate from untyped scripting language code. While good for initial development, the lack of static type annotations can impact code-quality and performance in the long run. We present an approach for integrating untyped code and typed code in the same system to allow an initial prototype to smoothly evolve into an efficient and robust program. We introduce  like types  , a novel intermediate point between dynamic and static typing. Occurrences of like types variables are checked statically within their scope but, as they may be bound to dynamic values, their usage is checked dynamically. Thus like types provide some of the benefits of static typing without decreasing the expressiveness of the language. We provide a formal account of like types in a core object calculus and evaluate their applicability in the context of a new scripting language.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1706299.1706343},
    x-isbn = {978-1-60558-479-9},
    x-url = {http://dx.doi.org/10.1145/1706299.1706343},
    xpages = {377--388},
    year = {2010}
}

@inproceedings{dvanhorn:Felleisen2010Adding,
    author = {Felleisen, Matthias},
    booktitle = {TLDI '10: Proceedings of the 5th ACM SIGPLAN workshop on Types in language design and implementation},
    citeulike-article-id = {7796653},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1708017},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1708016.1708017},
    date-added = {2010-09-08 06:24:05},
    location = {Madrid, Spain},
    priority = {2},
    publisher = {ACM},
    title = {Adding types to untyped languages},
    x-abstract = {Over the last 15 years, we have experienced a programming language renaissance. Numerous scripting languages have become widely used in industrial and open-source projects. They have supplemented the existing mainstream {languages--C}++ and Java--and, in contexts such as systems administration and web programming, they have started to play a dominant role.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1708016.1708017},
    x-isbn = {978-1-60558-891-9},
    x-url = {http://dx.doi.org/10.1145/1708016.1708017},
    xpages = {1--2},
    year = {2010}
}

@book{dvanhorn:Morgan1990Programming,
    author = {Morgan, Carroll},
    citeulike-article-id = {891640},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=95423},
    date-added = {2010-09-08 05:49:34},
    priority = {2},
    publisher = {Prentice-Hall, Inc.},
    title = {Programming from specifications},
    x-address = {Upper Saddle River, NJ, USA},
    x-isbn = {0-13-726225-6},
    x-url = {http://portal.acm.org/citation.cfm?id=95423},
    year = {1990}
}

@article{dvanhorn:Matthews2009Operational,
    author = {Matthews, Jacob and Findler, Robert B.},
    citeulike-article-id = {6347224},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1498926.1498930},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1498926.1498930},
    date-added = {2010-09-08 05:39:22},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {Operational semantics for multi-language programs},
    x-abstract = {Interoperability is big business, a fact to which .{NET}, the {JVM}, and {COM} can attest. Language designers are well aware of this, and they are designing programming languages that reflect it\&mdash;for instance, {SML}.{NET}, F\&num;, Mondrian, and Scala all treat interoperability as a central design feature. Still, current multi-language research tends not to focus on the semantics of these features, but only on how to implement them efficiently. In this article, we attempt to rectify that by giving a technique for specifying the operational semantics of a multi-language system as a composition of the models of its constituent languages. Our technique abstracts away the low-level details of interoperability like garbage collection and representation coherence, and lets us focus on semantic properties like type-safety, equivalence, and termination behavior. In doing so it allows us to adapt standard theoretical techniques such as subject-reduction, logical relations, and operational equivalence for use on multi-language systems. Generally speaking, our proofs of properties in a multi-language context are mutually referential versions of their single language counterparts.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1498926.1498930},
    x-issn = {0164-0925},
    x-number = {3},
    x-url = {http://dx.doi.org/10.1145/1498926.1498930},
    x-volume = {31},
    xpages = {1--44},
    year = {2009}
}

@phdthesis{dvanhorn:Clements2006Portable,
    author = {Clements, John},
    citeulike-article-id = {7796622},
    date-added = {2010-09-08 05:19:26},
    priority = {2},
    school = {Northeastern University},
    title = {Portable and {High-Level} Access to the Stack with Continuation Marks},
    x-month = feb,
    year = {2006}
}

@incollection{dvanhorn:VanHorn2008Flow,
    author = {Van{ }Horn, David and Mairson, Harry G.},
    booktitle = {Static Analysis},
    chapter = {17},
    citeulike-article-id = {5141450},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-69166-2\_17},
    citeulike-linkout-1 = {http://www.springerlink.com/content/x1n1193817682237},
    date-added = {2010-09-08 05:09:07},
    journal = {Static Analysis},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Flow Analysis, Linearity, and {PTIME}},
    x-abstract = {Flow analysis is a ubiquitous and much-studied component of compiler technology\^{a}and its variations abound. Amongst the most well known is Shivers\^{a} {0CFA}; however, the best known algorithm for {0CFA} requires time cubic in the size of the analyzed program and is unlikely to be improved. Consequently, several analyses have been designed to approximate {0CFA} by trading precision for faster computation. Henglein\^{a}s simple closure analysis, for example, forfeits the notion of directionality in flows and enjoys an  almost linear  time algorithm. But in making trade-offs between precision and complexity, what has been given up and what has been gained? Where do these analyses differ and where do they coincide?  We identify a core language\^{a}the linear \^{I}»-calculus\^{a}where {0CFA}, simple closure analysis, and many other known approximations or restrictions to {0CFA} are rendered identical. Moreover, for this core language, analysis corresponds with (instrumented) evaluation. Because analysis faithfully captures evaluation, and because the linear \^{I}»-calculus is complete for ptime, we derive ptime-completeness results for all of these analyses.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-540-69166-2\_17},
    x-editor = {Alpuente, Mar\'{\i}a and Vidal, Germ\'{a}n},
    x-isbn = {978-3-540-69163-1},
    x-issn = {0302-9743},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-540-69166-2\_17},
    x-volume = {5079},
    xpages = {255-269--269},
    year = {2008}
}

@book{dvanhorn:Meyer1997Objectoriented,
    author = {Meyer, Bertrand},
    citeulike-article-id = {1334997},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=261119},
    date-added = {2010-09-08 04:43:06},
    priority = {2},
    publisher = {Prentice-Hall, Inc.},
    title = {Object-oriented software construction (2nd ed.)},
    x-abstract = {An abstract is not available.},
    x-address = {Upper Saddle River, NJ, USA},
    x-isbn = {0-13-629155-4},
    x-url = {http://portal.acm.org/citation.cfm?id=261119},
    year = {1997}
}

@phdthesis{dvanhorn:Findler2002Behavioral,
    author = {Findler, Robert B.},
    citeulike-article-id = {7796576},
    date-added = {2010-09-08 04:31:47},
    priority = {2},
    school = {Rice University},
    title = {Behavioral Software Contracts},
    x-month = apr,
    year = {2002}
}

@inproceedings{dvanhorn:TobinHochstadt2006Interlanguage,
    author = {Tobin-Hochstadt, Sam and Felleisen, Matthias},
    booktitle = {OOPSLA '06: Companion to the 21st ACM SIGPLAN Symposium on Object-oriented Programming Systems, Languages, and Applications},
    citeulike-article-id = {2898851},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1176617.1176755},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1176617.1176755},
    date-added = {2010-09-08 04:06:24},
    location = {Portland, Oregon, USA},
    priority = {2},
    publisher = {ACM},
    title = {Interlanguage migration: from scripts to programs},
    x-abstract = {As scripts grow into full-fledged applications, programmers should want to port portions of their programs from scripting languages to languages with sound and rich type systems. This form of interlanguage migration ensures type-safety and provides minimal guarantees for reuse in other applications, {too.In} this paper, we present a framework for expressing this form of interlanguage migration. Given a program that consists of modules in the untyped lambda calculus, we prove that rewriting one of them in a simply typed lambda calculus produces an equivalent program and adds the expected amount of type safety, i.e.,  code in typed modules can't go wrong . To ensure these guarantees, the migration process infers constraints from the statically typed module and imposes them on the dynamically typed modules in the form of behavioral contracts.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1176617.1176755},
    x-isbn = {1-59593-491-X},
    x-url = {http://dx.doi.org/10.1145/1176617.1176755},
    xpages = {964--974},
    year = {2006}
}

@inproceedings{dvanhorn:TobinHochstadt2010Logical,
    author = {Tobin-Hochstadt, Sam and Felleisen, Matthias},
    booktitle = {ICFP '10: International Conference on Functional Programming},
    citeulike-article-id = {7796548},
    date-added = {2010-09-08 04:04:27},
    priority = {2},
    publisher = {ACM},
    title = {Logical Types for Untyped Languages},
    x-month = sep,
    x-series = {ICFP},
    year = {2010}
}

@phdthesis{dvanhorn:TobinHochstadt2010Typed,
    author = {Tobin-Hochstadt, Sam},
    citeulike-article-id = {7796546},
    date-added = {2010-09-08 04:01:17},
    priority = {2},
    school = {Northeastern University},
    title = {Typed Scheme: From Scripts to Programs},
    x-month = jan,
    year = {2010}
}

@inproceedings{dvanhorn:Dimoulas2009Future,
    author = {Dimoulas, Christos and Pucella, Riccardo and Felleisen, Matthias},
    booktitle = {PPDP '09: Proceedings of the 11th ACM SIGPLAN Conference on Principles and Practice of Declarative Programming},
    citeulike-article-id = {7796542},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1599410.1599435},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1599410.1599435},
    date-added = {2010-09-08 03:56:11},
    location = {Coimbra, Portugal},
    priority = {2},
    publisher = {ACM},
    title = {Future contracts},
    x-abstract = {Many recent research projects focus on language support for behavioral software contracts, that is, assertions that govern the boundaries between software building blocks such as procedures, classes, or modules. Contracts primarily help locate bugs in programs, but they also tend to affect the performance of the program, especially as they become complex.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1599410.1599435},
    x-isbn = {978-1-60558-568-0},
    x-url = {http://dx.doi.org/10.1145/1599410.1599435},
    xpages = {195--206},
    year = {2009}
}

@article{dvanhorn:Flanagan1999Semantics,
    author = {Flanagan, C. and Felleisen, M.},
    citeulike-article-id = {7796538},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=44231},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796899003329},
    date-added = {2010-09-08 03:52:19},
    journal = {Journal of Functional Programming},
    priority = {2},
    title = {The semantics of future and an application},
    x-abstract = {The future annotation of {MultiLisp} provides a simple method for taming the implicit parallelism of functional programs. Prior research on future has concentrated on implementation and design issues, and has largely ignored the development of a semantic characterization of future. This paper considers an idealized functional language with futures and presents a series of operational semantics with increasing degrees of intensionality. The first semantics defines future to be a semantically transparent annotation. The second semantics interprets a future expression as a potentially parallel task. The third semantics explicates the coordination of parallel tasks by introducing placeholder objects and touch {operations.We} use the last semantics to derive a program analysis algorithm and an optimization algorithm that removes provably redundant touch operations. Experiments with the Gambit compiler indicate that this optimization significantly reduces the overhead imposed by touch operations.},
    x-doi = {10.1017/s0956796899003329},
    x-number = {01},
    x-url = {http://dx.doi.org/10.1017/s0956796899003329},
    x-volume = {9},
    xpages = {1--31},
    year = {1999}
}

@inproceedings{dvanhorn:Lerner2002Composing,
    author = {Lerner, Sorin and Grove, David and Chambers, Craig},
    booktitle = {POPL '02: Proceedings of the 29th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {225304},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=503298},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/503272.503298},
    date-added = {2010-09-08 03:41:56},
    location = {Portland, Oregon},
    priority = {2},
    publisher = {ACM},
    title = {Composing dataflow analyses and transformations},
    x-abstract = {Dataflow analyses can have mutually beneficial interactions. Previous efforts to exploit these interactions have either (1) iteratively performed each individual analysis until no further improvements are discovered or (2) developed "super-analyses" that manually combine conceptually separate analyses. We have devised a new approach that allows analyses to be defined independently while still enabling them to be combined automatically and profitably. Our approach avoids the loss of precision associated with iterating individual analyses and the implementation difficulties of manually writing a super-analysis. The key to our approach is a novel method of implicit communication between the individual components of a super-analysis based on graph transformations. In this paper, we precisely define our approach; we demonstrate that it is sound and it terminates; finally we give experimental results showing that in practice (1) our framework produces results at least as precise as iterating the individual analyses while compiling at least 5 times faster, and (2) our framework achieves the same precision as a manually written super-analysis while incurring a compile-time overhead of less than 20\%.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/503272.503298},
    x-isbn = {1-58113-450-9},
    x-month = jan,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1145/503272.503298},
    x-volume = {37},
    xpages = {270--282},
    year = {2002}
}

@phdthesis{dvanhorn:VanHorn2009Complexity,
    author = {Van{ }Horn, David},
    citeulike-article-id = {7796521},
    date-added = {2010-09-08 03:28:14},
    priority = {2},
    school = {Brandeis University},
    title = {The Complexity of Flow Analysis in {Higher-Order} Languages},
    x-month = aug,
    year = {2009}
}

@techreport{dvanhorn:Earl2011StackSummarizing,
    author = {Earl, Christopher and Might, Matt and Van Horn, David},
    citeulike-article-id = {7796516},
    date-added = {2010-09-08 03:18:43},
    priority = {2},
    title = {{Stack-Summarizing} {Control-Flow} Analysis of {Higher-Order} Programs},
    year = {2011}
}

@inproceedings{dvanhorn:Chang2010Evaluating,
    author = {Chang, Stephen and Van{ }Horn, David and Felleisen, Matthias},
    booktitle = {Trends in Functional Programming},
    citeulike-article-id = {7796514},
    date-added = {2010-09-08 03:14:41},
    priority = {2},
    title = {Evaluating Call By Need on the Control Stack},
    x-series = {LNCS},
    year = {2010}
}

@inproceedings{dvanhorn:Earl2010Pushdown,
    author = {Earl, Christopher and Might, Matthew and Van Horn, David},
    booktitle = {Workshop on Scheme and Functional Programming},
    citeulike-article-id = {7750284},
    date-added = {2010-08-31 18:27:47},
    priority = {2},
    title = {Pushdown control-flow analysis of higher-order programs},
    year = {2010}
}

@incollection{dvanhorn:Navabi2009Exceptionally,
    author = {Navabi, Armand and Jagannathan, Suresh},
    booktitle = {Coordination Models and Languages},
    chapter = {3},
    citeulike-article-id = {7750280},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-02053-7\_3},
    citeulike-linkout-1 = {http://www.springerlink.com/content/n2780775v1545662},
    date-added = {2010-08-31 18:23:22},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Exceptionally Safe Futures},
    x-abstract = {A future is a well-known programming construct used to introduce concurrency to sequential programs. Computations annotated as futures are executed asynchronously and run concurrently with their continuations. Typically, futures are not transparent annotations: a program with futures need not produce the same result as the sequential program from which it was derived. Safe futures guarantee a future-annotated program produce the same result as its sequential counterpart. Ensuring safety is especially challenging in the presence of constructs such as exceptions that permit the expression of non-local control-flow. For example, a future may raise an exception whose handler is in its continuation. To ensure safety, we must guarantee the continuation does not discard this handler regardless of the continuation's own internal control-flow (e.g. exceptions it raises or futures it spawns). In this paper, we present a formulation of safe futures for a higher-order functional language with first-class exceptions. Safety can be guaranteed dynamically by stalling the execution of a continuation that has an exception handler potentially required by its future until the future completes. To enable greater concurrency, we develop a static analysis and instrumentation and formalize the runtime behavior for instrumented programs that allows execution to discard handlers precisely when it is safe to do so.},
    x-address = {Berlin, Heidelberg},
    x-doi = {10.1007/978-3-642-02053-7\_3},
    x-editor = {Field, John and Vasconcelos, Vasco},
    x-isbn = {978-3-642-02052-0},
    x-series = {Lecture Notes in Computer Science},
    x-url = {http://dx.doi.org/10.1007/978-3-642-02053-7\_3},
    x-volume = {5521},
    xpages = {47--65},
    year = {2009}
}

@article{dvanhorn:Debray1997Interprocedural,
    author = {Debray, Saumya K. and Proebsting, Todd A.},
    citeulike-article-id = {7736808},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=262004.262006},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/262004.262006},
    date-added = {2010-08-30 04:38:54},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {Interprocedural control flow analysis of first-order programs with tail-call optimization},
    x-abstract = {Knowledge of low-level control flow is essential for many compiler optimizations. In systems with tail-call optimization, the determination of interprocedural control flow is complicated by the fact that because of tail-call optimization, control flow at procedure returns is not readily evident from the call graph of the program. This article shows how interprocedural control-flow analysis of first-order programs can be carried out using well-known concepts from parsing theory. In particular, we show that context-insensitive ( or zeroth-order) control-flow analysis corresponds to the notion of {FOLLOW} sets in context-free grammars, while context-sensitive (or first-order) control-flow analysis corresponds to the notion of {LR}(1) items. The control-flow information so obtained can be used to improve the precision of interprocedural dataflow analyses as well as to extend certain low-level code optimizations across procedure boundaries.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/262004.262006},
    x-issn = {0164-0925},
    x-number = {4},
    x-url = {http://dx.doi.org/10.1145/262004.262006},
    x-volume = {19},
    xpages = {568--585},
    year = {1997}
}

@inproceedings{dvanhorn:Serrano1995Control,
    author = {Serrano, Manuel},
    booktitle = {SAC '95: Proceedings of the 1995 ACM Symposium on Applied Computing},
    booktitle = {SAC '95},
    citeulike-article-id = {7630241},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=315891.315934},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/315891.315934},
    date-added = {2010-08-13 01:58:30},
    location = {Nashville, Tennessee, United States},
    priority = {0},
    publisher = {ACM},
    title = {Control flow analysis: a functional languages compilation paradigm},
    x-abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/315891.315934},
    x-isbn = {0-89791-658-1},
    x-url = {http://dx.doi.org/10.1145/315891.315934},
    xpages = {118--122},
    year = {1995}
}

@article{dvanhorn:Felleisen1992Revised,
    author = {Felleisen, M.},
    citeulike-article-id = {1373},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=136293.136297},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/0304-3975(92)90014-7},
    date-added = {2010-07-29 21:29:00},
    day = {14},
    journal = {Theoretical Computer Science},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {The revised report on the syntactic theories of sequential control and state},
    x-abstract = {The syntactic theories of control and state are conservative extensions of the λ υ -calculus for equational reasoning about imperative programming facilities in higher-order languages. Unlike the simple λ υ -calculus, the extended theories are mixtures of equivalence relations and compatible congruence relations on the term language, which significantly complicates the reasoning process. In this paper we develop fully compatible equational theories of the same imperative higher-order programming languages. The new theories subsume the original calculi of control and state and satisfy the usual {Church–Rosser} and Standardization Theorems. With the new calculi, equational reasoning about imperative programs becomes as simple as reasoning about functional programs.},
    x-doi = {10.1016/0304-3975(92)90014-7},
    x-issn = {03043975},
    x-month = sep,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1016/0304-3975(92)90014-7},
    x-volume = {103},
    xpages = {235--271},
    year = {1992}
}

@article{dvanhorn:Wright1994Syntactic,
    author = {Wright, Andrew K. and Felleisen, Matthias},
    citeulike-article-id = {1374},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=191905.191909},
    citeulike-linkout-1 = {http://dx.doi.org/10.1006/inco.1994.1093},
    date-added = {2010-07-28 21:39:27},
    day = {15},
    journal = {Information and Computation},
    priority = {2},
    publisher = {Academic Press, Inc.},
    title = {A Syntactic Approach to Type Soundness},
    x-abstract = {We present a new approach to proving type soundness for {Hindley/Milner}-style polymorphic type systems. The keys to our approach are (1) an adaptation of subject reduction theorems from combinatory logic to programming languages, and (2) the use of rewriting techniques for the specification of the language semantics. The approach easily extends from polymorphic functional languages to imperative languages that provide references, exceptions, continuations, and similar features. We illustrate the technique with a type soundness theorem for the core of Standard {ML}, which includes the first type soundness proof for polymorphic exceptions and continuations.},
    x-doi = {10.1006/inco.1994.1093},
    x-issn = {08905401},
    x-month = nov,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1006/inco.1994.1093},
    x-volume = {115},
    xpages = {38--94},
    year = {1994}
}

@phdthesis{dvanhorn:Flanagan1997Effective,
    author = {Flanagan, Cormac},
    citeulike-article-id = {7546648},
    date-added = {2010-07-28 01:46:46},
    priority = {2},
    school = {Rice University},
    title = {Effective Static Debugging via Componential {Set-Based} Analysis},
    x-month = may,
    year = {1997}
}

@phdthesis{dvanhorn:Meunier2006Diss,
    author = {Meunier, Philippe},
    citeulike-article-id = {7544563},
    date-added = {2010-07-27 15:18:41},
    priority = {2},
    school = {Northeastern University},
    title = {Modular {Set-Based} Analysis from Contracts},
    x-month = may,
    year = {2006}
}

@article{dvanhorn:Lee2002Proof,
    author = {Lee, Oukseh and Yi, Kwangkeun and Paek, Yunheung},
    citeulike-article-id = {7537317},
    date-added = {2010-07-24 18:48:22},
    journal = {IPL},
    priority = {2},
    publisher = {Elsevier},
    title = {A proof method for the correctness of modularized {0CFA}},
    x-volume = {81},
    xpages = {179--185},
    year = {2002}
}

@article{dvanhorn:Cousot2002Constructive,
    author = {Cousot, Patrick},
    citeulike-article-id = {4298357},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=567195.567197},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/s0304-3975(00)00313-3},
    date-added = {2010-07-24 18:03:11},
    day = {28},
    journal = {Theor. Comput. Sci.},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {Constructive design of a hierarchy of semantics of a transition system by abstract interpretation},
    x-abstract = {We construct a hierarchy of semantics by successive abstract interpretations. Starting from the maximal trace semantics of a transition system, we derive the big-step semantics, termination and nontermination semantics, Plotkin's natural, Smyth's demoniac and Hoare's angelic relational semantics and equivalent nondeterministic denotational semantics (with alternative powerdomains to the {Egli-Milner} and Smyth constructions), D. Scott's deterministic denotational semantics, the generalized and Dijkstra's conservative/liberal predicate transformer semantics, the generalized/total and Hoare's partial correctness axiomatic semantics and the corresponding proof methods. All the semantics are presented in a uniform fixpoint form and the correspondences between these semantics are established through composable Galois connections, each semantics being formally calculated by abstract interpretation of a more concrete one using Kleene and/or Tarski fixpoint approximation transfer theorems. Copyright 2002 Elsevier Science {B.V}.},
    x-address = {Essex, UK},
    x-doi = {10.1016/s0304-3975(00)00313-3},
    x-issn = {0304-3975},
    x-month = apr,
    x-number = {1-2},
    x-url = {http://dx.doi.org/10.1016/s0304-3975(00)00313-3},
    x-volume = {277},
    xpages = {47--103},
    year = {2002}
}

@article{dvanhorn:Cousot2007Biinductive,
    author = {Cousot, P. and Cousot, R.},
    citeulike-article-id = {7537287},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1298822},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.entcs.2007.08.015},
    date-added = {2010-07-24 17:35:44},
    day = {24},
    journal = {Electron. Notes Theor. Comput. Sci.},
    priority = {2},
    publisher = {Elsevier Science Publishers B. V.},
    title = {Bi-inductive Structural Semantics (Extended Abstract)},
    x-abstract = {We propose a simple order-theoretic generalization of set-theoretic inductive definitions. This generalization covers inductive, co-inductive and bi-inductive definitions and is preserved by abstraction. This allows the structural operational semantics to describe simultaneously the finite/terminating and infinite/diverging behaviors of programs. This is illustrated on the structural bifinitary small/big-step trace/relational/operational semantics of the call-by-value @l-calculus.},
    x-address = {Amsterdam, The Netherlands, The Netherlands},
    x-doi = {10.1016/j.entcs.2007.08.015},
    x-issn = {1571-0661},
    x-month = oct,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1016/j.entcs.2007.08.015},
    x-volume = {192},
    xpages = {29--44},
    year = {2007}
}

@article{dvanhorn:Jensen2002Types,
    author = {Jensen, Thomas},
    citeulike-article-id = {7537279},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=860267},
    date-added = {2010-07-24 17:22:23},
    priority = {2},
    publisher = {Springer-Verlag New York, Inc.},
    title = {Types in program analysis},
    x-abstract = {This paper surveys type-based program analysis with an emphasis on the polyvariant program analyses that can be obtained using conjunctive (or intersection) types and parametric polymorphism. In particular, we show 1) how binding-time analysis and strictness analysis are variations of a common framework based on conjunctive types, 2) that the standard abstract interpretation used for strictness analysis is equivalent to the type-based analysis, and 3) that the conjunctive strictness analysis can be made more modular by blending conjunctions with parametric polymorphism.},
    x-address = {New York, NY, USA},
    x-isbn = {3-540-00326-6},
    x-url = {http://portal.acm.org/citation.cfm?id=860267},
    xpages = {204--222},
    year = {2002}
}

@inproceedings{dvanhorn:Reppy2006Typesensitive,
    author = {Reppy, John},
    booktitle = {ML '06: Proceedings of the 2006 Workshop on ML},
    booktitle = {ML '06},
    citeulike-article-id = {1352870},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1159888},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1159876.1159888},
    date-added = {2010-07-24 17:20:49},
    location = {Portland, Oregon, USA},
    priority = {2},
    publisher = {ACM},
    title = {Type-sensitive control-flow analysis},
    x-abstract = {Higher-order typed languages, such as {ML}, provide strong support for data and type abstraction. While such abstraction is often viewed as costing performance, there are situations where it may provide opportunities for more aggressive program optimization. Specifically, we can exploit the fact that type abstraction guarantees representation independence, which allows the compiler to specialize data representations. This paper describes a first step in supporting such optimizations; namely a control-flow analysis that uses the program's type information to compute more precise results. We present our algorithm as an extension of Serrano's version of {0-CFA} and we show that it respects types. We also discuss applications of the analysis with examples of optimizations enabled by the analysis that would not be possible using normal {CFA}.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1159876.1159888},
    x-isbn = {1-59593-483-9},
    x-url = {http://dx.doi.org/10.1145/1159876.1159888},
    xpages = {74--83},
    year = {2006}
}

@inproceedings{dvanhorn:Cousot1997Types,
    author = {Cousot, Patrick},
    booktitle = {POPL '97: Proceedings of the 24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    booktitle = {POPL '97},
    citeulike-article-id = {2805371},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=263744},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/263699.263744},
    date-added = {2010-07-24 17:01:41},
    location = {Paris, France},
    priority = {0},
    publisher = {ACM},
    title = {Types as abstract interpretations},
    x-abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/263699.263744},
    x-isbn = {0-89791-853-3},
    x-url = {http://dx.doi.org/10.1145/263699.263744},
    xpages = {316--331},
    year = {1997}
}

@inproceedings{dvanhorn:Shao1994Spaceefficient,
    author = {Shao, Zhong and Appel, Andrew W.},
    booktitle = {LFP '94: Proceedings of the 1994 ACM Conference on LISP and Functional Programming},
    citeulike-article-id = {7536656},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=182409.156783},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/182409.156783},
    date-added = {2010-07-24 02:08:41},
    location = {Orlando, Florida, United States},
    priority = {0},
    publisher = {ACM},
    title = {Space-efficient closure representations},
    x-abstract = {Many modern compilers implement function calls (or returns) in two steps: first, a  closure  environment is properly installed to provide access for free variables in the target program fragment; second, the control is transferred to the target by a  ” jump with arguments (or results)”.  Closure conversion , which decides where and how to represent closures at runtime, is a crucial step in compilation of functional languages. We have a new algorithm that exploits the use of compile-time control and data flow information to optimize closure representations. By extensive closure sharing and allocating as many closures in registers as possible, our new closure conversion algorithm reduces heap allocation by 36\% and memory fetches for local/global variables by 43\%; and improves the already-efficient code generated by the Standard {ML} of New Jersey compiler by about 17\% on a {DECstation} 5000. Moreover, unlike most other approaches, our new closure allocation scheme satisfies the strong  ” safe for space complexity” rule, thus achieving good asymptotic space usage.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/182409.156783},
    x-isbn = {0-89791-643-3},
    x-series = {LFP '94},
    x-url = {http://dx.doi.org/10.1145/182409.156783},
    xpages = {150--161},
    year = {1994}
}

@inproceedings{dvanhorn:Stefanescu1994Equational,
    author = {Stefanescu, Dan and Zhou, Yuli},
    booktitle = {LFP '94: Proceedings of the 1994 ACM conference on LISP and functional programming},
    citeulike-article-id = {7536649},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=182409.182497},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/182409.182497},
    date-added = {2010-07-24 01:46:12},
    location = {Orlando, Florida, United States},
    priority = {2},
    publisher = {ACM},
    title = {An equational framework for the flow analysis of higher order functional programs},
    x-abstract = {We present a simple method for the general flow analysis of high-order functional programs. The method computes an abstraction of the program's runtime environment via a system of monotonic equations. As the environment can grow unbounded, we exploit patterns in the program's control structure (i.e., the call-tree) to determine some static partition of the environment, and merge points in the environment belonging to the same equivalent-class. High order functions are handled by embedding control information into closures. The method is proven correct with respect to a rewriting system based operational semantics. Various implementation issues are also considered.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/182409.182497},
    x-isbn = {0-89791-643-3},
    x-url = {http://dx.doi.org/10.1145/182409.182497},
    xpages = {318--327},
    year = {1994}
}

@inproceedings{dvanhorn:Jones1982Flexible,
    author = {Jones, Neil D. and Muchnick, Steven S.},
    booktitle = {POPL '82: Proceedings of the 9th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {1567509},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=582161},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/582153.582161},
    date-added = {2010-07-23 23:50:09},
    location = {Albuquerque, New Mexico},
    priority = {0},
    publisher = {ACM},
    title = {A flexible approach to interprocedural data flow analysis and programs with recursive data structures},
    x-abstract = {A new approach to data flow analysis of procedural programs and programs with recursive data structures is described. The method depends on simulation of the interpreter for the subject programming language using a retrieval function to approximate a program's data structures.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/582153.582161},
    x-isbn = {0-89791-065-6},
    x-series = {POPL '82},
    x-url = {http://dx.doi.org/10.1145/582153.582161},
    xpages = {66--74},
    year = {1982}
}

@phdthesis{dvanhorn:Danvy:DSc,
    author = {Danvy, Olivier},
    citeulike-article-id = {7531722},
    date-added = {2010-07-23 01:44:36},
    priority = {0},
    school = {Department of Computer Science, Aarhus University},
    title = {An Analytical Approach to Program as Data Objects},
    type = {{DSc} thesis},
    x-address = {Aarhus, Denmark},
    x-month = oct,
    year = {2006}
}

@inproceedings{dvanhorn:Clements2001Modeling,
    author = {Clements, John and Flatt, Matthew and Felleisen, Matthias},
    booktitle = {ESOP '01: Proceedings of the 10th European Symposium on Programming Languages and Systems},
    citeulike-article-id = {7531167},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=645395.651947},
    date-added = {2010-07-22 16:51:36},
    priority = {0},
    publisher = {Springer-Verlag},
    title = {Modeling an Algebraic Stepper},
    x-address = {London, UK},
    x-isbn = {3-540-41862-8},
    x-url = {http://portal.acm.org/citation.cfm?id=645395.651947},
    xpages = {320--334},
    year = {2001}
}

@article{dvanhorn:Cousot1992Abstract,
    author = {Cousot, Patrick and Cousot, Radhia},
    citeulike-article-id = {4253516},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/logcom/2.4.511},
    citeulike-linkout-1 = {http://logcom.oxfordjournals.org/cgi/content/abstract/2/4/511},
    date-added = {2010-07-19 06:01:12},
    day = {1},
    journal = {J Logic Computation},
    priority = {2},
    title = {Abstract Interpretation Frameworks},
    x-abstract = {We introduce abstract interpretation frameworks which are variations on the archetypal framework using Galois connections between concrete and abstract semantics, widenings and narrowings and are obtained by relaxation of the original hypotheses. We consider various ways of establishing the correctness of an abstract interpretation depending on how the relation between the concrete and abstract semantics is denned. We insist upon those correspondences allowing for the inducing of the approximate abstract semantics from the concrete one. Furthermore we study various notions of widening and narrowing as a means of obtaining convergence in the iterations used in abstract interpretation. 10.1093/logcom/2.4.511},
    x-doi = {10.1093/logcom/2.4.511},
    x-month = aug,
    x-number = {4},
    x-url = {http://dx.doi.org/10.1093/logcom/2.4.511},
    x-volume = {2},
    xpages = {511--547},
    year = {1992}
}

@inproceedings{dvanhorn:DBLP:conf/esop/VardoulakisS10,
    author = {Vardoulakis, Dimitrios and Shivers, Olin},
    booktitle = {European Symposium on Programming (ESOP)},
    citeulike-article-id = {6865796},
    date-added = {2010-07-18 16:37:39},
    priority = {0},
    publisher = {Springer},
    title = {CFA2: a {C}ontext-{F}ree {A}pproach to {C}ontrol-{F}low {A}nalysis},
    x-issn = {0302-9743},
    x-series = {LNCS},
    x-volume = {6012},
    xpages = {570--589},
    year = {2010}
}

@inproceedings{dvanhorn:Ong2006ModelChecking,
    author = {Ong, C. H. Luke},
    booktitle = {21st Annual IEEE Symposium on Logic in Computer Science (LICS'06)},
    citeulike-article-id = {6941050},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/LICS.2006.38},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/lics.2006.38},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1691219},
    date-added = {2010-07-18 16:08:34},
    journal = {Logic in Computer Science, Symposium on},
    location = {Seattle, WA, USA},
    priority = {2},
    publisher = {IEEE},
    title = {On {Model-Checking} Trees Generated by {Higher-Order} Recursion Schemes},
    x-abstract = {We prove that the modal mu-calculus model-checking problem for (ranked and ordered) node-labelled trees that are generated by order-n recursion schemes (whether safe or not, and whether homogeneously typed or not) is {n-EXPTIME} complete, for every nges0. It follows that the monadic second-order theories of these trees are decidable. There are three major ingredients. The first is a certain transference principle from the tree generated by the scheme - the value tree - to an auxiliary computation tree, which is itself a tree generated by a related order-0 recursion scheme (equivalently, a regular tree). Using innocent game semantics in the sense of Hyland and Ong, we establish a strong correspondence between paths in the value tree and traversals in the computation tree. This allows us to prove that a given alternating parity tree automaton ({APT}) has an (accepting) run-tree over the value tree iff it has an (accepting) traversal-tree over the computation tree. The second ingredient is the simulation of an (accepting) traversal-tree by a certain set of annotated paths over the computation tree; we introduce traversal-simulating {APT} as a recognising device for the latter. Finally, for the complexity result, we prove that traversal-simulating {APT} enjoy a succinctness property: for deciding acceptance, it is enough to consider run-trees that have a reduced branching factor. The desired bound is then obtained by analysing the complexity of solving an associated (finite) acceptance parity game},
    x-address = {Los Alamitos, CA, USA},
    x-doi = {10.1109/lics.2006.38},
    x-isbn = {0-7695-2631-4},
    x-issn = {1043-6871},
    x-series = {LICS},
    x-url = {http://dx.doi.org/10.1109/lics.2006.38},
    xpages = {81--90},
    year = {2006}
}

@inproceedings{dvanhorn:Findler2002Contracts,
    author = {Findler, Robert B. and Felleisen, Matthias},
    booktitle = {ICFP '02: Proceedings of the seventh ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {1362},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=581484},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/581478.581484},
    date-added = {2010-07-09 01:23:47},
    location = {Pittsburgh, PA, USA},
    priority = {0},
    publisher = {ACM},
    title = {Contracts for higher-order functions},
    x-abstract = {Assertions play an important role in the construction of robust software. Their use in programming languages dates back to the 1970s. Eiffel, an object-oriented programming language, wholeheartedly adopted assertions and developed the "Design by Contract" philosophy. Indeed, the entire object-oriented community recognizes the value of assertion-based contracts on {methods.In} contrast, languages with higher-order functions do not support assertion-based contracts. Because predicates on functions are, in general, undecidable, specifying such predicates appears to be meaningless. Instead, the functional languages community developed type systems that statically approximate interesting {predicates.In} this paper, we show how to support higher-order function contracts in a theoretically well-founded and practically viable manner. Specifically, we introduce λ con , a typed lambda calculus with assertions for higher-order functions. The calculus models the assertion monitoring system that we employ in {DrScheme}. We establish basic properties of the model (type soundness, etc.) and illustrate the usefulness of contract checking with examples from {DrScheme}'s code {base.We} believe that the development of an assertion system for higher-order functions serves two purposes. On one hand, the system has strong practical potential because existing type systems simply cannot express many assertions that programmers would like to state. On the other hand, an inspection of a large base of invariants may provide inspiration for the direction of practical future type system research.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/581478.581484},
    x-isbn = {1-58113-487-8},
    x-issn = {0362-1340},
    x-month = sep,
    x-series = {ICFP},
    x-url = {http://dx.doi.org/10.1145/581478.581484},
    xpages = {48--59},
    year = {2002}
}

@inproceedings{dvanhorn:Meunier2006Modular,
    author = {Meunier, Philippe and Findler, Robert B. and Felleisen, Matthias},
    booktitle = {POPL '06: Conference record of the 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    booktitle = {POPL '06},
    citeulike-article-id = {524959},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1111057},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1111037.1111057},
    date-added = {2010-07-08 22:56:31},
    location = {Charleston, South Carolina, USA},
    priority = {0},
    publisher = {ACM},
    title = {Modular set-based analysis from contracts},
    x-abstract = {In {PLT} Scheme, programs consist of modules with contracts. The latter describe the inputs and outputs of functions and objects via predicates. A run-time system enforces these predicates; if a predicate fails, the enforcer raises an exception that blames a specific module with an explanation of the {fault.In} this paper, we show how to use such module contracts to turn set-based analysis into a fully modular parameterized analysis. Using this analysis, a static debugger can indicate for any given contract check whether the corresponding predicate is always satisfied, partially satisfied, or (potentially) completely violated. The static debugger can also predict the source of potential errors, i.e., it is sound with respect to the blame assignment of the contract system.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1111037.1111057},
    x-isbn = {1-59593-027-2},
    x-month = jan,
    x-series = {POPL},
    x-url = {http://dx.doi.org/10.1145/1111037.1111057},
    xpages = {218--231},
    year = {2006}
}

@phdthesis{dvanhorn:Klop1980Combinatory,
    author = {Klop, Jan W.},
    citeulike-article-id = {7333194},
    date-added = {2010-06-17 03:34:30},
    priority = {2},
    school = {Utrecht University},
    title = {Combinatory Reduction Systems},
    year = {1980}
}

@incollection{dvanhorn:Mellies2005Axiomatic,
    author = {Mellies, Paul-Andre},
    booktitle = {Processes, Terms and Cycles: Steps on the Road to Infinity: Essays Dedicated to Jan Willem Klop on the Occasion of his 60th Birthday},
    citeulike-article-id = {7333181},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.2331},
    date-added = {2010-06-17 03:06:11},
    priority = {2},
    title = {Axiomatic Rewriting Theory I - A Diagrammatic Standardization Theorem},
    x-abstract = {Machine  translation  \#\# -calculus  interpretation  \#\# -calculus  Formally, the -calculus contains two classes of objects: terms and substitutions. Terms are written in the de Bruijn notation.},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.2331},
    xpages = {554--638},
    year = {2005}
}

@inproceedings{dvanhorn:Gonthier1992Abstract,
    author = {Gonthier, Georges and L\'{e}vy, Jean-Jacques and Melli\`{e}s, Paul-Andr\'{e}},
    booktitle = {Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science},
    citeulike-article-id = {7332923},
    date-added = {2010-06-16 21:59:09},
    priority = {0},
    title = {An Abstract Standardisation Theorem},
    x-month = jun,
    xpages = {72--81},
    year = {1992}
}

@article{dvanhorn:Takahashi1995Parallel,
    author = {Takahashi, M.},
    citeulike-article-id = {7018539},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=207191},
    citeulike-linkout-1 = {http://dx.doi.org/10.1006/inco.1995.1057},
    date-added = {2010-06-16 20:55:21},
    journal = {Information and Computation},
    priority = {0},
    publisher = {Academic Press, Inc.},
    title = {Parallel Reductions in \(\{lambda\)-Calculus}},
    x-abstract = {The notion of parallel reduction is extracted from the simple proof of the {Church-Rosser} theorem by Tait and {Martin-L\"{o}f}. Intuitively, this means to reduce a number of redexes (existing in a λ-term) simultaneously. Thus in the case of β-reduction the effect of a parallel reduction is same as that of a "complete development" which is defined by using "residuals" of β-redexes. A nice feature of parallel reduction, however, is that it can be defined directly by induction on the structure of λ-terms (without referring to residuals or other auxiliary notions), and the inductive definition provides us exactly what we need in proving the theorem inductively. Moreover, the notion can be easily extended to other reduction systems such as Girard′s second-order system F and G\"{o}del′s system T . In this paper, after reevaluating the significance of the notion of parallel reduction in {Tait-and-Martin}-L\"{o}f type proofs of the {Church-Rosser} theorems, we show that the notion of parallel reduction is also useful in giving short and direct proofs of some other fundamental theorems in reduction theory of λ-calculus; among others, we give such simple proofs of the standardization theorem for β-reduction (a special case of which is known as the leftmost reduction theorem for β-reduction), the quasi-leftmost reduction theorem for β-reduction, the postponement theorem of η-reduction (in βη-reduction), and the leftmost reduction theorem for βη-reduction.},
    x-address = {Duluth, MN, USA},
    x-doi = {10.1006/inco.1995.1057},
    x-issn = {08905401},
    x-month = apr,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1006/inco.1995.1057},
    x-volume = {118},
    xpages = {120--127},
    year = {1995}
}

@techreport{dvanhorn:Crary2009Simple,
    author = {Crary, Karl},
    citeulike-article-id = {7332802},
    date-added = {2010-06-16 20:42:43},
    institution = {CMU-CS-09-137},
    priority = {0},
    title = {A Simple Proof of {Call-by-Value} Standardization},
    x-month = jun,
    year = {2009}
}

@article{dvanhorn:Plotkin1975Callbyname,
    author = {Plotkin, Gordon},
    citeulike-article-id = {467090},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0304-3975(75)90017-1},
    citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6V1G-46922HH-3/2/a20b91fda9c99ea8a205f1b1d03237ae},
    date-added = {2010-06-16 20:04:14},
    journal = {Theoretical Computer Science},
    priority = {0},
    title = {Call-by-name, call-by-value and the \(\lambda\)-calculus},
    x-abstract = {This paper examines the old question of the relationship between {ISWIM} and the \^{I}»-calculus, using the distinction between call-by-value and call-by-name. It is held that the relationship should be mediated by a standardisation theorem. Since this leads to difficulties, a new \^{I}»-calculus is introduced whose standardisation theorem gives a good correspondence with {ISWIM} as given by the {SECD} machine, but without the letrec feature. Next a call-by-name variant of {ISWIM} is introduced which is in an analogous correspondence withthe usual \^{I}»-calculus. The relation between call-by-value and call-by-name is then studied by giving simulations of each language by the other and interpretations of each calculus in the other. These are obtained as another application of the continuation technique. Some emphasis is placed throughout on the notion of operational equality (or contextual equality). If terms can be proved equal in a calculus they are operationally equal in the corresponding language. Unfortunately, operational equality is not preserved by either of the simulations.},
    x-doi = {10.1016/0304-3975(75)90017-1},
    x-issn = {03043975},
    x-month = dec,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1016/0304-3975(75)90017-1},
    x-volume = {1},
    xpages = {125--159},
    year = {1975}
}

@book{dvanhorn:Curry1958Combinatory,
    author = {Curry, Haskell B. and Feys, Robert},
    citeulike-article-id = {7332754},
    date-added = {2010-06-16 19:55:38},
    priority = {2},
    publisher = {North-Holland},
    title = {Combinatory Logic},
    x-volume = {1},
    year = {1958}
}

@article{dvanhorn:Mitschke1979Standardization,
    author = {Mitschke, Gerd},
    citeulike-article-id = {7332725},
    date-added = {2010-06-16 19:17:33},
    journal = {Z. Math. Logik Grundlang. Math.},
    priority = {2},
    title = {The standardization theorem for the \(\lambda\)-calculus},
    x-volume = {25},
    xpages = {29--31},
    year = {1979}
}

@incollection{dvanhorn:Xi1997Upper,
    author = {Xi, Hongwei},
    booktitle = {Computational Logic and Proof Theory },
    citeulike-article-id = {7331063},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-63385-5\_54},
    citeulike-linkout-1 = {http://www.springerlink.com/content/83889w8805530176},
    date-added = {2010-06-16 18:07:11},
    priority = {0},
    title = {Upper bounds for standardizations and an application},
    x-abstract = {We first present a new proof for the standardization theorem, a fundamental theorem in -calculus. Since our proof is largely built upon structural induction on lambda terms, we can extract some bounds for the number of -reduction steps in the standard -reduction sequences obtained from transforming a given -reduction sequences. This result sharpens the standardization theorem. As an application, we establish a super-exponential bound for the lengths of -reduction sequences from any given simply typed -terms.},
    x-doi = {10.1007/3-540-63385-5\_54},
    x-url = {http://dx.doi.org/10.1007/3-540-63385-5\_54},
    xpages = {335--348},
    year = {1997}
}

@inproceedings{dvanhorn:Might2010Resolving,
    author = {Might, Matthew and Smaragdakis, Yannis and Van{ }Horn, David},
    booktitle = {PLDI '10: Proceedings of the 2010 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {7329790},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1806596.1806631},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1806596.1806631},
    date-added = {2010-06-16 15:16:45},
    location = {Toronto, Ontario, Canada},
    priority = {0},
    publisher = {ACM},
    title = {Resolving and exploiting the {\(k\)}-CFA paradox: illuminating functional vs. object-oriented program analysis},
    x-abstract = {Low-level program analysis is a fundamental problem, taking the shape of "flow analysis" in functional languages and "points-to" analysis in imperative and object-oriented languages. Despite the similarities, the vocabulary and results in the two communities remain largely distinct, with limited cross-understanding. One of the few links is Shivers's {k-CFA} work, which has advanced the concept of "context-sensitive analysis" and is widely known in both communities. Recent results indicate that the relationship between the functional and object-oriented incarnations of {k-CFA} is not as well understood as thought. Van Horn and Mairson proved {k-CFA} for k ≥ 1 to be {EXPTIME}-complete; hence, no polynomial-time algorithm can exist. Yet, there are several polynomial-time formulations of context-sensitive points-to analyses in object-oriented languages. Thus, it seems that functional {k-CFA} may actually be a profoundly different analysis from object-oriented {k-CFA}. We resolve this paradox by showing that the exact same specification of {k-CFA} is polynomial-time for object-oriented languages yet exponential-time for functional ones: objects and closures are subtly different, in a way that interacts crucially with context-sensitivity and complexity. This illumination leads to an immediate payoff: by projecting the object-oriented treatment of objects onto closures, we derive a polynomial-time hierarchy of context-sensitive {CFAs} for functional programs.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1806596.1806631},
    x-isbn = {978-1-4503-0019-3},
    x-series = {\},
    x-url = {http://dx.doi.org/10.1145/1806596.1806631},
    xpages = {305--315},
    year = {2010}
}

@article{dvanhorn:ariola1997,
    author = {Ariola, Zena M. and Felleisen, Matthias},
    citeulike-article-id = {6905427},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=44089},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796897002724},
    date-added = {2010-06-16 15:12:29},
    journal = {Journal of Functional Programming},
    priority = {0},
    title = {The call-by-need lambda calculus},
    x-abstract = {Plotkin (1975) showed that the lambda calculus is a good model of the evaluation process for call-by-name functional programs. Reducing programs to constants or lambda abstractions according to the leftmost-outermost strategy exactly mirrors execution on an abstract machine like Landin\&apos;s {SECD} machine. The machine-based evaluator returns a constant or the token closure if and only if the standard reduction sequence starting at the same program will end in the same constant or in some lambda abstraction. However, the calculus does not capture the sharing of the evaluation of arguments that lazy implementations use to speed up the execution. More precisely, a lazy implementation evaluates procedure arguments only when needed and then only once. All other references to the formal procedure parameter re-use the value of the first argument evaluation. The mismatch between the operational semantics of the lambda calculus and the actual behavior of the prototypical implementation is a major obstacle for compiler writers. Unlike implementors of the leftmost-outermost strategy or of a call-by-value language, implementors of lazy systems cannot easily explain the behavior of their evaluator in terms of source level syntax. Hence, they often cannot explain why a certain syntactic transformation \&lsquo;works\&rsquo; and why another doesn\&apos;t. In this paper we develop an equational characterization of the most popular lazy implementation technique \&ndash; traditionally called \&lsquo;call-by-need\&rsquo; \&ndash; and prove it correct with respect to the original lambda calculus. The theory is a strictly smaller theory than Plotkin\&apos;s call-by-name lambda calculus. Immediate applications of the theory concern the correctness proofs of a number of implementation strategies, e.g. the call-by-need continuation passing transformation and the realization of sharing via assignments. Some of this material first appeared in a paper presented at the 1995 {ACM} Conference on the Principles of Programming Languages. The paper was a joint effort with Maraist, Odersky and Wadler, who had independently developed a different equational characterization of call-by-need. We contrast our work with that of Maraist et al. in the body of this paper where appropriate.},
    x-doi = {10.1017/s0956796897002724},
    x-number = {03},
    x-url = {http://dx.doi.org/10.1017/s0956796897002724},
    x-volume = {7},
    xpages = {265--301},
    year = {1997}
}

@article{dvanhorn:Alur2005Analysis,
    author = {Alur, Rajeev and Benedikt, Michael and Etessami, Kousha and Godefroid, Patrice and Reps, Thomas and Yannakakis, Mihalis},
    citeulike-article-id = {902085},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1075382.1075387},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1075382.1075387},
    date-added = {2010-06-10 20:43:44},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {0},
    publisher = {ACM},
    title = {Analysis of recursive state machines},
    x-abstract = {Recursive state machines ({RSMs}) enhance the power of ordinary state machines by allowing vertices to correspond either to ordinary states or to potentially recursive invocations of other state machines. {RSMs} can model the control flow in sequential imperative programs containing recursive procedure calls. They can be viewed as a visual notation extending Statecharts-like hierarchical state machines, where concurrency is disallowed but recursion is allowed. They are also related to various models of pushdown systems studied in the verification and program analysis {communities.After} introducing {RSMs} and comparing their expressiveness with other models, we focus on whether verification can be efficiently performed for {RSMs}. Our first goal is to examine the verification of linear time properties of {RSMs}. We begin this study by dealing with two key components for algorithmic analysis and model checking, namely, reachability (Is a target state reachable from initial states?) and cycle detection (Is there a reachable cycle containing an accepting state?). We show that both these problems can be solved in time  O ( n \&theta; 2 ) and space  O ( n \&theta;), where  n  is the size of the recursive machine and \&theta; is the maximum, over all component state machines, of the minimum of the number of entries and the number of exits of each component. From this, we easily derive algorithms for linear time temporal logic model checking with the same complexity in the model. We then turn to properties in the branching time logic {CTL}*, and again demonstrate a bound linear in the size of the state machine, but only for the case of {RSMs} with a single exit node.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1075382.1075387},
    x-issn = {0164-0925},
    x-month = jul,
    x-number = {4},
    x-url = {http://dx.doi.org/10.1145/1075382.1075387},
    x-volume = {27},
    xpages = {786--818},
    year = {2005}
}

@article{dvanhorn:Besson2001Model,
    author = {Besson, Fr\'{e}d\'{e}ric and Jensen, Thomas and Le M\'{e}tayer, Daniel and Thorn, Tommy},
    citeulike-article-id = {801509},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=514705},
    date-added = {2010-04-02 14:45:02},
    journal = {J. Comput. Secur.},
    priority = {2},
    publisher = {IOS Press},
    title = {Model checking security properties of control flow graphs},
    x-abstract = {A fundamental problem in software-based security is whether local
 security checks inserted into the code are sufficient to implement
 a global security property. This article introduces a formalism
 based on a linear-time temporal logic for specifying global
 security properties pertaining to the control flow of the program,
 and illustrates its expressive power with a number of existing
 properties. We define a minimalistic, security-dedicated program
 model that only contains procedure call and run-time security
 checks and propose an automatic method for verifying that an
 implementation using local security checks satisfies a global
 security property. We then show how to instantiate the framework to
 the security architecture of Java 2 based on stack inspection and
 privileged method calls.},
    x-address = {Amsterdam, The Netherlands, The Netherlands},
    x-issn = {0926-227X},
    x-month = jan,
    x-number = {3},
    x-url = {http://portal.acm.org/citation.cfm?id=514705},
    x-volume = {9},
    xpages = {217--250},
    year = {2001}
}

@inproceedings{dvanhorn:Bartoletti2001Static,
    author = {Bartoletti, Massimo and Degano, Pierpaolo and Ferrari, Gianluigi},
    booktitle = {In Proceedings of International Workshop on Concurrency and Coordination, Electronic Notes in Theoretical Computer Science},
    citeulike-article-id = {6938151},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.105.7955},
    date-added = {2010-04-01 04:26:45},
    priority = {2},
    title = {Static analysis for stack inspection},
    x-abstract = {We propose two control flow analyses for the Java bytecode. They safely approximate the set of permissions granted/denied to code at run-time. This static information helps optimizing the implementation of the stack inspection algorithm. 1},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.105.7955},
    x-volume = {54},
    year = {2001}
}

@inproceedings{dvanhorn:Besson2002Secure,
    author = {Besson, Fr\'{e}d\'{e}ric and Thomas de Grenier de Latour and Jensen, Thomas},
    booktitle = {PPDP '02: Proceedings of the 4th ACM SIGPLAN International Conference on Principles and Practice of Declarative Programming},
    citeulike-article-id = {6938126},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=571157.571166},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/571157.571166},
    date-added = {2010-04-01 03:58:03},
    location = {Pittsburgh, PA, USA},
    priority = {2},
    publisher = {ACM},
    title = {Secure calling contexts for stack inspection},
    x-abstract = {Stack inspection is a mechanism for programming secure applications by which a method can obtain information from the call stack about the code that (directly or indirectly) invoked it. This mechanism plays a fundamental role in the security architecture of Java and the .{NET} Common Language Runtime. A central problem with stack inspection is to determine to what extent the <i>local</i> checks inserted into the code are sufficient to guarantee that a <i>global</i> security property is enforced. In this paper, we present a technique for inferring a <i>secure calling context</i> for a method. By a secure calling context we mean a pre-condition on the call stack sufficient for guaranteeing that execution of the method will not violate a given global property. This is particularly useful for annotating library code in order to avoid having to re-analyse libraries for every new application. The technique is a constraint based static program analysis implemented via fixed point iteration over an abstract domain of linear temporal logic properties.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/571157.571166},
    x-isbn = {1-58113-528-9},
    x-url = {http://dx.doi.org/10.1145/571157.571166},
    xpages = {76--87},
    year = {2002}
}

@inproceedings{dvanhorn:Skalka2000Static,
    author = {Skalka, Christian and Smith, Scott},
    booktitle = {ICFP '00: Proceedings of the fifth ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {558733},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=351244},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/351240.351244},
    date-added = {2010-04-01 03:56:28},
    priority = {2},
    publisher = {ACM},
    title = {Static enforcement of security with types},
    x-abstract = {A number of security systems for programming languages have recently appeared, including systems for enforcing some form of  access control . The Java {JDK} 1.2 security architecture is one such system that is widely studied and used. While the architecture has many appealing features, access control checks are all implemented via dynamic method calls. This is a highly non-declarative form of specification which is hard to read, and which leads to additional run-time overhead. In this paper, we present a novel  security type system  that enforces the same security guarantees as Java Stack Inspection, but via a static type system with no additional run-time checks. The system allows security properties of programs to be clearly expressed within the types themselves. We also define and prove correct an inference algorithm for security types, meaning that the system has the potential to be layered on top of the existing Java architecture, without requiring new syntax.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/351240.351244},
    x-isbn = {1-58113-202-6},
    x-issn = {0362-1340},
    x-month = sep,
    x-number = {\},
    x-url = {http://dx.doi.org/10.1145/351240.351244},
    x-volume = {\},
    xpages = {34--45},
    year = {2000}
}

@article{dvanhorn:Fournet2003Stack,
    author = {Fournet, C\'{e}dric and Gordon, Andrew D.},
    citeulike-article-id = {6930267},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=641909.641912},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/641909.641912},
    date-added = {2010-03-30 17:11:43},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {Stack inspection: Theory and variants},
    x-abstract = {Stack inspection is a security mechanism implemented in runtimes such as the {JVM} and the {CLR} to accommodate components with diverse levels of trust. Although stack inspection enables the fine-grained expression of access control policies, it has rather a complex and subtle semantics. We present a formal semantics and an equational theory to explain how stack inspection affects program behavior and code optimisations. We discuss the security properties enforced by stack inspection, and also consider variants with stronger, simpler properties.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/641909.641912},
    x-issn = {0164-0925},
    x-number = {3},
    x-url = {http://dx.doi.org/10.1145/641909.641912},
    x-volume = {25},
    xpages = {360--399},
    year = {2003}
}

@book{dvanhorn:1987Abstract,
    citeulike-article-id = {6900846},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=576316},
    date-added = {2010-03-24 14:50:55},
    priority = {2},
    publisher = {Prentice Hall Professional Technical Reference},
    title = {Abstract Interpretation of Declarative Languages},
    x-editor = {Abramsky, Samson and Hankin, Chris},
    x-isbn = {0470209712},
    x-url = {http://portal.acm.org/citation.cfm?id=576316},
    year = {1987}
}

@article{dvanhorn:Jones2007Flow,
    author = {Jones, N. and Andersen, N.},
    citeulike-article-id = {6900845},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.tcs.2006.12.030},
    date-added = {2010-03-24 14:49:36},
    day = {01},
    journal = {Theoretical Computer Science},
    priority = {2},
    title = {Flow analysis of lazy higher-order functional programs},
    x-abstract = {In recent years much interest has been shown in a class of functional languages including {HASKELL}, lazy {ML}, {SASL}/{KRC}/{MIRANDA}, {ALFL}, {ORWELL}, and {PONDER}. It has been seen that their expressive power is great, programs are compact, and program manipulation and transformation is much easier than with imperative languages or more traditional applicative ones. Common characteristics: they are purely applicative, manipulate trees as data objects, use pattern matching both to determine control flow and to decompose compound data structures, and use a  ” lazy” evaluation strategy. In this paper we describe a technique for data flow analysis of programs in this class by safely approximating the behavior of a certain class of term rewriting systems. In particular we obtain  ” safe” descriptions of program inputs, outputs and intermediate results by regular sets of trees. Potential applications include optimization, strictness analysis and partial evaluation. The technique improves earlier work because of its applicability to programs with higher-order functions, and with either eager or lazy evaluation. The technique addresses the call-by-name aspect of laziness, but not memoization.},
    x-doi = {10.1016/j.tcs.2006.12.030},
    x-issn = {03043975},
    x-month = may,
    x-number = {1-3},
    x-url = {http://dx.doi.org/10.1016/j.tcs.2006.12.030},
    x-volume = {375},
    xpages = {120--136},
    year = {2007}
}

@incollection{dvanhorn:Faxen1995Optimizing,
    author = {Fax\'{e}n, Karl},
    booktitle = {Static Analysis },
    citeulike-article-id = {6900824},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-60360-3\_37},
    citeulike-linkout-1 = {http://www.springerlink.com/content/p041749341578266},
    date-added = {2010-03-24 14:45:10},
    priority = {2},
    title = {Optimizing lazy functional programs using flow inference},
    x-abstract = {Nonstrict higher order functional programming languages are notorious for their low run time efficiency. Optimizations based on flow analysis, which determines for each variable x in a program which expressions could have originated the value of x, can improve the situation by removing redundant eval and thunk operations, avoiding thunk updates, and allowing the use of unboxed representations of some data. We formulate flow analysis as an inference problem in a type system built using type inclusion constraints and an algorithm for solving these constraints is also given.},
    x-doi = {10.1007/3-540-60360-3\_37},
    x-url = {http://dx.doi.org/10.1007/3-540-60360-3\_37},
    xpages = {136--153},
    year = {1995}
}

@inproceedings{dvanhorn:Cardelli1984Compiling,
    author = {Cardelli, Luca},
    booktitle = {LISP and Functional Programming},
    citeulike-article-id = {82599},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.208},
    date-added = {2010-03-22 19:32:22},
    priority = {2},
    title = {Compiling a Functional Language},
    x-abstract = {Machine The Functional Abstract Machine (Fam) is a stack machine designed to support functional languages on large address space computers. It can be considered an {SECD} machine [Landin 64] which has been optimized to allow very fast function application and the use of true stacks (as opposed to linked lists). This section contains a brief overview of the Fam; which is fully described in [Cardelli 83]. The machine supports functional objects (closures, which are dynamically allocated and garbage ...},
    x-url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.208},
    xpages = {208--217},
    year = {1984}
}

@book{dvanhorn:Appel1991Compiling,
    author = {Appel, Andrew W.},
    citeulike-article-id = {2429806},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0521416957},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0521416957},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0521416957},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0521416957},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0521416957/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0521416957},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0521416957},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0521416957},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0521416957\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0521416957},
    date-added = {2010-03-22 15:12:48},
    day = {29},
    howpublished = {Hardcover},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Compiling with Continuations},
    x-abstract = {{This book shows how continuation-passing style is used as an intermediate representation to perform optimizations and program transformations. Continuations can be used to compile most programming languages.  The method is illustrated in a compiler for the programming language Standard ML.  Prior knowledge of ML, however, is not necessary, as the author carefully explains each concept as it arises. This is the first book to show how concepts from the theory of programming languages can be applied to the production of practical optimizing compilers for modern languages like ML. All the details of compiling are covered, including the interface to a runtime system and garbage collector.}},
    x-isbn = {0521416957},
    x-month = nov,
    x-url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0521416957},
    year = {1991}
}

@inproceedings{dvanhorn:Danvy-al:FLOPS10,
    author = {Danvy, Olivier and Millikin, Kevin and Munk, Johan and Zerny, Ian},
    booktitle = {Functional and Logic Programming, 10th International Symposium, FLOPS 2010},
    booktitle = {To appear},
    citeulike-article-id = {6857295},
    date-added = {2010-03-16 15:12:25},
    priority = {2},
    publisher = {Springer},
    title = {Defunctionalized Interpreters for {Call-by-Need} Evaluation},
    x-address = {Sendai, Japan},
    x-editor = {Blume, Matthias and Vidal, German},
    x-month = apr,
    x-series = {Lecture Notes in Computer Science},
    year = {2010}
}

@article{dvanhorn:Krivine2007Callbyname,
    author = {Krivine, Jean-Louis},
    citeulike-article-id = {6400453},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10990-007-9018-9},
    citeulike-linkout-1 = {http://www.springerlink.com/content/1736u87071124110},
    date-added = {2010-03-16 02:29:15},
    day = {1},
    journal = {Higher-Order and Symbolic Computation},
    priority = {2},
    title = {A call-by-name lambda-calculus machine},
    x-abstract = {Abstract\&nbsp;\&nbsp; We present a particularly simple lazy lambda-calculus machine, which was introduced twenty-five years ago. It has been, since, used and implemented by several authors, but remained unpublished. We also build an extension, with a control instruction and continuations. This machine was conceived in order to execute programs obtained from mathematical proofs, by means of the {Curry-Howard} (also known as  ” proof-program”) correspondence. The control instruction corresponds to the axiom of excluded middle.},
    x-doi = {10.1007/s10990-007-9018-9},
    x-issn = {1388-3690},
    x-month = sep,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1007/s10990-007-9018-9},
    x-volume = {20},
    xpages = {199--207},
    year = {2007}
}

@unpublished{dvanhorn:Krivine1985Un,
    author = {Krivine, Jean-Louis},
    citeulike-article-id = {6855687},
    date-added = {2010-03-16 02:27:50},
    priority = {2},
    title = {Un interpr\'{e}teur du lambda-calcul},
    year = {1985}
}

@article{dvanhorn:Ager2004Functional,
    author = {Ager, Mads S. and Danvy, Olivier and Midtgaard, Jan},
    citeulike-article-id = {2917380},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.ipl.2004.02.012},
    citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6V0F-4C47N5K-1/1/fc45ae0b61f9fcd63d1600e9061b28cb},
    date-added = {2010-03-16 02:18:52},
    day = {15},
    journal = {Information Processing Letters},
    priority = {2},
    title = {A functional correspondence between call-by-need evaluators and lazy abstract machines},
    x-abstract = {We bridge the gap between compositional evaluators and abstract machines for the lambda-calculus, using closure conversion, transformation into continuation-passing style, and defunctionalization of continuations. This article is a followup of our article at {PPDP} 2003, where we consider call by name and call by value. Here, however, we consider call by need. We derive a lazy abstract machine from an ordinary call-by-need evaluator that threads a heap of updatable cells. In this resulting abstract machine, the continuation fragment for updating a heap cell naturally appears as an 'update marker', an implementation technique that was invented for the Three Instruction Machine and subsequently used to construct lazy variants of Krivine's abstract machine. Tuning the evaluator leads to other implementation techniques such as unboxed values. The correctness of the resulting abstract machines is a corollary of the correctness of the original evaluators and of the program transformations used in the derivation.},
    x-doi = {10.1016/j.ipl.2004.02.012},
    x-issn = {00200190},
    x-month = jun,
    x-number = {5},
    x-url = {http://dx.doi.org/10.1016/j.ipl.2004.02.012},
    x-volume = {90},
    xpages = {223--232},
    year = {2004}
}

@article{dvanhorn:Pottier2005Systematic,
    author = {Pottier, Fran\c{c}ois and Skalka, Christian and Smith, Scott},
    citeulike-article-id = {190447},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1057392},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1057387.1057392},
    date-added = {2010-03-13 01:04:46},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {A systematic approach to static access control},
    x-abstract = {The Java Security Architecture includes a dynamic mechanism for enforcing access control checks, the so-called  stack inspection  process. While the architecture has several appealing features, access control checks are all implemented via dynamic method calls. This is a highly nondeclarative form of specification that is hard to read, and that leads to additional run-time overhead. This article develops type systems that can statically guarantee the success of these checks. Our systems allow security properties of programs to be clearly expressed within the types themselves, which thus serve as static declarations of the security policy. We develop these systems using a systematic methodology: we show that the security-passing style translation, proposed by Wallach et al. [2000] as a  dynamic  implementation technique, also gives rise to  static  security-aware type systems, by composition with conventional type systems. To define the latter, we use the general {HM}( X ) framework, and easily construct several constraint- and unification-based type systems.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1057387.1057392},
    x-issn = {0164-0925},
    x-month = mar,
    x-number = {2},
    x-url = {http://dx.doi.org/10.1145/1057387.1057392},
    x-volume = {27},
    xpages = {344--382},
    year = {2005}
}

@inproceedings{dvanhorn:Hudak1986Semantic,
    author = {Hudak, Paul},
    booktitle = {LFP '86: Proceedings of the 1986 ACM conference on LISP and functional programming},
    citeulike-article-id = {350023},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=319838.319876},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/319838.319876},
    date-added = {2010-03-12 02:10:48},
    location = {Cambridge, Massachusetts, United States},
    priority = {2},
    publisher = {ACM},
    title = {A semantic model of reference counting and its abstraction (detailed summary)},
    x-abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has opted to expose the complete List rather than only correct and linked references.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/319838.319876},
    x-isbn = {0-89791-200-4},
    x-url = {http://dx.doi.org/10.1145/319838.319876},
    xpages = {351--363},
    year = {1986}
}

@inproceedings{dvanhorn:Goldberg1992Polymorphic,
    author = {Goldberg, Benjamin and Gloger, Michael},
    booktitle = {LFP '92: Proceedings of the 1992 ACM conference on LISP and functional programming},
    citeulike-article-id = {6784415},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=141471.141504},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/141471.141504},
    date-added = {2010-03-09 23:09:58},
    location = {San Francisco, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Polymorphic type reconstruction for garbage collection without tags},
    x-abstract = {Several papers, have recently claimed that garbage collection can be performed on untagged data in the presence of {ML}-style type polymorphism.  They rely on the ability to reconstruct the type of any reachable object during garbage collection.  The bad news is that this is false\&mdash;there can be reachable objects in the program whose type cannot be determined by the garbage collector.  The good news is that tag-free garbage collection can be performed anyway\&mdash;any object whose type cannot be determined by the collector is, in fact, garbage.  Such objects can be discarded by the collector.  This is the key result of this paper.   We present a type reconstruction algorithm that can determine the type of any non-garbage object.  Unfortunately,   the implementation of the tag-free collector for a polymorphically typed language is difficult in ways that were not described in the previous papers, and we address some implementation issues as well.  However, we mainly describe how to perform type reconstruction during garbage collection and do not attempt to address practical issues of the garbage collection process.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/141471.141504},
    x-isbn = {0-89791-481-3},
    x-url = {http://dx.doi.org/10.1145/141471.141504},
    xpages = {53--65},
    year = {1992}
}

@book{dvanhorn:Danvy2006Analytical,
    author = {Danvy, Olivier},
    citeulike-article-id = {6778732},
    date-added = {2010-03-09 00:51:56},
    priority = {2},
    title = {An Analytical Approach to Programs as Data Objects},
    x-month = apr,
    year = {2006}
}

@inproceedings{dvanhorn:Midtgaard2009Controlflow,
    author = {Midtgaard, Jan and Jensen, Thomas P.},
    booktitle = {ICFP '09: Proceedings of the 14th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {5904200},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1596550.1596592},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1596550.1596592},
    date-added = {2010-03-09 00:36:16},
    location = {Edinburgh, Scotland},
    priority = {0},
    publisher = {ACM},
    title = {Control-flow Analysis of Function Calls and Returns by Abstract Interpretation},
    x-abstract = {We derive a control-flow analysis that approximates the interprocedural control-flow of both function calls and returns in the presence of first-class functions and tail-call optimization. In addition to an abstract environment, our analysis computes for each expression an abstract control stack, effectively approximating where function calls return across optimized tail calls. The analysis is systematically calculated by abstract interpretation of the stack-based {CaEK} abstract machine of Flanagan et al. using a series of Galois connections. Abstract interpretation provides a unifying setting in which we 1) prove the analysis equivalent to the composition of a continuation-passing style ({CPS}) transformation followed by an abstract interpretation of a stack-less {CPS} machine, and 2) extract an equivalent constraint-based formulation, thereby providing a rational reconstruction of a constraint-based control-flow analysis from abstract interpretation principles.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1596550.1596592},
    x-isbn = {978-1-60558-332-7},
    x-series = {ICFP '09},
    x-url = {http://dx.doi.org/10.1145/1596550.1596592},
    xpages = {287--298},
    year = {2009}
}

@inproceedings{dvanhorn:esop:kmf07,
    author = {Kuan, George and MacQueen, David and Findler, Robert B.},
    booktitle = {ESOP '07},
    booktitle = {Programming Languages and Systems, 16th European Symposium on Programming, ESOP 2007},
    citeulike-article-id = {6778071},
    citeulike-linkout-0 = {http://www.cs.uchicago.edu/\~{}gkuan/pubs/esop07-kmf.pdf},
    date-added = {2010-03-08 21:28:36},
    priority = {2},
    title = {A Rewriting Semantics for Type Inference},
    x-editor = {Nicola, Rocco D.},
    x-month = mar,
    x-url = {http://www.cs.uchicago.edu/\~{}gkuan/pubs/esop07-kmf.pdf},
    x-volume = {4421},
    year = {2007}
}

@incollection{dvanhorn:sepr09,
    author = {Kuan, George},
    booktitle = {Semantics Engineering with PLT Redex},
    citeulike-article-id = {6778064},
    date-added = {2010-03-08 21:23:40},
    priority = {2},
    publisher = {MIT Press},
    title = {Type Checking and Inference via Reductions},
    x-editor = {Felleisen, Matthias and Findler, Robert B. and Flatt, Matthew},
    year = {2009}
}

@inproceedings{dvanhorn:Flanagan1993Essence,
    author = {Flanagan, Cormac and Sabry, Amr and Duba, Bruce F. and Felleisen, Matthias},
    booktitle = {PLDI '93: Proceedings of the ACM SIGPLAN 1993 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {190446},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=155113},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/155090.155113},
    date-added = {2010-03-05 21:38:47},
    location = {Albuquerque, New Mexico, United States},
    priority = {2},
    publisher = {ACM},
    title = {The essence of compiling with continuations},
    x-abstract = {In order to simplify the compilation process, many compilers for higher-order languages use the continuation-passing style ({CPS}) transformation in a first phase to generate an intermediate representation of the source program. The salient aspect of this intermediate form is that all procedures take an argument that represents the rest of the computation (the  ” continuation”). Since the nai¨ve {CPS} transformation considerably increases the size of programs, {CPS} compilers perform reductions to produce a more compact intermediate representation. Although often implemented as a part of the {CPS} transformation, this step is conceptually a second phase. Finally, code generators for typical {CPS} compilers treat continuations specially in order to optimize the interpretation of continuation parameters.   A thorough analysis of the abstract machine for {CPS} terms show that the actions of the code generator  invert  the nai¨ve {CPS} translation step. Put differently, the combined effect of the three phases is equivalent to a source-to-source transformation that simulates the compaction phase. Thus, fully developed {CPS} compilers do not need to employ the {CPS} transformation but can achieve the same results with a simple source-level transformation.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/155090.155113},
    x-isbn = {0-89791-598-4},
    x-month = jun,
    x-number = {\},
    x-url = {http://dx.doi.org/10.1145/155090.155113},
    x-volume = {\},
    xpages = {237--247},
    year = {1993}
}

@incollection{dvanhorn:Cousot98-5,
    author = {Cousot, Patrick},
    booktitle = {Calculational System Design},
    citeulike-article-id = {6768482},
    date-added = {2010-03-05 21:29:37},
    priority = {2},
    publisher = {NATO ASI Series F. IOS Press, Amsterdam},
    title = {The Calculational Design of a Generic Abstract Interpreter},
    x-editor = {Broy, M. and Steinbr\"{u}ggen, R.},
    year = {1999}
}

@book{dvanhorn:Felleisen2009Semantics,
    author = {Felleisen, Matthias and Findler, Robert B. and Flatt, Matthew},
    citeulike-article-id = {6749381},
    date-added = {2010-03-02 16:18:29},
    priority = {2},
    publisher = {MIT Press},
    title = {Semantics Engineering with {PLT} Redex},
    x-isbn = {0-262-06275-5},
    x-month = aug,
    year = {2009}
}

@article{dvanhorn:Clements2004Tailrecursive,
    author = {Clements, John and Felleisen, Matthias},
    citeulike-article-id = {1394},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1034778},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1034774.1034778},
    date-added = {2010-03-01 20:51:33},
    journal = {ACM Trans. Program. Lang. Syst.},
    priority = {2},
    publisher = {ACM},
    title = {A Tail-recursive Machine with Stack Inspection},
    x-abstract = {Security folklore holds that a security mechanism based on stack inspection is incompatible with a global tail call optimization policy; that an implementation of such a language must allocate memory for a source-code tail call, and a program that uses only tail calls (and no other memory-allocating construct) may nevertheless exhaust the available memory. In this article, we prove this widely held belief wrong. We exhibit an abstract machine for a language with security stack inspection whose space consumption function is equivalent to that of the canonical tail call optimizing abstract machine. Our machine is surprisingly simple and suggests that tail calls are as easy to implement in a security setting as they are in a conventional one.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1034774.1034778},
    x-issn = {0164-0925},
    x-month = nov,
    x-number = {6},
    x-url = {http://dx.doi.org/10.1145/1034774.1034778},
    x-volume = {26},
    xpages = {1029--1052},
    year = {2004}
}

@article{dvanhorn:Ager2005Functional,
    author = {Ager, Mads S. and Danvy, Olivier and Midtgaard, Jan},
    citeulike-article-id = {6745807},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.tcs.2005.06.008},
    date-added = {2010-03-01 18:17:40},
    day = {06},
    journal = {Theoretical Computer Science},
    priority = {0},
    title = {A functional correspondence between monadic evaluators and abstract machines for languages with computational effects},
    x-abstract = {We extend our correspondence between evaluators and abstract machines from the pure setting of the  λ -calculus to the impure setting of the computational  λ -calculus. We show how to derive new abstract machines from monadic evaluators for the computational  λ -calculus. Starting from (1) a generic evaluator parameterized by a monad and (2) a monad specifying a computational effect, we inline the components of the monad in the generic evaluator to obtain an evaluator written in a style that is specific to this computational effect. We then derive the corresponding abstract machine by closure-converting, {CPS}-transforming, and defunctionalizing this specific evaluator. We illustrate the construction with the identity monad, obtaining the {CEK} machine, and with a lifted state monad, obtaining a variant of the {CEK} machine with error and state. In addition, we characterize the tail-recursive stack inspection presented by Clements and Felleisen as a lifted state monad. This enables us to combine this stack-inspection monad with other monads and to construct abstract machines for languages with properly tail-recursive stack inspection and other computational effects. The construction scales to other monads—including one more properly dedicated to stack inspection than the lifted state monad—and other monadic evaluators.},
    x-doi = {10.1016/j.tcs.2005.06.008},
    x-issn = {03043975},
    x-month = sep,
    x-number = {1},
    x-url = {http://dx.doi.org/10.1016/j.tcs.2005.06.008},
    x-volume = {342},
    xpages = {149--172},
    year = {2005}
}

@inproceedings{dvanhorn:Felleisen1987Calculus,
    author = {Felleisen, Matthias and Friedman, D. P.},
    booktitle = {POPL '87: Proceedings of the 14th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    booktitle = {POPL'87},
    citeulike-article-id = {6745776},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=41625.41654},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/41625.41654},
    date-added = {2010-03-01 17:51:15},
    location = {Munich, West Germany},
    priority = {0},
    publisher = {ACM},
    title = {A calculus for assignments in higher-order languages},
    x-abstract = {Imperative assignments are abstractions of recurring programming patterns in purely functional programming languages. When added to higher-order functional languages, they provide a higher-level of modularity and security but invalidate the simple substitution semantics. We show that, given an operational interpretation of a denotational semantics for such a language, it is possible to design a two-level extension of the \&lgr; u -calculus. This calculus provides a location-free rewriting semantics of the language and offers new possibilities for reasoning with assignments. The upper level of the calculus factors out all the steps in a reduction sequence which must be in a linear order; the lower level allows a partial ordering of reduction steps.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/41625.41654},
    x-isbn = {0-89791-215-2},
    x-url = {http://dx.doi.org/10.1145/41625.41654},
    xpages = {314--325},
    year = {1987}
}

@inproceedings{dvanhorn:Might:2006:DeltaCFA,
    author = {Might, Matthew and Shivers, Olin},
    booktitle = {POPL '06: Conference record of the 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {4837404},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1111037.1111049},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1111037.1111049},
    date-added = {2009-11-20 04:00:25},
    location = {Charleston, South Carolina, USA},
    priority = {2},
    publisher = {ACM},
    title = {Environment analysis via \(\{Delta\)-CFA}},
    x-abstract = {We describe a new program-analysis framework, based on {CPS} and procedure-string abstractions, that can handle critical analyses which the  {k-CFA} framework cannot. We present the main theorems concerning correctness, show an application analysis, and describe a running implementation.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1111037.1111049},
    x-isbn = {1-59593-027-2},
    x-series = {POPL '06},
    x-url = {http://dx.doi.org/10.1145/1111037.1111049},
    xpages = {127--140},
    year = {2006}
}

@inproceedings{dvanhorn:Gustavsson:PADO01,
    author = {Gustavsson, J\"{o}rgen and Svenningsson, Josef},
    booktitle = {PADO '01: Proceedings of the Second Symposium on Programs as Data Objects},
    citeulike-article-id = {6171563},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=668111},
    date-added = {2009-11-20 03:15:26},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Constraint Abstractions},
    x-address = {London, UK},
    x-isbn = {3-540-42068-1},
    x-url = {http://portal.acm.org/citation.cfm?id=668111},
    xpages = {63--83},
    year = {2001}
}

@inproceedings{dvanhorn:Rehof:POPL01,
    author = {Rehof, Jakob and F\"{a}hndrich, Manuel},
    booktitle = {POPL '01: Proceedings of the 28th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5442196},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=360204.360208},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/360204.360208},
    date-added = {2009-11-20 02:56:17},
    location = {London, United Kingdom},
    priority = {2},
    publisher = {ACM},
    title = {Type-base flow analysis: from polymorphic subtyping to {CFL}-reachability},
    x-abstract = {We present a novel approach to scalable implementation of type-based flow analysis with polymorphic subtyping. Using a new presentation of polymorphic subytping with instantiation constraints, we are able to apply context-free language ({CFL}) reachability techniques to type-based flow analysis. We develop a {CFL}-based algorithm for computing flow-information in time O( n \&sup3;), where  n  is the size of the typed program. The algorithm substantially improves upon the best previously known algorithm for flow analysis based on polymorphic subtyping with complexity O( n 8 ). Our technique also yields the first demand-driven algorithm for polymorphic subtype-based flow-computation. It works directly on higher-order programs with structured data of finite type (unbounded data structures are incorporated via finite approximations), supports context-sensitive, global flow summariztion and includes polymorphic recursion.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/360204.360208},
    x-isbn = {1-58113-336-7},
    x-url = {http://dx.doi.org/10.1145/360204.360208},
    xpages = {54--66},
    year = {2001}
}

@phdthesis{dvanhorn:Lhotak:PhD:2006,
    author = {Lhot\'{a}k, Ond\v{r}ej},
    citeulike-article-id = {6127600},
    date-added = {2009-11-16 20:21:44},
    priority = {2},
    school = {McGill University},
    title = {Program Analysis using Binary Decision Diagrams},
    x-month = jan,
    year = {2006}
}

@inbook{dvanhorn:Sharir:Interprocedural,
    author = {Sharir, Micha and Pnueli, Amir},
    booktitle = {Program Flow Analysis},
    chapter = {7},
    citeulike-article-id = {6057102},
    date-added = {2009-11-02 18:56:32},
    priority = {2},
    publisher = {Prentice-Hall, Inc.},
    title = {Two Approaches to Interprocedural Data Flow Analysis},
    x-address = {Englewood Cliffs, NJ},
    x-editor = {Muchnick, Steven S. and Jones, Neil D.},
    x-isbn = {0137296819},
    xpages = {189--233},
    year = {1981}
}

@article{dvanhorn:Igarashi:TOPLAS:2001,
    author = {Igarashi, Atsushi and Pierce, Benjamin C. and Wadler, Philip},
    citeulike-article-id = {3425305},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=503505},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/503502.503505},
    date-added = {2009-10-26 15:00:29},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {java},
    priority = {2},
    publisher = {ACM},
    title = {Featherweight {J}ava: a minimal core calculus for {J}ava and GJ},
    x-abstract = {Several recent studies have introduced lightweight versions of Java: reduced languages in which complex features like threads and reflection are dropped to enable rigorous arguments about key properties such as type safety. We carry this process a step further, omitting almost all features of the full language (including interfaces and even assignment) to obtain a small calculus, Featherweight Java, for which rigorous proofs are not only possible but easy. Featherweight Java bears a similar relation to Java as the lambda-calculus does to languages such as {ML} and Haskell. It offers a similar computational "feel," providing classes, methods, fields, inheritance, and dynamic typecasts with a semantics closely following Java's. A proof of type safety for Featherweight Java thus illustrates many of the interesting features of a safety proof for the full language, while remaining pleasingly compact. The minimal syntax, typing rules, and operational semantics of Featherweight Java make it a handy tool for studying the consequences of extensions and variations. As an illustration of its utility in this regard, we extend Featherweight Java with generic classes in the style of {GJ} (Bracha, Odersky, Stoutamire, and Wadler) and give a detailed proof of type safety. The extended system formalizes for the first time some of the key features of {GJ}.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/503502.503505},
    x-issn = {0164-0925},
    x-month = may,
    x-number = {3},
    x-url = {http://dx.doi.org/10.1145/503502.503505},
    x-volume = {23},
    xpages = {396--450},
    year = {2001}
}

@article{dvanhorn:Skalka-Smith-VanHorn:AIOOL05,
    author = {Skalka, Christian and Smith, Scott and Van Horn, David},
    citeulike-article-id = {5395202},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.entcs.2005.01.027},
    date-added = {2009-08-07 21:51:31},
    day = {24},
    journal = {Electronic Notes in Theoretical Computer Science},
    priority = {0},
    title = {A Type and Effect System for Flexible Abstract Interpretation of {J}ava (Extended Abstract)},
    x-abstract = {This paper describes a flexible type and effect inference system for Featherweight Java ({FJ}). The effect terms generated by static type and effect inference embody the abstract interpretation of pro- gram event sequences. Flexibility in the analysis is obtained by post-processing of inferred effects, allowing a modular adaptation to extensions of the language. Several example transformations are discussed, including how inferred effects can be transformed to reflect the impact of exceptions on {FJ} control flow.},
    x-doi = {10.1016/j.entcs.2005.01.027},
    x-issn = {15710661},
    x-month = may,
    x-url = {http://dx.doi.org/10.1016/j.entcs.2005.01.027},
    x-volume = {131},
    xpages = {111--124},
    year = {2005}
}

@article{dvanhorn:Skalka-Smith-VanHorn:JFP08,
    author = {Skalka, Christian and Smith, Scott and Van{ }Horn, David},
    citeulike-article-id = {5395173},
    citeulike-linkout-0 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online\&aid=1695700},
    citeulike-linkout-1 = {http://dx.doi.org/10.1017/s0956796807006466},
    date-added = {2009-08-07 21:46:03},
    journal = {Journal of Functional Programming},
    priority = {0},
    title = {Types and trace effects of higher order programs},
    x-abstract = {This paper shows how type effect systems can be combined with model-checking techniques to produce powerful, automatically verifiable program logics for higher order programs. The properties verified are based on the ordered sequence of events that occur during program execution, so-called event traces. Our type and effect systems infer conservative approximations of the event traces arising at run-time, and model-checking techniques are used to verify logical properties of these histories. Our language model is based on the λ-calculus. Technical results include a type inference algorithm for a polymorphic type effect system, and a method for applying known model-checking techniques to the trace effects inferred by the type inference algorithm, allowing static enforcement of history- and stack-based security mechanisms. A type safety result is proven for both unification and subtyping constraint versions of the type system, ensuring that statically well-typed programs do not contain trace event checks that can fail at run-time.},
    x-doi = {10.1017/s0956796807006466},
    x-number = {02},
    x-url = {http://dx.doi.org/10.1017/s0956796807006466},
    x-volume = {18},
    xpages = {179--249},
    year = {2008}
}

@inproceedings{dvanhorn:VanHorn-Mairson:ICFP07,
    author = {Van{ }Horn, David and Mairson, Harry G.},
    booktitle = {ICFP '07: Proceedings of the 12th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {2784124},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1291151.1291166},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1291151.1291166},
    date-added = {2009-08-07 21:42:15},
    priority = {0},
    publisher = {ACM},
    title = {Relating complexity and precision in control flow analysis},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1291151.1291166},
    x-isbn = {9781595938152},
    x-url = {http://dx.doi.org/10.1145/1291151.1291166},
    xpages = {85--96},
    year = {2007}
}

@proceedings{dvanhorn:DBLP:conf/rta/2006,
    booktitle = {RTA},
    citeulike-article-id = {5395154},
    date-added = {2009-08-07 21:29:29},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {Term Rewriting and Applications, 17th International Conference, {RTA} 2006, Seattle, {WA}, {USA}, August 12-14, 2006, Proceedings},
    x-editor = {Pfenning, Frank},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {4098},
    year = {2006}
}

@inproceedings{dvanhorn:giesl-etal-rta06,
    author = {Giesl, J{\"{u}}rgen and Swiderski, Stephan and Kamp, Peter S. and Thiemann, Ren{\'{e}}},
    booktitle = {RTA},
    citeulike-article-id = {5395153},
    date-added = {2009-08-07 21:29:28},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {Automated Termination Analysis for Haskell: From Term Rewriting to Programming Languages},
    x-editor = {Pfenning, Frank},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {4098},
    xpages = {297--312},
    year = {2006}
}

@inproceedings{dvanhorn:biswas-popl97,
    author = {Biswas, Sandip K.},
    booktitle = {POPL '97: Proceedings of the 24th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395152},
    date-added = {2009-08-07 21:29:28},
    key = {POPL 1997},
    keywords = {file-import-09-08-07},
    location = {Paris, France},
    priority = {2},
    publisher = {ACM},
    title = {A demand-driven set-based analysis},
    x-address = {New York, NY, USA},
    xpages = {372--385},
    year = {1997}
}

@article{dvanhorn:palsberg-schwarzbach-ic95,
    author = {Palsberg, Jens and Schwartzbach, Michael I.},
    citeulike-article-id = {5395151},
    date-added = {2009-08-07 21:29:28},
    journal = {Inf. Comput.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Academic Press, Inc.},
    title = {Safety analysis versus type inference},
    x-address = {Duluth, MN, USA},
    x-number = {1},
    x-volume = {118},
    xpages = {128--141},
    year = {1995}
}

@phdthesis{dvanhorn:ayers-phd93,
    author = {Ayers, Andrew E.},
    citeulike-article-id = {5395150},
    date-added = {2009-08-07 21:29:28},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {Massachusetts Institute of Technology},
    title = {Abstract analysis and optimization of Scheme},
    x-address = {Cambridge, MA, USA},
    year = {1993}
}

@inproceedings{dvanhorn:diwan-etal-oopsla96,
    author = {Diwan, Amer and Eliot and Mckinley, Kathryn S.},
    booktitle = {OOPSLA '96: Proceedings of the 11th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
    citeulike-article-id = {5395149},
    date-added = {2009-08-07 21:29:28},
    keywords = {file-import-09-08-07},
    location = {San Jose, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Simple and effective analysis of statically-typed object-oriented programs},
    x-address = {New York, NY, USA},
    xpages = {292--305},
    year = {1996}
}

@inproceedings{dvanhorn:graver-johnson-popl90,
    author = {Graver, Justin O. and Johnson, Ralph E.},
    booktitle = {POPL '90: Proceedings of the 17th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395148},
    date-added = {2009-08-07 21:29:28},
    key = {POPL 1990},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {A type system for Smalltalk},
    x-address = {New York, NY, USA},
    xpages = {136--150},
    year = {1990}
}

@inproceedings{dvanhorn:johnson-etal-oopsla88,
    author = {Johnson, Ralph E. and Graver, Justin O. and Zurawski, Laurance W.},
    booktitle = {OOPSLA '88: Conference proceedings on Object-oriented programming systems, languages and applications},
    citeulike-article-id = {5395147},
    date-added = {2009-08-07 21:29:28},
    keywords = {file-import-09-08-07},
    location = {San Diego, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {{TS}: An optimizing compiler for {S}malltalk},
    x-address = {New York, NY, USA},
    xpages = {18--26},
    year = {1988}
}

@inproceedings{dvanhorn:bacon-sweeney-oopsla96,
    author = {Bacon, David F. and Sweeney, Peter F.},
    booktitle = {OOPSLA '96: Proceedings of the 11th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
    citeulike-article-id = {5395146},
    date-added = {2009-08-07 21:29:28},
    keywords = {file-import-09-08-07},
    location = {San Jose, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Fast static analysis of C++ virtual function calls},
    x-address = {New York, NY, USA},
    xpages = {324--341},
    year = {1996}
}

@inproceedings{dvanhorn:chambers-ungar-pldi90,
    author = {Chambers, Craig and Ungar, David},
    booktitle = {PLDI '90: Proceedings of the ACM SIGPLAN 1990 conference on Programming language design and implementation},
    citeulike-article-id = {5395145},
    date-added = {2009-08-07 21:29:28},
    keywords = {file-import-09-08-07},
    location = {White Plains, New York, United States},
    priority = {2},
    publisher = {ACM},
    title = {Interactive type analysis and extended message splitting; optimizing dynamically-typed object-oriented programs},
    x-address = {New York, NY, USA},
    xpages = {150--164},
    year = {1990}
}

@article{dvanhorn:spoto-jensen-toplas03,
    author = {Spoto, Fausto and Jensen, Thomas},
    citeulike-article-id = {5395144},
    date-added = {2009-08-07 21:29:27},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Class analyses as abstract interpretations of trace semantics},
    x-address = {New York, NY, USA},
    x-number = {5},
    x-volume = {25},
    xpages = {578--630},
    year = {2003}
}

@inproceedings{dvanhorn:jagannathan-wright-pldi96,
    author = {Jagannathan, Suresh and Wright, Andrew},
    booktitle = {PLDI '96: Proceedings of the ACM SIGPLAN 1996 conference on Programming language design and implementation},
    citeulike-article-id = {5395143},
    date-added = {2009-08-07 21:29:27},
    keywords = {file-import-09-08-07},
    location = {Philadelphia, Pennsylvania, United States},
    priority = {2},
    publisher = {ACM},
    title = {Flow-directed inlining},
    x-address = {New York, NY, USA},
    xpages = {193--205},
    year = {1996}
}

@inproceedings{dvanhorn:palsberg-schwartzbach-oopsla91,
    author = {Palsberg, Jens and Schwartzbach, Michael I.},
    booktitle = {OOPSLA '91: Conference proceedings on Object-oriented programming systems, languages, and applications},
    citeulike-article-id = {5395142},
    date-added = {2009-08-07 21:29:27},
    keywords = {file-import-09-08-07},
    location = {Phoenix, Arizona, United States},
    priority = {2},
    publisher = {ACM},
    title = {Object-oriented type inference},
    x-address = {New York, NY, USA},
    xpages = {146--161},
    year = {1991}
}

@article{dvanhorn:chakaravarthy-horwitz-ai02,
    author = {Chakaravarthy, Venkatesan T. and Horwitz, Susan},
    citeulike-article-id = {5395141},
    date-added = {2009-08-07 21:29:27},
    journal = {Acta Informatica},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {On the {Non-Approximability} of Points-to Analysis},
    x-month = jul,
    x-number = {8},
    x-volume = {38},
    xpages = {587--598},
    year = {2002}
}

@inproceedings{dvanhorn:vitek-etal-cc92,
    author = {Vitek, Jan and Horspool, R. Nigel and Uhl, James S.},
    booktitle = {CC '92: Proceedings of the 4th International Conference on Compiler Construction},
    citeulike-article-id = {5395140},
    date-added = {2009-08-07 21:29:27},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {{Compile-Time} Analysis of {Object-Oriented} Programs},
    x-address = {London, UK},
    xpages = {236--250},
    year = {1992}
}

@inproceedings{dvanhorn:oxhoj-etal-ecoop92,
    author = {{J}, Nicholas {.} and Palsberg, Jens and Schwartzbach, Michael I.},
    booktitle = {ECOOP '92: Proceedings of the European Conference on Object-Oriented Programming},
    citeulike-article-id = {5395139},
    date-added = {2009-08-07 21:29:27},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Making Type Inference Practical},
    x-address = {London, UK},
    xpages = {329--349},
    year = {1992}
}

@phdthesis{dvanhorn:hofmann-hab98,
    author = {Hofmann, Martin},
    booktitle = {Habilitation Thesis},
    citeulike-article-id = {5395138},
    date-added = {2009-08-07 21:29:27},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {TU Darmstadt},
    title = {Type Systems for {Polynomial-Time} Computation},
    year = {1998}
}

@article{dvanhorn:kristiansen-tcs04,
    author = {Kristiansen, L. and Niggl, K. H.},
    citeulike-article-id = {5395137},
    date-added = {2009-08-07 21:29:27},
    journal = {Theor. Comput. Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {On the computational complexity of imperative programming languages},
    x-address = {Essex, UK},
    x-number = {1-2},
    x-volume = {318},
    xpages = {139--161},
    year = {2004}
}

@inproceedings{dvanhorn:leivant-popl93,
    author = {Leivant, Daniel},
    booktitle = {POPL '93: Proceedings of the 20th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395136},
    date-added = {2009-08-07 21:29:27},
    key = {POPL 1993},
    keywords = {file-import-09-08-07},
    location = {Charleston, South Carolina, United States},
    priority = {2},
    publisher = {ACM},
    title = {Stratified functional programs and computational complexity},
    x-address = {New York, NY, USA},
    xpages = {325--333},
    year = {1993}
}

@article{dvanhorn:hofmann-ic03,
    author = {Hofmann, Martin},
    citeulike-article-id = {5395135},
    date-added = {2009-08-07 21:29:27},
    journal = {Inf. Comput.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Academic Press, Inc.},
    title = {Linear types and non-size-increasing polynomial time computation},
    x-address = {Duluth, MN, USA},
    x-number = {1},
    x-volume = {183},
    xpages = {57--85},
    year = {2003}
}

@article{dvanhorn:wells-etal-jfp02,
    author = {Wells, J. B. and Dimock, Allyn and Muller, Robert and Turbak, Franklyn},
    citeulike-article-id = {5395134},
    date-added = {2009-08-07 21:29:26},
    journal = {J. Funct. Program.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {A calculus with polymorphic and polyvariant flow types},
    x-address = {New York, NY, USA},
    x-number = {3},
    x-volume = {12},
    xpages = {183--227},
    year = {2002}
}

@inproceedings{dvanhorn:amtoft-turbak-esop00,
    author = {Amtoft, Torben and Turbak, Franklyn A.},
    booktitle = {ESOP '00: Proceedings of the 9th European Symposium on Programming Languages and Systems},
    citeulike-article-id = {5395133},
    date-added = {2009-08-07 21:29:26},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Faithful Translations between Polyvariant Flows and Polymorphic Types},
    x-address = {London, UK},
    xpages = {26--40},
    year = {2000}
}

@inproceedings{dvanhorn:bravenboer-smaragdakis-oopsla09,
    author = {Bravenboer, Martin and Smaragdakis, Yannis},
    booktitle = {OOPSLA '09: Proceedings of the 24th annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
    booktitle = {To appear.},
    citeulike-article-id = {5395132},
    date-added = {2009-08-07 21:29:26},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Strictly Declarative Specification of Sophisticated Points-to Analyses},
    x-month = oct,
    year = {2009}
}

@article{dvanhorn:damiani-toplas03,
    author = {Damiani, Ferruccio},
    citeulike-article-id = {5395131},
    date-added = {2009-08-07 21:29:26},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Rank 2 intersection types for local definitions and conditional expressions},
    x-address = {New York, NY, USA},
    x-number = {4},
    x-volume = {25},
    xpages = {401--451},
    year = {2003}
}

@article{dvanhorn:damiani-fi07,
    author = {Damiani, Ferruccio},
    citeulike-article-id = {5395130},
    date-added = {2009-08-07 21:29:26},
    journal = {Fundam. Inf.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {IOS Press},
    title = {Rank 2 Intersection for Recursive Definitions},
    x-address = {Amsterdam, The Netherlands, The Netherlands},
    x-number = {4},
    x-volume = {77},
    xpages = {451--488},
    year = {2007}
}

@inproceedings{dvanhorn:damiani-prost-types96,
    author = {Damiani, Ferruccio and Prost, Fr\'{e}d\'{e}ric},
    booktitle = {TYPES '96: Selected papers from the International Workshop on Types for Proofs and Programs},
    citeulike-article-id = {5395129},
    date-added = {2009-08-07 21:29:26},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Detecting and Removing {Dead-Code} using Rank 2 Intersection},
    x-address = {London, UK},
    xpages = {66--87},
    year = {1998}
}

@article{dvanhorn:vanbakel-tcs92,
    author = {van Bakel, Steffen},
    citeulike-article-id = {5395128},
    date-added = {2009-08-07 21:29:26},
    journal = {Theor. Comput. Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {Complete restrictions of the intersection type discipline},
    x-address = {Essex, UK},
    x-number = {1},
    x-volume = {102},
    xpages = {135--163},
    year = {1992}
}

@article{dvanhorn:zwick-alg06,
    author = {Zwick, Uri},
    citeulike-article-id = {5395127},
    date-added = {2009-08-07 21:29:26},
    journal = {Algorithmica},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag New York, Inc.},
    title = {A Slightly Improved {Sub-Cubic} Algorithm for the All Pairs Shortest Paths Problem with Real Edge Lengths},
    x-address = {Secaucus, NJ, USA},
    x-number = {2},
    x-volume = {46},
    xpages = {181--192},
    year = {2006}
}

@inproceedings{dvanhorn:chan-stoc07,
    author = {Chan, Timothy M.},
    booktitle = {STOC '07: Proceedings of the thirty-ninth annual ACM symposium on Theory of computing},
    citeulike-article-id = {5395126},
    date-added = {2009-08-07 21:29:26},
    keywords = {file-import-09-08-07},
    location = {San Diego, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {More algorithms for all-pairs shortest paths in weighted graphs},
    x-address = {New York, NY, USA},
    xpages = {590--598},
    year = {2007}
}

@article{dvanhorn:vassilevska-ipl09,
    author = {Vassilevska, Virginia},
    citeulike-article-id = {5395125},
    date-added = {2009-08-07 21:29:26},
    journal = {Inf. Process. Lett.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier North-Holland, Inc.},
    title = {Efficient algorithms for clique problems},
    x-address = {Amsterdam, The Netherlands, The Netherlands},
    x-number = {4},
    x-volume = {109},
    xpages = {254--257},
    year = {2009}
}

@techreport{dvanhorn:basch-etal-95,
    author = {Basch, Julien and Khanna, Sanjeev and Motwani, Rajeev},
    citeulike-article-id = {5395124},
    date-added = {2009-08-07 21:29:25},
    institution = {Stanford University},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {On diameter verification and boolean matrix multiplication},
    x-address = {Stanford, CA, USA},
    year = {1995}
}

@article{dvanhorn:rytter-ic85,
    author = {Rytter, Wojciech},
    citeulike-article-id = {5395123},
    date-added = {2009-08-07 21:29:25},
    journal = {Inf. Control},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Academic Press Professional, Inc.},
    title = {Fast recognition of pushdown automaton and context-free languages},
    x-address = {San Diego, CA, USA},
    x-number = {1-3},
    x-volume = {67},
    xpages = {12--22},
    year = {1985}
}

@article{dvanhorn:aho-hopcroft-ullman-ic68,
    author = {Aho, Alfred V. and Hopcroft, John E. and Ullmana, Jeffrey D.},
    citeulike-article-id = {5395122},
    date-added = {2009-08-07 21:29:25},
    journal = {Information and Control},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Time and Tape Complexity of Pushdown Automaton Languages},
    x-number = {3},
    x-volume = {13},
    xpages = {186--206},
    year = {1968}
}

@misc{dvanhorn:neal-89,
    author = {Neal, Radford},
    booktitle = {Unpublished manuscript. \url{ftp://ftp.cs.utoronto.ca/pub/radford/taxc.ps}},
    citeulike-article-id = {5395121},
    date-added = {2009-08-07 21:29:25},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {The computational complexity of taxonomic inference},
    x-month = dec,
    year = {1989}
}

@book{dvanhorn:martin-97,
    author = {Martin, John C.},
    citeulike-article-id = {5395120},
    date-added = {2009-08-07 21:29:25},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {McGraw-Hill Higher Education},
    title = {Introduction to Languages and the Theory of Computation},
    year = {1997}
}

@inproceedings{dvanhorn:lee-etal-popl01,
    author = {Lee, Chin S. and Jones, Neil D. and Ben Amram, Amir M.},
    booktitle = {POPL '01: Proceedings of the 28th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395119},
    date-added = {2009-08-07 21:29:25},
    keywords = {file-import-09-08-07},
    location = {London, United Kingdom},
    priority = {2},
    publisher = {ACM},
    title = {The size-change principle for program termination},
    x-address = {New York, NY, USA},
    xpages = {81--92},
    year = {2001}
}

@article{dvanhorn:palsberg-wand-jfp03,
    author = {Palsberg, Jens and Wand, Mitchell},
    citeulike-article-id = {5395118},
    date-added = {2009-08-07 21:29:25},
    journal = {J. Funct. Program.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {{CPS} transformation of flow information},
    x-address = {New York, NY, USA},
    x-number = {5},
    x-volume = {13},
    xpages = {905--923},
    year = {2003}
}

@inproceedings{dvanhorn:wand-williamson-esop02,
    author = {Wand, Mitchell and Williamson, Galen B.},
    booktitle = {ESOP '02: Proceedings of the 11th European Symposium on Programming Languages and Systems},
    citeulike-article-id = {5395117},
    date-added = {2009-08-07 21:29:25},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {A Modular, Extensible Proof Method for {Small-Step} Flow Analyses},
    x-address = {London, UK},
    xpages = {213--227},
    year = {2002}
}

@article{dvanhorn:meunier-etal-hosc05,
    author = {Meunier, Philippe and Findler, Robert B. and Steckler, Paul and Wand, Mitchell},
    citeulike-article-id = {5395116},
    date-added = {2009-08-07 21:29:25},
    journal = {Higher Order Symbol. Comput.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Selectors Make {Set-Based} Analysis Too Hard},
    x-address = {Hingham, MA, USA},
    x-number = {3-4},
    x-volume = {18},
    xpages = {245--269},
    year = {2005}
}

@article{dvanhorn:montenyohl-wand-scp91,
    author = {Montenyohl, Margaret and Wand, Mitchell},
    citeulike-article-id = {5395115},
    date-added = {2009-08-07 21:29:25},
    journal = {Sci. Comput. Program.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier North-Holland, Inc.},
    title = {Correctness of static flow analysis in continuation semantics},
    x-address = {Amsterdam, The Netherlands, The Netherlands},
    x-number = {1},
    x-volume = {16},
    xpages = {1--18},
    year = {1991}
}

@article{dvanhorn:steckler-wand-toplas97,
    author = {Steckler, Paul A. and Wand, Mitchell},
    citeulike-article-id = {5395114},
    date-added = {2009-08-07 21:29:25},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Lightweight closure conversion},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {19},
    xpages = {48--86},
    year = {1997}
}

@misc{dvanhorn:wand-02,
    author = {Wand, Mitchell},
    booktitle = {Unpublished manuscript. \url{ftp://ftp.ccs.neu.edu/pub/people/wand/papers/order-sensitive-cfa.ps}},
    citeulike-article-id = {5395113},
    date-added = {2009-08-07 21:29:25},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Analyses that distinguish different evaluation orders, or, unsoundness results in control-flow analysis},
    x-month = jul,
    year = {2002}
}

@proceedings{dvanhorn:popl08,
    citeulike-article-id = {5395112},
    date-added = {2009-08-07 21:29:25},
    key = {POPL 2008},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {Proceedings of the 35th annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
    x-address = {New York, NY, USA},
    year = {2008}
}

@proceedings{dvanhorn:popl98,
    citeulike-article-id = {5395111},
    date-added = {2009-08-07 21:29:25},
    key = {POPL 1998},
    keywords = {file-import-09-08-07},
    location = {San Diego, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Proceedings of the 25th {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
    x-address = {New York, NY, USA},
    year = {1998}
}

@proceedings{dvanhorn:popl97,
    citeulike-article-id = {5395110},
    date-added = {2009-08-07 21:29:25},
    key = {POPL 1997},
    keywords = {file-import-09-08-07},
    location = {Paris, France},
    priority = {2},
    publisher = {ACM},
    title = {Proceedings of the 24th {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
    x-address = {New York, NY, USA},
    year = {1997}
}

@proceedings{dvanhorn:popl95,
    citeulike-article-id = {5395109},
    date-added = {2009-08-07 21:29:25},
    key = {POPL 1995},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Proceedings of the 22nd {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
    x-address = {New York, NY, USA},
    year = {1995}
}

@proceedings{dvanhorn:popl93,
    citeulike-article-id = {5395108},
    date-added = {2009-08-07 21:29:25},
    key = {POPL 1993},
    keywords = {file-import-09-08-07},
    location = {Charleston, South Carolina, United States},
    priority = {2},
    publisher = {ACM},
    title = {Proceedings of the 20th {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
    x-address = {New York, NY, USA},
    year = {1993}
}

@proceedings{dvanhorn:popl91,
    citeulike-article-id = {5395107},
    date-added = {2009-08-07 21:29:25},
    key = {POPL 1991},
    keywords = {file-import-09-08-07},
    location = {Orlando, Florida, United States},
    priority = {2},
    publisher = {ACM},
    title = {Proceedings of the 18th {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
    x-address = {New York, NY, USA},
    year = {1991}
}

@proceedings{dvanhorn:popl90,
    citeulike-article-id = {5395106},
    date-added = {2009-08-07 21:29:25},
    key = {POPL 1990},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Proceedings of the 17th {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
    x-address = {New York, NY, USA},
    year = {1990}
}

@inproceedings{dvanhorn:hoang-mitchell-popl95,
    author = {Hoang, My and Mitchell, John C.},
    booktitle = {POPL '95: Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395105},
    date-added = {2009-08-07 21:29:25},
    key = {POPL 1995},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Lower bounds on type inference with subtypes},
    x-address = {New York, NY, USA},
    xpages = {176--185},
    year = {1995}
}

@article{dvanhorn:ben-amram-etal-toplas07,
    author = {Ben Amram, Amir M. and Lee, Chin S.},
    citeulike-article-id = {5395104},
    date-added = {2009-08-07 21:29:24},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Program termination analysis in polynomial time},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {29},
    xpages = {5},
    year = {2007}
}

@proceedings{dvanhorn:icfp97,
    citeulike-article-id = {5395103},
    date-added = {2009-08-07 21:29:24},
    keywords = {file-import-09-08-07},
    location = {Amsterdam, The Netherlands},
    priority = {2},
    publisher = {ACM},
    title = {{ICFP} '97: Proceedings of the second {ACM} {SIGPLAN} international conference on Functional programming},
    x-address = {New York, NY, USA},
    x-editor = {Berman, A. Michael},
    year = {1997}
}

@inproceedings{dvanhorn:tobin-hochstadt-felleisen-popl08,
    author = {Tobin-Hochstadt, Sam and Felleisen, Matthias},
    booktitle = {POPL '08: Proceedings of the 35th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    booktitle = {POPL '08},
    citeulike-article-id = {5395102},
    date-added = {2009-08-07 21:29:24},
    key = {POPL 2008},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {The design and implementation of {T}yped {S}cheme},
    x-address = {New York, NY, USA},
    xpages = {395--406},
    year = {2008}
}

@article{dvanhorn:damian-danvy-jfp03,
    author = {Damian, Daniel and Danvy, Olivier},
    citeulike-article-id = {5395101},
    date-added = {2009-08-07 21:29:24},
    journal = {J. Funct. Program.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {{CPS} transformation of flow information, {P}art {II}: administrative reductions},
    x-address = {New York, NY, USA},
    x-number = {5},
    x-volume = {13},
    xpages = {925--933},
    year = {2003}
}

@inproceedings{dvanhorn:tip-palsberg-oopsla00,
    author = {Tip, Frank and Palsberg, Jens},
    booktitle = {OOPSLA '00: Proceedings of the 15th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
    citeulike-article-id = {5395100},
    date-added = {2009-08-07 21:29:24},
    keywords = {file-import-09-08-07},
    location = {Minneapolis, Minnesota, United States},
    priority = {2},
    publisher = {ACM},
    title = {Scalable propagation-based call graph construction algorithms},
    x-address = {New York, NY, USA},
    xpages = {281--293},
    year = {2000}
}

@article{dvanhorn:grove-chambers-toplas01,
    author = {Grove, David and Chambers, Craig},
    citeulike-article-id = {5395099},
    date-added = {2009-08-07 21:29:24},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {A framework for call graph construction algorithms},
    x-address = {New York, NY, USA},
    x-number = {6},
    x-volume = {23},
    xpages = {685--746},
    year = {2001}
}

@article{dvanhorn:milanova-etal-tosem05,
    author = {Milanova, Ana and Rountev, Atanas and Ryder, Barbara G.},
    citeulike-article-id = {5395098},
    date-added = {2009-08-07 21:29:24},
    journal = {ACM Trans. Softw. Eng. Methodol.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Parameterized object sensitivity for points-to analysis for {J}ava},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {14},
    xpages = {1--41},
    year = {2005}
}

@article{dvanhorn:rinetzky-etal-toplas08,
    author = {Rinetzky, N. and Ramalingam, G. and Sagiv, M. and Yahav, E.},
    citeulike-article-id = {5395097},
    date-added = {2009-08-07 21:29:24},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {On the complexity of partially-flow-sensitive alias analysis},
    x-address = {New York, NY, USA},
    x-number = {3},
    x-volume = {30},
    xpages = {1--28},
    year = {2008}
}

@inproceedings{dvanhorn:emami-etal-pldi94,
    author = {Emami, Maryam and Ghiya, Rakesh and Hendren, Laurie J.},
    booktitle = {PLDI '94: Proceedings of the ACM SIGPLAN 1994 conference on Programming language design and implementation},
    citeulike-article-id = {5395096},
    date-added = {2009-08-07 21:29:24},
    keywords = {file-import-09-08-07},
    location = {Orlando, Florida, United States},
    priority = {2},
    publisher = {ACM},
    title = {Context-sensitive interprocedural points-to analysis in the presence of function pointers},
    x-address = {New York, NY, USA},
    xpages = {242--256},
    year = {1994}
}

@inproceedings{dvanhorn:wilson-lam-pldi95,
    author = {Wilson, Robert P. and Lam, Monica S.},
    booktitle = {PLDI '95: Proceedings of the ACM SIGPLAN 1995 conference on Programming language design and implementation},
    citeulike-article-id = {5395095},
    date-added = {2009-08-07 21:29:24},
    keywords = {file-import-09-08-07},
    location = {La Jolla, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Efficient context-sensitive pointer analysis for {C} programs},
    x-address = {New York, NY, USA},
    xpages = {1--12},
    year = {1995}
}

@phdthesis{dvanhorn:landi-phd92,
    author = {Landi, William},
    citeulike-article-id = {5395094},
    date-added = {2009-08-07 21:29:24},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {Rutgers University},
    title = {Interprocedural Aliasing in the Presence of Pointers},
    year = {1992}
}

@inproceedings{dvanhorn:choi-etal-popl93,
    author = {Choi, Jong D. and Burke, Michael and Carini, Paul},
    booktitle = {POPL '93: Proceedings of the 20th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395093},
    date-added = {2009-08-07 21:29:24},
    key = {POPL 1993},
    keywords = {file-import-09-08-07},
    location = {Charleston, South Carolina, United States},
    priority = {2},
    publisher = {ACM},
    title = {Efficient flow-sensitive interprocedural computation of pointer-induced aliases and side effects},
    x-address = {New York, NY, USA},
    xpages = {232--245},
    year = {1993}
}

@article{dvanhorn:ramalingam-toplas94,
    author = {Ramalingam, G.},
    citeulike-article-id = {5395092},
    date-added = {2009-08-07 21:29:24},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {The undecidability of aliasing},
    x-address = {New York, NY, USA},
    x-number = {5},
    x-volume = {16},
    xpages = {1467--1471},
    year = {1994}
}

@inproceedings{dvanhorn:chakaravarthy-popl03,
    author = {Chakaravarthy, Venkatesan T.},
    booktitle = {POPL '03: Proceedings of the 30th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395091},
    date-added = {2009-08-07 21:29:24},
    keywords = {file-import-09-08-07},
    location = {New Orleans, Louisiana, USA},
    priority = {2},
    publisher = {ACM},
    title = {New results on the computability and complexity of points--to analysis},
    x-address = {New York, NY, USA},
    xpages = {115--125},
    year = {2003}
}

@inproceedings{dvanhorn:meyers-popl81,
    author = {Myers, Eugene M.},
    booktitle = {POPL '81: Proceedings of the 8th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395090},
    date-added = {2009-08-07 21:29:24},
    keywords = {file-import-09-08-07},
    location = {Williamsburg, Virginia},
    priority = {2},
    publisher = {ACM},
    title = {A precise inter-procedural data flow algorithm},
    x-address = {New York, NY, USA},
    xpages = {219--230},
    year = {1981}
}

@article{dvanhorn:landi-loplas92,
    author = {Landi, William},
    citeulike-article-id = {5395089},
    date-added = {2009-08-07 21:29:24},
    journal = {ACM Lett. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Undecidability of static analysis},
    x-address = {New York, NY, USA},
    x-number = {4},
    x-volume = {1},
    xpages = {323--337},
    year = {1992}
}

@inproceedings{dvanhorn:defouw-etal-popl98,
    author = {Defouw, Greg and Grove, David and Chambers, Craig},
    booktitle = {POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395088},
    date-added = {2009-08-07 21:29:23},
    key = {POPL 1998},
    keywords = {file-import-09-08-07},
    location = {San Diego, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Fast interprocedural class analysis},
    x-address = {New York, NY, USA},
    xpages = {222--236},
    year = {1998}
}

@article{dvanhorn:chaterjee-etal-tse01,
    author = {Chatterjee, Ramkrishna and Ryder, Barbara G. and Landi, William A.},
    citeulike-article-id = {5395087},
    date-added = {2009-08-07 21:29:23},
    journal = {IEEE Trans. Softw. Eng.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {IEEE Press},
    title = {Complexity of Points-To Analysis of {J}ava in the Presence of Exceptions},
    x-address = {Piscataway, NJ, USA},
    x-number = {6},
    x-volume = {27},
    xpages = {481--512},
    year = {2001}
}

@article{dvanhorn:jones-bohr-lmcs08,
    author = {Jones, Neil D. and Bohr, Nina},
    citeulike-article-id = {5395086},
    date-added = {2009-08-07 21:29:23},
    journal = {Logical Methods in Computer Science},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Call-by-value Termination in the Untyped \$\\lambda\$-calculus},
    x-number = {1},
    x-volume = {4},
    xpages = {1--39},
    year = {2008}
}

@article{dvanhorn:mcallester-jacm02,
    author = {Mcallester, David},
    citeulike-article-id = {5395085},
    date-added = {2009-08-07 21:29:23},
    journal = {J. ACM},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {On the complexity analysis of static analyses},
    x-address = {New York, NY, USA},
    x-number = {4},
    x-volume = {49},
    xpages = {512--537},
    year = {2002}
}

@techreport{dvanhorn:midtgaard-vanhorn-tr09,
    author = {Midtgaard, Jan and Van{ }Horn, David},
    citeulike-article-id = {5395084},
    date-added = {2009-08-07 21:29:23},
    institution = {Roskilde University, Denmark},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Subcubic Control Flow Analysis Algorithms},
    x-month = may,
    x-number = {125},
    year = {2009}
}

@inproceedings{dvanhorn:landi-ryder-popl91,
    author = {Landi, William and Ryder, Barbara G.},
    booktitle = {POPL '91: Proceedings of the 18th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395083},
    date-added = {2009-08-07 21:29:23},
    key = {POPL 1991},
    keywords = {file-import-09-08-07},
    location = {Orlando, Florida, United States},
    priority = {2},
    publisher = {ACM},
    title = {Pointer-induced aliasing: a problem taxonomy},
    x-address = {New York, NY, USA},
    xpages = {93--103},
    year = {1991}
}

@inproceedings{dvanhorn:landi-ryder-pldi92retro,
    author = {Landi, William and Ryder, Barbara G.},
    citeulike-article-id = {5395082},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {A safe approximate algorithm for interprocedural pointer aliasing},
    x-address = {New York, NY, USA},
    x-editor = {Mckinley, Kathryn S.},
    x-number = {4},
    x-volume = {39},
    xpages = {473--489},
    year = {2004}
}

@book{dvanhorn:pldi-best04,
    citeulike-article-id = {5395081},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {{SIGPLAN} Not., Special Issue: 20 Years of {PLDI} (1979 - 1999): A Selection},
    x-address = {New York, NY, USA},
    x-editor = {Mckinley, Kathryn S.},
    x-number = {4},
    x-volume = {39},
    year = {2004}
}

@phdthesis{dvanhorn:andersen-phd94,
    author = {Andersen, Lars O.},
    citeulike-article-id = {5395080},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {DIKU, University of Copenhagen},
    title = {Program Analysis and Specialization for the {C} Programming Language},
    x-month = may,
    year = {1994}
}

@inproceedings{dvanhorn:henglein-fplca91,
    author = {Henglein, Fritz},
    booktitle = {Proceedings of the 5th ACM Conference on Functional Programming Languages and Computer Architecture},
    citeulike-article-id = {5395079},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Efficient Type Inference for {Higher-Order} {Binding-Time} Analysis},
    x-address = {London, UK},
    xpages = {448--472},
    year = {1991}
}

@inproceedings{dvanhorn:hind-paste01,
    author = {Hind, Michael},
    booktitle = {PASTE '01: Proceedings of the 2001 ACM SIGPLAN-SIGSOFT workshop on Program analysis for software tools and engineering},
    citeulike-article-id = {5395078},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    location = {Snowbird, Utah, United States},
    priority = {2},
    publisher = {ACM},
    title = {Pointer analysis: haven't we solved this problem yet?},
    x-address = {New York, NY, USA},
    xpages = {54--61},
    year = {2001}
}

@inproceedings{dvanhorn:steensgaard-popl96,
    author = {Steensgaard, Bjarne},
    booktitle = {POPL '96: Proceedings of the 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5395077},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    location = {St. Petersburg Beach, Florida, United States},
    priority = {2},
    publisher = {ACM},
    title = {Points-to analysis in almost linear time},
    x-address = {New York, NY, USA},
    xpages = {32--41},
    year = {1996}
}

@article{dvanhorn:horwitz-toplas97,
    author = {Horwitz, Susan},
    citeulike-article-id = {5395076},
    date-added = {2009-08-07 21:29:23},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Precise flow-insensitive may-alias analysis is {NP}-hard},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {19},
    xpages = {1--6},
    year = {1997}
}

@inproceedings{dvanhorn:landi-ryder-pldi92,
    author = {Landi, William and Ryder, Barbara G.},
    booktitle = {PLDI '92: Proceedings of the ACM SIGPLAN 1992 conference on Programming language design and implementation},
    citeulike-article-id = {5395075},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {A safe approximate algorithm for interprocedural aliasing},
    x-address = {New York, NY, USA},
    xpages = {235--248},
    year = {1992}
}

@inproceedings{dvanhorn:muth-debray-popl00,
    author = {Muth, Robert and Debray, Saumya},
    booktitle = {POPL '00: Proceedings of the 27th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395074},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    location = {Boston, MA, USA},
    priority = {2},
    publisher = {ACM},
    title = {On the complexity of flow-sensitive dataflow analyses},
    x-address = {New York, NY, USA},
    xpages = {67--80},
    year = {2000}
}

@inproceedings{dvanhorn:ullman-allen-sfcs86,
    author = {Ullman, Jeffrey D. and {Gelder}, Allen {.}},
    booktitle = {SFCS '86: Proceedings of the 27th Annual Symposium on Foundations of Computer Science (sfcs 1986)},
    citeulike-article-id = {5395073},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Parallel complexity of logical query programs},
    x-address = {Washington, DC, USA},
    xpages = {438--454},
    year = {1986}
}

@inproceedings{dvanhorn:tiuryn-mfcs90,
    author = {Tiuryn, Jerzy},
    booktitle = {MFCS '90: Proceedings on Mathematical foundations of computer science 1990},
    citeulike-article-id = {5395072},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    location = {Banska\\'{} Bystrica, Czechoslovakia},
    priority = {2},
    publisher = {Springer-Verlag New York, Inc.},
    title = {Type inference problems: a survey},
    x-address = {New York, NY, USA},
    xpages = {105--120},
    year = {1990}
}

@article{dvanhorn:curry-dialectica69,
    author = {Curry, Haskell B.},
    citeulike-article-id = {5395071},
    date-added = {2009-08-07 21:29:23},
    journal = {Dialectica},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Modified basic functionality in combinatory logic},
    x-number = {2},
    x-volume = {23},
    xpages = {83--92},
    year = {1969}
}

@inproceedings{dvanhorn:kfoury-etal-icfp99,
    author = {Kfoury, Assaf J. and Mairson, Harry G. and Turbak, Franklyn A. and Wells, J. B.},
    booktitle = {ICFP '99: Proceedings of the fourth ACM SIGPLAN international conference on Functional programming},
    citeulike-article-id = {5395070},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    location = {Paris, France},
    priority = {2},
    publisher = {ACM},
    title = {Relating typability and expressiveness in finite-rank intersection type systems (extended abstract)},
    x-address = {New York, NY, USA},
    xpages = {90--101},
    year = {1999}
}

@article{dvanhorn:hindley-tcs89,
    author = {Hindley, J. Roger},
    citeulike-article-id = {5395069},
    date-added = {2009-08-07 21:29:23},
    journal = {Theor. Comput. Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {{BCK}-combinators and linear \$\\lambda\$-terms have types},
    x-volume = {64},
    xpages = {97--105},
    year = {1989}
}

@inproceedings{dvanhorn:hirokawa-tacs91,
    author = {Hirokawa, Sachio},
    booktitle = {TACS '91: Proceedings of the International Conference on Theoretical Aspects of Computer Software},
    citeulike-article-id = {5395068},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Principal Type-Schemes of {BCI}-Lambda-Terms},
    x-address = {London, UK},
    xpages = {633--650},
    year = {1991}
}

@inproceedings{dvanhorn:kanellakis-etal-robinson,
    author = {Kanellakis, Paris C. and Mairson, Harry G. and Mitchell, John C.},
    booktitle = {Computational Logic: Essays in Honor of Alan Robinson},
    citeulike-article-id = {5395067},
    date-added = {2009-08-07 21:29:23},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {MIT Press},
    title = {Unification and {ML}-Type Reconstruction},
    xpages = {444--478},
    year = {1991}
}

@inproceedings{dvanhorn:barendregt-volb,
    author = {Barendregt, Henk P.},
    citeulike-article-id = {5395066},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {MIT Press},
    title = {Functional programming and lambda calculus},
    x-address = {Cambridge, MA, USA},
    x-editor = {van Leeuwen, J.},
    xpages = {321--363},
    year = {1990}
}

@book{dvanhorn:volb,
    citeulike-article-id = {5395065},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {MIT Press},
    title = {Handbook of Theoretical Computer Science (Vol. B): Formal Models and Semantics},
    x-address = {Cambridge, MA, USA},
    x-editor = {van Leeuwen, J.},
    year = {1990}
}

@inproceedings{dvanhorn:mitchell-volb,
    author = {Mitchell, John C.},
    citeulike-article-id = {5395064},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {MIT Press},
    title = {Type systems for programming languages},
    x-address = {Cambridge, MA, USA},
    x-editor = {van Leeuwen, J.},
    xpages = {365--458},
    year = {1990}
}

@book{dvanhorn:garey-johnson,
    author = {Garey, Michael R. and Johnson, David S.},
    citeulike-article-id = {5395063},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {W. H. Freeman \& Co.},
    title = {Computers and Intractability: A Guide to the Theory of {NP}-Completeness},
    x-address = {New York, NY, USA},
    year = {1979}
}

@book{dvanhorn:paulson,
    author = {Paulson, Lawrence C.},
    citeulike-article-id = {5395062},
    date-added = {2009-08-07 21:29:22},
    edition = {Second},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {{ML} for the Working Programmer},
    year = {1996}
}

@inproceedings{dvanhorn:jagannathan-etal-popl98,
    author = {Jagannathan, Suresh and Thiemann, Peter and Weeks, Stephen and Wright, Andrew},
    booktitle = {POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5395061},
    date-added = {2009-08-07 21:29:22},
    key = {POPL 1998},
    keywords = {file-import-09-08-07},
    location = {San Diego, California, United States},
    priority = {2},
    publisher = {ACM},
    title = {Single and loving it: must-alias analysis for higher-order languages},
    x-address = {New York, NY, USA},
    xpages = {329--341},
    year = {1998}
}

@techreport{dvanhorn:cardone-hindley-06,
    author = {Cardone, Felice and Hindley, J. Roger},
    booktitle = {To appear in {\em Handbook of the History of Logic, Volume 5}, D. M. Gabbay and J. Woods, editors.},
    citeulike-article-id = {5395060},
    date-added = {2009-08-07 21:29:22},
    institution = {Swansea University Mathematics Department Research Report},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {History of Lambda-calculus and Combinatory Logic},
    x-number = {MRRS-05-06},
    year = {2006}
}

@article{dvanhorn:hindley-ams69,
    author = {Hindley, J. Roger},
    citeulike-article-id = {5395059},
    date-added = {2009-08-07 21:29:22},
    journal = {Transactions of the American Mathematical Society},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {The Principal {Type-Scheme} of an Object in Combinatory Logic},
    x-month = dec,
    xpages = {29--60},
    year = {1969}
}

@book{dvanhorn:jones97,
    author = {Jones, Neil D.},
    citeulike-article-id = {5395058},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {MIT Press},
    title = {Computability and Complexity: From a Programming Perspective},
    x-address = {Cambridge, MA, USA},
    year = {1997}
}

@inproceedings{dvanhorn:kanellakis-mitchell-popl89,
    author = {Kanellakis, P. C. and Mitchell, J. C.},
    booktitle = {POPL '89: Proceedings of the 16th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395057},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    location = {Austin, Texas, United States},
    priority = {2},
    publisher = {ACM},
    title = {Polymorphic unification and {ML} typing},
    x-address = {New York, NY, USA},
    xpages = {105--115},
    year = {1989}
}

@article{dvanhorn:melski-reps00,
    author = {Melski, David and Reps, Thomas},
    citeulike-article-id = {5395056},
    date-added = {2009-08-07 21:29:22},
    journal = {Theor. Comput. Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {Interconvertibility of a class of set constraints and context-free-language reachability},
    x-address = {Essex, UK},
    x-number = {1-2},
    x-volume = {248},
    xpages = {29--98},
    year = {2000}
}

@article{dvanhorn:urzyczyn-mscs97,
    author = {Urzyczyn, Pawe{l}},
    citeulike-article-id = {5395055},
    date-added = {2009-08-07 21:29:22},
    journal = {Mathematical. Structures in Comp. Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Type reconstruction in {F\$\_\\omega\$}},
    x-address = {New York, NY, USA},
    x-number = {4},
    x-volume = {7},
    xpages = {329--358},
    year = {1997}
}

@inproceedings{dvanhorn:reynolds-pcp74,
    author = {Reynolds, John C.},
    booktitle = {Programming Symposium, Proceedings Colloque sur la Programmation},
    citeulike-article-id = {5395054},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Towards a theory of type structure},
    x-address = {London, UK},
    xpages = {408--423},
    year = {1974}
}

@inproceedings{dvanhorn:boehm-sfcs85,
    author = {Boehm, Hans J.},
    booktitle = {SFCS '85: Proceedings of the 26th Annual Symposium on Foundations of Computer Science (sfcs 1985)},
    citeulike-article-id = {5395053},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Partial polymorphic type inference is undecidable},
    x-address = {Washington, DC, USA},
    xpages = {339--345},
    year = {1985}
}

@article{dvanhorn:wand-fi87,
    author = {Wand, Mitchell},
    citeulike-article-id = {5395052},
    date-added = {2009-08-07 21:29:22},
    journal = {Fundam. Inform.},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {A simple algorithm and proof for type inference.},
    x-volume = {10},
    xpages = {115--122},
    year = {1987}
}

@article{dvanhorn:pfenning-fi93,
    author = {Pfenning, Frank},
    citeulike-article-id = {5395051},
    date-added = {2009-08-07 21:29:22},
    journal = {Fundam. Inf.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {IOS Press},
    title = {On the undecidability of partial polymorphic type reconstruction},
    x-address = {Amsterdam, The Netherlands, The Netherlands},
    x-number = {1-2},
    x-volume = {19},
    xpages = {185--199},
    year = {1993}
}

@inproceedings{dvanhorn:leivant-popl83,
    author = {Leivant, Daniel},
    booktitle = {POPL '83: Proceedings of the 10th ACM SIGACT-SIGPLAN symposium on Principles of programming languages},
    citeulike-article-id = {5395050},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    location = {Austin, Texas},
    priority = {2},
    publisher = {ACM},
    title = {Polymorphic type inference},
    x-address = {New York, NY, USA},
    xpages = {88--98},
    year = {1983}
}

@inbook{dvanhorn:herbrand,
    author = {Herbrand, Jacques},
    booktitle = {Chapter 5 of Herbrand's PhD, {\it Recherches sur la th\'{e}orie de la de\'{e}monstration}},
    citeulike-article-id = {5395049},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Harvard University Press},
    title = {Investigations in proof theory: The properties of true propositions},
    x-editor = {{Heijenoort}, Jean {.}},
    xpages = {525--581},
    year = {1930}
}

@book{dvanhorn:frege-to-godel,
    citeulike-article-id = {5395048},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Harvard University Press},
    title = {From Frege to G\"{o}del: A Source Book in Mathematical Logic, 1879--1931},
    x-editor = {{Heijenoort}, Jean {.}},
    year = {1967}
}

@article{dvanhorn:robinson-jacm65,
    author = {Robinson, J. Alan},
    citeulike-article-id = {5395047},
    date-added = {2009-08-07 21:29:22},
    journal = {J. ACM},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {A {Machine-Oriented} Logic Based on the Resolution Principle},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {12},
    xpages = {23--41},
    year = {1965}
}

@book{dvanhorn:muchnick-jones-81,
    citeulike-article-id = {5395046},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Prentice Hall},
    title = {Program Flow Analysis: Theory and Applications},
    x-editor = {Muchnick, Steven S. and Jones, Neil D.},
    year = {1981}
}

@inproceedings{dvanhorn:jones-muchnick-pfa81,
    author = {Jones, Neil D. and Muchnick, Steven S.},
    chapter = {12},
    citeulike-article-id = {5395045},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Prentice Hall},
    title = {Complexity of flow analysis, inductive assertion synthesis, and a language due to {Dijkstra}},
    x-editor = {Muchnick, Steven S. and Jones, Neil D.},
    xpages = {380--393},
    year = {1981}
}

@inproceedings{dvanhorn:jones-muchnick-popl79,
    author = {Jones, Neil D. and Muchnick, Steven S.},
    booktitle = {POPL '79: Proceedings of the 6th ACM SIGACT-SIGPLAN symposium on Principles of programming languages},
    citeulike-article-id = {5395044},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    location = {San Antonio, Texas},
    priority = {2},
    publisher = {ACM},
    title = {Flow analysis and optimization of {LISP}-like structures},
    x-address = {New York, NY, USA},
    xpages = {244--256},
    year = {1979}
}

@inproceedings{dvanhorn:heintze-mcallester-icfp97,
    author = {Heintze, Nevin and Mcallester, David},
    booktitle = {ICFP '97: Proceedings of the second ACM SIGPLAN international conference on Functional programming},
    citeulike-article-id = {5395043},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    location = {Amsterdam, The Netherlands},
    priority = {2},
    publisher = {ACM},
    title = {On the complexity of set-based analysis},
    x-address = {New York, NY, USA},
    x-editor = {Berman, A. Michael},
    xpages = {150--163},
    year = {1997}
}

@article{dvanhorn:reps-ai96,
    author = {Reps, Thomas W.},
    citeulike-article-id = {5395042},
    citeulike-linkout-0 = {\#},
    date-added = {2009-08-07 21:29:22},
    journal = {Acta Informatica},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {On the Sequential Nature of Interprocedural {Program-Analysis} Problems},
    x-number = {8},
    x-url = {citeseer.ist.psu.edu/reps95sequential.html},
    x-volume = {33},
    xpages = {739--757},
    year = {1996}
}

@article{dvanhorn:dwork-et-al-jlp84,
    author = {Dwork, Cynthia and Kanellakis, Paris C. and Mitchell, John C.},
    citeulike-article-id = {5395041},
    date-added = {2009-08-07 21:29:22},
    journal = {J. Log. Program.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier Science Inc.},
    title = {On the sequential nature of unification},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {1},
    xpages = {35--50},
    year = {1984}
}

@proceedings{dvanhorn:DBLP:conf/sas/2008,
    booktitle = {SAS},
    citeulike-article-id = {5395040},
    date-added = {2009-08-07 21:29:22},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {Static Analysis, 15th International Symposium, {SAS} 2008, Valencia, Spain, July 16-18, 2008. Proceedings},
    x-editor = {Alpuente, Mar'{i}a and Vidal, Germ{\'{a}}n},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {5079},
    year = {2008}
}

@inproceedings{dvanhorn:comini-etal-sas08,
    author = {Comini, Marco and Damiani, Ferruccio and Vrech, Samuel},
    booktitle = {SAS},
    citeulike-article-id = {5395039},
    date-added = {2009-08-07 21:29:21},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {On Polymorphic Recursion, Type Systems, and Abstract Interpretation},
    x-editor = {Alpuente, Mar'{i}a and Vidal, Germ{\'{a}}n},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {5079},
    xpages = {144--158},
    year = {2008}
}

@inproceedings{dvanhorn:midtgaard-jensen-sas-08,
    author = {Midtgaard, Jan and Jensen, Thomas},
    booktitle = {SAS},
    citeulike-article-id = {5395038},
    date-added = {2009-08-07 21:29:21},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {A Calculational Approach to {Control-Flow} Analysis by Abstract Interpretation},
    x-editor = {Alpuente, Mar\'{\i}a and Vidal, Germ\'{a}n},
    x-series = {LNCS},
    x-volume = {5079},
    xpages = {347--362},
    year = {2008}
}

@inproceedings{dvanhorn:blanc-levy-klop-05,
    author = {Blanc, Tomasz and L{\'{e}}vy, Jean J. and Maranget, Luc},
    booktitle = {Processes, Terms and Cycles},
    citeulike-article-id = {5395037},
    date-added = {2009-08-07 21:29:21},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {Sharing in the Weak {Lambda-Calculus}},
    x-editor = {Middeldorp, Aart and van Oostrom, Vincent and van Raamsdonk, Femke and de Vrijer, Roel C.},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {3838},
    xpages = {70--87},
    year = {2005}
}

@proceedings{dvanhorn:DBLP:conf/birthday/2005klop,
    booktitle = {Processes, Terms and Cycles},
    citeulike-article-id = {5395036},
    date-added = {2009-08-07 21:29:21},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {Processes, Terms and Cycles: Steps on the Road to Infinity, Essays Dedicated to Jan Willem Klop, on the Occasion of His 60th Birthday},
    x-editor = {Middeldorp, Aart and van Oostrom, Vincent and van Raamsdonk, Femke and de Vrijer, Roel C.},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {3838},
    year = {2005}
}

@inproceedings{dvanhorn:kuan-macqueen-ml-07,
    author = {Kuan, George and Macqueen, David},
    booktitle = {ML '07: Proceedings of the 2007 workshop on Workshop on ML},
    citeulike-article-id = {5395035},
    date-added = {2009-08-07 21:29:21},
    keywords = {file-import-09-08-07},
    location = {Freiburg, Germany},
    priority = {2},
    publisher = {ACM},
    title = {Efficient type inference using ranked type variables},
    x-address = {New York, NY, USA},
    xpages = {3--14},
    year = {2007}
}

@inproceedings{dvanhorn:chaudhuri-popl08,
    author = {Chaudhuri, Swarat},
    booktitle = {POPL '08: Proceedings of the 35th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395034},
    date-added = {2009-08-07 21:29:21},
    key = {POPL 2008},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, USA},
    priority = {2},
    publisher = {ACM},
    title = {Subcubic algorithms for recursive state machines},
    x-address = {New York, NY, USA},
    xpages = {159--169},
    year = {2008}
}

@misc{dvanhorn:henglein-unpub90,
    author = {Henglein, Fritz},
    booktitle = {Unpublished manuscript},
    citeulike-article-id = {5395033},
    date-added = {2009-08-07 21:29:21},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Type Invariant Simulation: A Lower Bound Technique for Type Inference},
    year = {1990}
}

@article{dvanhorn:landin-64,
    author = {Landin, Peter J.},
    citeulike-article-id = {5395032},
    date-added = {2009-08-07 21:29:21},
    journal = {The Computer Journal},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {The mechanical evaluation of expressions},
    x-number = {4},
    x-volume = {6},
    xpages = {308--320},
    year = {1964}
}

@book{dvanhorn:hankin-lambda,
    author = {Hankin, Chris},
    citeulike-article-id = {5395031},
    date-added = {2009-08-07 21:29:21},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {King's College},
    title = {An Introduction to Lambda Calculi for Computer Scientists},
    year = {2004}
}

@phdthesis{dvanhorn:might-phd,
    author = {Might, Matthew},
    booktitle = {Adviser-Olin G. Shivers},
    citeulike-article-id = {5395030},
    date-added = {2009-08-07 21:29:20},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {Georgia Institute of Technology},
    title = {Environment analysis of higher-order languages},
    x-address = {Atlanta, GA, USA},
    year = {2007}
}

@inproceedings{dvanhorn:might-shivers-popl06,
    author = {Might, Matthew and Shivers, Olin},
    booktitle = {POPL '06: Conference record of the 33rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {5395029},
    date-added = {2009-08-07 21:29:20},
    keywords = {file-import-09-08-07},
    location = {Charleston, South Carolina, USA},
    priority = {2},
    publisher = {ACM},
    title = {Environment analysis via {\$\\Delta\$}{CFA}},
    x-address = {New York, NY, USA},
    xpages = {127--140},
    year = {2006}
}

@article{dvanhorn:cosmo-etal-mscs03,
    author = {Di Cosmo, Roberto and Kesner, Delia and Polonovski, Emmanuel},
    citeulike-article-id = {5395028},
    date-added = {2009-08-07 21:29:20},
    journal = {Mathematical. Structures in Comp. Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Proof nets and explicit substitutions},
    x-address = {New York, NY, USA},
    x-number = {3},
    x-volume = {13},
    xpages = {409--450},
    year = {2003}
}

@article{dvanhorn:girard-tcs87,
    author = {Girard, Jean Y.},
    citeulike-article-id = {5395027},
    date-added = {2009-08-07 21:29:20},
    journal = {Theor. Comput. Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {Linear logic},
    x-address = {Essex, UK},
    x-number = {1},
    x-volume = {50},
    xpages = {1--102},
    year = {1987}
}

@article{dvanhorn:rice,
    author = {Rice, Henry G.},
    citeulike-article-id = {5395026},
    date-added = {2009-08-07 21:29:20},
    journal = {Trans. Amer. Math. Soc.},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Classes of Recursively Enumerable Sets and Their Decision Problems},
    x-volume = {74},
    xpages = {358--366},
    year = {1953}
}

@misc{dvanhorn:pllc,
    author = {Felleisen, Matthias and Flatt, Matthew},
    booktitle = {Soon to be published manuscript, in development since 1989},
    citeulike-article-id = {5395025},
    date-added = {2009-08-07 21:29:20},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Programming Languages and Lambda Calculi},
    year = {2009}
}

@book{dvanhorn:barendregt,
    author = {Barendregt, Henk P.},
    citeulike-article-id = {5395024},
    date-added = {2009-08-07 21:29:20},
    edition = {revised},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {North-Holland},
    title = {The Lambda Calculus: Its Syntax and Semantics},
    x-series = {Studies in Logic and the Foundations of Mathematics},
    x-volume = {103},
    year = {1984}
}

@book{dvanhorn:eopl1,
    author = {Friedman, Daniel P. and Wand, Mitchell and Haynes, Christopher T.},
    citeulike-article-id = {5395023},
    date-added = {2009-08-07 21:29:20},
    edition = {first},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {MIT Press},
    title = {Essentials of Programming Languages},
    year = {1992}
}

@book{dvanhorn:eopl3,
    author = {Friedman, Daniel P. and Wand, Mitchell},
    citeulike-article-id = {5395022},
    date-added = {2009-08-07 21:29:20},
    edition = {third},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {MIT Press},
    title = {Essentials of Programming Languages},
    year = {2008}
}

@article{dvanhorn:reynolds-hosc98,
    author = {Reynolds, John C.},
    booktitle = {Originally published in \emph{ACM'72: Proceedings of the ACM Annual Conference}.},
    citeulike-article-id = {5395021},
    date-added = {2009-08-07 21:29:20},
    journal = {Higher-Order and Symbolic Computation},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Definitional Interpreters for {Higher-Order} Programming Languages},
    x-number = {4},
    x-volume = {11},
    xpages = {363--397},
    year = {1998}
}

@inproceedings{dvanhorn:reynolds-acm72,
    author = {Reynolds, John C.},
    booktitle = {ACM '72: Proceedings of the ACM Annual Conference},
    booktitle = {},
    citeulike-article-id = {5395020},
    date-added = {2009-08-07 21:29:20},
    keywords = {file-import-09-08-07},
    location = {Boston, Massachusetts, United States},
    priority = {2},
    publisher = {ACM},
    title = {Definitional interpreters for higher-order programming languages},
    x-address = {New York, NY, USA},
    xpages = {717--740},
    year = {1972}
}

@book{dvanhorn:harper-sml,
    author = {Harper, Robert},
    booktitle = {Published online only: \url{http://www.cs.cmu.edu/\~{}rwh/smlbook/}, Working draft of December 6, 2007.},
    citeulike-article-id = {5395019},
    date-added = {2009-08-07 21:29:20},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Programming in Standard {ML}},
    year = {2005}
}

@book{dvanhorn:sitaram-tyscheme,
    author = {Sitaram, Dorai},
    booktitle = {Published online: \url{http://www.ccs.neu.edu/home/dorai/t-y-scheme/t-y-scheme.html}},
    citeulike-article-id = {5395018},
    date-added = {2009-08-07 21:29:20},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Teach Yourself Scheme in Fixnum Days},
    year = {2004}
}

@book{dvanhorn:dybvig-tspl,
    annote = {Introduction and reference manual for ANSI Standard Scheme with numerous short and extended examples and exercises.},
    author = {Dybvig, R. Kent},
    booktitle = {Published online: \url{http://www.scheme.com/tspl3/}},
    citeulike-article-id = {5395017},
    date-added = {2009-08-07 21:29:20},
    edition = {Third},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {{MIT} Press},
    title = {The {Scheme} Programming Language},
    year = {2002}
}

@phdthesis{dvanhorn:sampath-phd,
    author = {Sampath, Prahladavaradan},
    citeulike-article-id = {5395016},
    date-added = {2009-08-07 21:29:20},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {Imperial College, University of London},
    title = {Program Analysis using Game Semantics},
    x-month = jan,
    year = {2000}
}

@article{dvanhorn:hankin-malacaria-cs99,
    author = {Hankin, Chris and Malacaria, Pasquale},
    citeulike-article-id = {5395015},
    date-added = {2009-08-07 21:29:20},
    journal = {ACM Comput. Surv.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Program analysis games},
    x-address = {New York, NY, USA},
    x-number = {3},
    x-volume = {31},
    year = {1999}
}

@inproceedings{dvanhorn:jones-nielson,
    author = {Jones, Neil D. and Nielson, Flemming},
    citeulike-article-id = {5395014},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Oxford University Press},
    title = {Abstract interpretation: a semantics-based tool for program analysis},
    x-address = {Oxford, UK},
    x-editor = {Abramsky, S. and Gabbay, Dov M. and Maibaum, T. S. E.},
    xpages = {527--636},
    year = {1995}
}

@book{dvanhorn:handbook-of-logic,
    citeulike-article-id = {5395013},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Oxford University Press},
    title = {Handbook of logic in computer science (vol. 4): semantic modelling},
    x-address = {Oxford, UK},
    x-editor = {Abramsky, S. and Gabbay, Dov M. and Maibaum, T. S. E.},
    year = {1995}
}

@inproceedings{dvanhorn:Cousot:1977:AI,
    author = {Cousot, Patrick and Cousot, Radhia},
    booktitle = {POPL '77: Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    booktitle = {POPL '77},
    citeulike-article-id = {5395012},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    location = {Los Angeles, California},
    priority = {2},
    publisher = {ACM},
    title = {Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints},
    x-address = {New York, NY, USA},
    xpages = {238--252},
    year = {1977}
}

@article{dvanhorn:cousot-cousot-jlc92,
    author = {Cousot, Patrick and Cousot, Radhia},
    citeulike-article-id = {5395011},
    date-added = {2009-08-07 21:29:19},
    journal = {Journal of Logic and Computation},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Oxford University Press, Oxford, UK},
    title = {Abstract Interpretation Frameworks},
    x-month = aug,
    x-number = {4},
    x-volume = {2},
    xpages = {511--547},
    year = {1992}
}

@book{dvanhorn:curry-fest,
    citeulike-article-id = {5395010},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Academic Press},
    title = {To H. B. Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism},
    x-address = {London},
    x-editor = {Seldin, Jonathan P. and Hindley, J. Roger},
    year = {1980}
}

@inproceedings{dvanhorn:howard,
    author = {Howard, William A.},
    citeulike-article-id = {5395009},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Academic Press},
    title = {The formulae-as-types notion of construction},
    x-address = {London},
    x-editor = {Seldin, Jonathan P. and Hindley, J. Roger},
    xpages = {479--490},
    year = {1980}
}

@book{dvanhorn:sorensen-urzyczyn,
    author = {S{o}rensen, Morten H. and Urzyczyn, Pawel},
    citeulike-article-id = {5395008},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier Science Inc.},
    title = {Lectures on the {Curry-Howard} Isomorphism},
    x-address = {New York, NY, USA},
    x-series = {Studies in Logic and the Foundations of Mathematics},
    x-volume = {149},
    year = {2006}
}

@article{dvanhorn:wells-apal99,
    author = {Wells, J. B.},
    citeulike-article-id = {5395007},
    date-added = {2009-08-07 21:29:19},
    journal = {Annals of Pure and Applied Logic},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Typability and type checking in {S}ystem {F} are equivalent and undecidable},
    x-volume = {98},
    xpages = {111--156},
    year = {1999}
}

@book{dvanhorn:Papadimitriou94,
    author = {Papadimitriou, Christos H.},
    citeulike-article-id = {5395006},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Addison-Wesley},
    title = {Computational Complexity},
    x-address = {Reading, MA},
    year = {1994}
}

@inproceedings{dvanhorn:sereni-jones-aplas05,
    author = {Sereni, Damien and Jones, Neil D.},
    booktitle = {Programming Languages and Systems, Third Asian Symposium, APLAS 2005, Tsukuba, Japan, November 2-5, 2005, Proceedings},
    citeulike-article-id = {5395005},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {Termination Analysis of {Higher-Order} Functional Programs},
    x-editor = {Yi, Kwangkeun},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {3780},
    xpages = {281--297},
    year = {2005}
}

@inproceedings{dvanhorn:sereni-icfp07,
    author = {Sereni, Damien},
    booktitle = {ICFP '07: Proceedings of the 12th ACM SIGPLAN International Conference on Functional Programming, Freiburg, Germany, October 1--3, 2007},
    citeulike-article-id = {5395004},
    date-added = {2009-08-07 21:29:19},
    key = {ICFP'07},
    keywords = {file-import-09-08-07},
    location = {Freiburg, Germany},
    priority = {2},
    publisher = {ACM},
    title = {Termination analysis and call graph construction for higher-order functional programs},
    x-address = {New York, NY, USA},
    x-editor = {Hinze, Ralf and Ramsey, Norman},
    xpages = {71--84},
    year = {2007}
}

@book{dvanhorn:sicp,
    author = {Abelson, Harold and Sussman, Gerald J.},
    citeulike-article-id = {5395003},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {MIT Press},
    title = {Structure and Interpretation of Computer Programs},
    x-address = {Cambridge, MA, USA},
    year = {1996}
}

@inproceedings{dvanhorn:Might:2006:GammaCFA,
    author = {Might, Matthew and Shivers, Olin},
    booktitle = {ICFP'06},
    booktitle = {Proceedings of the 11th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {5395002},
    date-added = {2009-08-07 21:29:19},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Improving Flow Analyses via \({\Gamma}\){CFA}: Abstract Garbage Collection and Counting},
    x-address = {Portland, Oregon},
    x-month = sep,
    xpages = {13--25},
    year = {2006}
}

@inbook{dvanhorn:hankin-games,
    author = {Hankin, Chris and Nagarajan, Rajagopal and Sampath, Prahladavaradan},
    chapter = {Flow analysis: games and nets},
    citeulike-article-id = {5395001},
    date-added = {2009-08-07 21:29:18},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag New York, Inc.},
    title = {The essence of computation: complexity, analysis, transformation},
    x-address = {New York, NY, USA},
    xpages = {135--156},
    year = {2002}
}

@article{dvanhorn:mossin-njc98,
    author = {Mossin, Christian},
    citeulike-article-id = {5395000},
    date-added = {2009-08-07 21:29:18},
    journal = {Nordic J. of Computing},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Publishing Association Nordic Journal of Computing},
    title = {Higher-order value flow graphs},
    x-address = {Finland},
    x-number = {3},
    x-volume = {5},
    xpages = {214--234},
    year = {1998}
}

@phdthesis{dvanhorn:neergaard-phd,
    author = {Peter {{Mo Ller} Neergaard}},
    citeulike-article-id = {5394999},
    date-added = {2009-08-07 21:29:18},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {Brandeis University},
    title = {Complexity Aspects of Programming Language Design: From Logspace to Elementary Time via Proofnets and Intersection Types},
    x-address = {Waltham, Massachusetts},
    x-month = oct,
    year = {2004}
}

@article{dvanhorn:ashley-dybvig-toplas98,
    author = {Ashley, J. Michael and Dybvig, R. Kent},
    citeulike-article-id = {5394998},
    date-added = {2009-08-07 21:29:18},
    journal = {ACM TOPLAS},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {A practical and flexible flow analysis for higher-order languages},
    x-address = {New York, NY, USA},
    x-number = {4},
    x-volume = {20},
    xpages = {845--868},
    year = {1998}
}

@inproceedings{dvanhorn:burn-hankin-abramsky,
    author = {Burn, G. L. and Hankin, C. L. and Abramsky, S.},
    booktitle = {Programs as data objects},
    citeulike-article-id = {5394997},
    date-added = {2009-08-07 21:29:18},
    keywords = {file-import-09-08-07},
    location = {Copenhagen, Denmark},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {The theory of strictness analysis for higher order functions},
    x-address = {New York, NY, USA},
    x-editor = {Ganzinger, H. and Jones, N.},
    xpages = {42--62},
    year = {1985}
}

@article{dvanhorn:gmsv,
    author = {Gaifman, Haim and Mairson, Harry and Sagiv, Yehoshua and Vardi, Moshe Y.},
    citeulike-article-id = {5394996},
    date-added = {2009-08-07 21:29:18},
    journal = {J. ACM},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Undecidable optimization problems for database logic programs},
    x-address = {New York, NY, USA},
    x-number = {3},
    x-volume = {40},
    xpages = {683--713},
    year = {1993}
}

@article{dvanhorn:hkmv,
    author = {Hillebrand, Gerd G. and Kanellakis, Paris C. and Mairson, Harry G. and Vardi, Moshe Y.},
    citeulike-article-id = {5394995},
    date-added = {2009-08-07 21:29:18},
    journal = {J. Logic Program.},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Undecidable Boundedness Problems for Datalog Programs},
    x-number = {2},
    x-volume = {25},
    xpages = {163--190},
    year = {1995}
}

@inproceedings{dvanhorn:schubert-tcla01,
    author = {Schubert, Aleksy},
    booktitle = {Typed Lambda Calculi and Applications, 5th International Conference, TLCA 2001, Krakow, Poland, May 2-5, 2001, Proceedings},
    citeulike-article-id = {5394994},
    date-added = {2009-08-07 21:29:18},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {The Complexity of {beta-Reduction} in Low Orders.},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {2044},
    xpages = {400--414},
    year = {2001}
}

@article{dvanhorn:Midtgaard2011Controlflow,
    author = {Midtgaard, Jan},
    booktitle = {To appear.},
    citeulike-article-id = {5394993},
    date-added = {2009-08-07 21:29:18},
    journal = {ACM Computing Surveys},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Control-flow analysis of functional programs},
    year = {2011}
}

@phdthesis{dvanhorn:kam-76,
    author = {Kam, John B.},
    citeulike-article-id = {5394992},
    date-added = {2009-08-07 21:29:18},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {Princeton University},
    title = {Monotone data flow analysis frameworks: a formal theory of global computer program optimization.},
    x-address = {Princeton, NJ, USA},
    year = {1976}
}

@article{dvanhorn:kam-ullman-76,
    author = {Kam, John B. and Ullman, Jeffrey D.},
    citeulike-article-id = {5394991},
    date-added = {2009-08-07 21:29:18},
    journal = {J. ACM},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Global Data Flow Analysis and Iterative Algorithms},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {23},
    xpages = {158--171},
    year = {1976}
}

@book{dvanhorn:hecht,
    author = {Hecht, Matthew S.},
    citeulike-article-id = {5394990},
    date-added = {2009-08-07 21:29:18},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier Science Inc.},
    title = {Flow Analysis of Computer Programs},
    x-address = {New York, NY, USA},
    year = {1977}
}

@book{dvanhorn:mackay,
    author = {Mackay, David J. C.},
    citeulike-article-id = {5394989},
    date-added = {2009-08-07 21:29:18},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Information Theory, Inference \& Learning Algorithms},
    x-address = {New York, NY, USA},
    year = {2002}
}

@article{dvanhorn:shannon,
    author = {Shannon, Claude E.},
    citeulike-article-id = {5394988},
    date-added = {2009-08-07 21:29:18},
    journal = {Bell System Technical Journal},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {A mathematical theory of communication},
    x-volume = {27},
    year = {1948}
}

@techreport{dvanhorn:henglein92d,
    author = {Henglein, Fritz},
    booktitle = {DIKU Semantics Report D-193},
    citeulike-article-id = {5394987},
    date-added = {2009-08-07 21:29:17},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Simple Closure Analysis},
    x-month = mar,
    year = {1992}
}

@inproceedings{dvanhorn:lafont-ll95,
    author = {Lafont, Yves},
    booktitle = {Proceedings of the workshop on Advances in linear logic},
    citeulike-article-id = {5394986},
    date-added = {2009-08-07 21:29:17},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {From proof-nets to interaction nets},
    x-address = {New York, NY, USA},
    xpages = {225--247},
    year = {1995}
}

@inproceedings{dvanhorn:mossin-sas97,
    author = {Mossin, Christian},
    booktitle = {SAS '97: Proceedings of the 4th International Symposium on Static Analysis},
    citeulike-article-id = {5394985},
    date-added = {2009-08-07 21:29:17},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Exact Flow Analysis},
    x-address = {London, UK},
    xpages = {250--264},
    year = {1997}
}

@book{dvanhorn:jones-et-al-93,
    author = {Jones, Neil D. and Gomard, Carsten K. and Sestoft, Peter},
    citeulike-article-id = {5394984},
    date-added = {2009-08-07 21:29:17},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Prentice-Hall, Inc.},
    title = {Partial evaluation and automatic program generation},
    x-address = {Upper Saddle River, NJ, USA},
    year = {1993}
}

@article{dvanhorn:danvy-et-al-toplas96,
    author = {Danvy, Olivier and Karoline Malmkjae and Palsberg, Jens},
    citeulike-article-id = {5394983},
    date-added = {2009-08-07 21:29:17},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM Press},
    title = {Eta-expansion does The Trick},
    x-address = {New York, NY, USA},
    x-number = {6},
    x-volume = {18},
    xpages = {730--751},
    year = {1996}
}

@article{dvanhorn:banerjee-jensen-mscs03,
    author = {Banerjee, Anindya and Jensen, Thomas},
    citeulike-article-id = {5394982},
    date-added = {2009-08-07 21:29:17},
    journal = {Mathematical. Structures in Comp. Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Modular control-flow analysis with rank 2 intersection types},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {13},
    xpages = {87--124},
    year = {2003}
}

@inproceedings{dvanhorn:DBLP:conf/ictcs/MairsonT03,
    author = {Mairson, Harry G. and Terui, Kazushige},
    booktitle = {Theoretical Computer Science, 8th Italian Conference, ICTCS 2003, Bertinoro, Italy, October 13-15, 2003, Proceedings},
    citeulike-article-id = {5394981},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {On the Computational Complexity of {Cut-Elimination} in Linear Logic},
    x-editor = {Blundo, Carlo and Laneve, Cosimo},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {2841},
    xpages = {23--36},
    year = {2003}
}

@inproceedings{dvanhorn:danvy-filinksi-lfp90,
    author = {Danvy, Olivier and Filinski, Andrzej},
    booktitle = {Proceedings of the 1990 ACM Conference on LISP and Functional Programming},
    citeulike-article-id = {5394980},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    location = {Nice, France},
    priority = {2},
    publisher = {ACM Press},
    title = {Abstracting control},
    x-address = {New York, NY, USA},
    xpages = {151--160},
    year = {1990}
}

@inproceedings{dvanhorn:parigot-lpar92,
    author = {Parigot, Michel},
    booktitle = {Logic Programming and Automated Reasoning,International Conference LPAR'92, St. Petersburg, Russia, July 15-20, 1992, Proceedings},
    citeulike-article-id = {5394979},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {\$\\{lambda\\mu\$-Calculus}: An Algorithmic Interpretation of Classical Natural Deduction},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {624},
    xpages = {190--201},
    year = {1992}
}

@inproceedings{dvanhorn:filinski-ctcs89,
    author = {Filinski, Andrzej},
    booktitle = {Category Theory and Computer Science},
    citeulike-article-id = {5394978},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Declarative Continuations: an Investigation of Duality in Programming Language Semantics},
    x-address = {London, UK},
    xpages = {224--249},
    year = {1989}
}

@inproceedings{dvanhorn:lafont-proofs-and-types,
    author = {Lafont, Yves},
    booktitle = {Reprinted with corrections 1990},
    citeulike-article-id = {5394977},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {What is Linear Logic?},
    x-address = {New York, NY, USA},
    xpages = {149--160},
    year = {1989}
}

@book{dvanhorn:girard-proofs-and-types,
    author = {Girard, Jean Y. and Taylor, Paul and Lafont, Yves},
    booktitle = {Reprinted with corrections 1990},
    citeulike-article-id = {5394976},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Proofs and types},
    x-address = {New York, NY, USA},
    year = {1989}
}

@article{dvanhorn:asperti-laneve-tcs95,
    author = {Asperti, Andrea and Laneve, Cosimo},
    citeulike-article-id = {5394975},
    date-added = {2009-08-07 21:29:16},
    journal = {Theor. Comput. Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {Paths, computations and labels in the \$\\lambda\$-calculus},
    x-address = {Essex, UK},
    x-number = {2},
    x-volume = {142},
    xpages = {277--297},
    year = {1995}
}

@phdthesis{dvanhorn:Mossin:97:FlowAnalysis,
    author = {Mossin, Christian},
    citeulike-article-id = {5394974},
    date-added = {2009-08-07 21:29:16},
    keywords = {analysis, data, file-import-09-08-07, flow, types},
    priority = {2},
    school = {DIKU, University of Copenhagen},
    title = {Flow Analysis of Typed {Higher-Order} Programs},
    x-month = jan,
    year = {1997}
}

@misc{dvanhorn:mairson-unpub06,
    author = {Mairson, Harry G.},
    booktitle = {Unpublished manuscript},
    citeulike-article-id = {5394973},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {Axiom-sensitive normalization bounds for multiplicative linear logic},
    year = {2006}
}

@inproceedings{dvanhorn:mairson-popl90,
    author = {Mairson, Harry G.},
    booktitle = {POPL '90: Proceedings of the 17th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5394972},
    date-added = {2009-08-07 21:29:16},
    key = {POPL 1990},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, United States},
    priority = {2},
    publisher = {ACM Press},
    title = {Deciding {ML} typability is complete for deterministic exponential time},
    x-address = {New York, NY, USA},
    xpages = {382--401},
    year = {1990}
}

@inproceedings{dvanhorn:girard-goi89,
    author = {Girard, Jean Y.},
    booktitle = {Logic Colloquium '88},
    citeulike-article-id = {5394971},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {North Holland},
    title = {Geometry of interaction {I}: Interpretation of {S}ystem {F}},
    x-editor = {Bonotto, C.},
    xpages = {221--260},
    year = {1989}
}

@inproceedings{dvanhorn:mairson-icfp03,
    author = {Mairson, Harry G.},
    booktitle = {ICFP '03: Proceedings of the eighth ACM SIGPLAN International Conference on Functional Programming},
    booktitle = {Invited talk},
    citeulike-article-id = {5394970},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    location = {Uppsala, Sweden},
    priority = {2},
    publisher = {ACM Press},
    title = {From {H}ilbert space to {D}ilbert space: context semantics as a language for games and flow analysis},
    x-address = {New York, NY, USA},
    xpages = {125},
    year = {2003}
}

@inproceedings{dvanhorn:banerjee-icfp97,
    author = {Banerjee, Anindya},
    booktitle = {ICFP '97: Proceedings of the second ACM SIGPLAN International Conference on Functional Programming},
    booktitle = {ICFP '97},
    citeulike-article-id = {5394969},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    location = {Amsterdam, The Netherlands},
    priority = {2},
    publisher = {ACM},
    title = {A modular, polyvariant and type-based closure analysis},
    x-address = {New York, NY, USA},
    x-editor = {Berman, A. Michael},
    xpages = {1--10},
    year = {1997}
}

@inproceedings{dvanhorn:faxen-lomaps97,
    author = {Fax\'{e}n, Karl F.},
    booktitle = {Selected papers from the 5th LOMAPS Workshop on Analysis and Verification of Multiple-Agent Languages},
    citeulike-article-id = {5394968},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Polyvariance, Polymorphism and Flow Analysis},
    x-address = {London, UK},
    xpages = {260--278},
    year = {1997}
}

@inproceedings{dvanhorn:faxen-sas95,
    author = {Fax{\'{e}}n, Karl F.},
    booktitle = {SAS},
    citeulike-article-id = {5394967},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {Optimizing Lazy Functional Programs Using Flow Inference},
    x-editor = {Mycroft, Alan},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {983},
    xpages = {136--153},
    year = {1995}
}

@inproceedings{dvanhorn:tang-jouvelot-tacs94,
    author = {Tang, Yan M. and Jouvelot, Pierre},
    booktitle = {TACS '94: Proceedings of the International Conference on Theoretical Aspects of Computer Software},
    citeulike-article-id = {5394966},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Separate Abstract Interpretation for {Control-Flow} Analysis},
    x-address = {London, UK},
    xpages = {224--243},
    year = {1994}
}

@inproceedings{dvanhorn:sestoft-fpca89,
    author = {Sestoft, Peter},
    booktitle = {FPCA '89: Proceedings of the fourth International Conference on Functional Programming Languages and Computer Architecture},
    citeulike-article-id = {5394965},
    date-added = {2009-08-07 21:29:16},
    keywords = {file-import-09-08-07},
    location = {Imperial College, London, United Kingdom},
    priority = {2},
    publisher = {ACM Press},
    title = {Replacing function parameters by global variables},
    x-address = {New York, NY, USA},
    xpages = {39--53},
    year = {1989}
}

@mastersthesis{dvanhorn:sestoft-ms,
    author = {Sestoft, Peter},
    booktitle = {Master's thesis no.\~{}254},
    citeulike-article-id = {5394964},
    date-added = {2009-08-07 21:29:15},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {DIKU},
    title = {Replacing function parameters by global variables},
    x-address = {University of Copenhagen, Denmark},
    x-month = oct,
    year = {1988}
}

@inproceedings{dvanhorn:heintze-lfp94,
    author = {Heintze, Nevin},
    booktitle = {LFP '94: Proceedings of the 1994 ACM Conference on LISP and Functional Programming},
    citeulike-article-id = {5394963},
    date-added = {2009-08-07 21:29:15},
    keywords = {file-import-09-08-07},
    location = {Orlando, Florida, United States},
    priority = {2},
    publisher = {ACM Press},
    title = {Set-based analysis of {ML} programs},
    x-address = {New York, NY, USA},
    xpages = {306--317},
    year = {1994}
}

@inproceedings{dvanhorn:nielson-nielson-popl97,
    author = {Nielson, Flemming and Nielson, Hanne R.},
    booktitle = {POPL '97: Proceedings of the 24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5394962},
    date-added = {2009-08-07 21:29:15},
    key = {POPL 1997},
    keywords = {file-import-09-08-07},
    location = {Paris, France},
    priority = {2},
    publisher = {ACM Press},
    title = {Infinitary control flow analysis: a collecting semantics for closure analysis},
    x-address = {New York, NY, USA},
    xpages = {332--345},
    year = {1997}
}

@article{dvanhorn:palsberg-pavlopoulou-jfp01,
    author = {Palsberg, Jens and Pavlopoulou, Christina},
    citeulike-article-id = {5394961},
    date-added = {2009-08-07 21:29:15},
    journal = {J. Funct. Program.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {From Polyvariant flow information to intersection and union types},
    x-address = {New York, NY, USA},
    x-number = {3},
    x-volume = {11},
    xpages = {263--317},
    year = {2001}
}

@proceedings{dvanhorn:DBLP:conf/sas/95,
    citeulike-article-id = {5394960},
    date-added = {2009-08-07 21:29:15},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {Static Analysis, Second International Symposium, {SAS}'95, Glasgow, {UK}, September 25-27, 1995, Proceedings},
    x-editor = {Mycroft, Alan},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {983},
    year = {1995}
}

@inproceedings{dvanhorn:heintze-sas95,
    author = {Heintze, Nevin},
    booktitle = {SAS},
    citeulike-article-id = {5394959},
    date-added = {2009-08-07 21:29:15},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer},
    title = {{Control-Flow} Analysis and Type Systems},
    x-editor = {Mycroft, Alan},
    x-series = {Lecture Notes in Computer Science},
    x-volume = {983},
    xpages = {189--206},
    year = {1995}
}

@article{dvanhorn:palsberg-okeefe-toplas95,
    author = {Palsberg, Jens and O'Keefe, Patrick},
    citeulike-article-id = {5394958},
    date-added = {2009-08-07 21:29:15},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM Press},
    title = {A type system equivalent to flow analysis},
    x-address = {New York, NY, USA},
    x-number = {4},
    x-volume = {17},
    xpages = {576--599},
    year = {1995}
}

@article{dvanhorn:wright-jagannathan-toplas98,
    author = {Wright, Andrew K. and Jagannathan, Suresh},
    citeulike-article-id = {5394957},
    date-added = {2009-08-07 21:29:15},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM Press},
    title = {Polymorphic splitting: an effective polyvariant flow analysis},
    x-address = {New York, NY, USA},
    x-issn = {0164-0925},
    x-number = {1},
    x-volume = {20},
    xpages = {166--207},
    year = {1998}
}

@inproceedings{dvanhorn:griffin-popl90,
    author = {Griffin, Timothy G.},
    booktitle = {POPL '90: Proceedings of the 17th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5394956},
    date-added = {2009-08-07 21:29:15},
    key = {POPL 1990},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, United States},
    priority = {2},
    publisher = {ACM Press},
    title = {A formulae-as-type notion of control},
    x-address = {New York, NY, USA},
    xpages = {47--58},
    year = {1990}
}

@misc{dvanhorn:terui-ll2002,
    author = {Terui, Kazushige},
    booktitle = {Invited talk at LL2002 (LICS2002 affiliated workshop), Copenhagen},
    citeulike-article-id = {5394955},
    date-added = {2009-08-07 21:29:15},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {On the complexity of {Cut-Elimination} in Linear Logic},
    x-month = jul,
    year = {2002}
}

@inproceedings{dvanhorn:Jones:1981:LambdaFlow,
    author = {Jones, Neil D.},
    booktitle = {Proceedings of the 8th Colloquium on Automata, Languages and Programming},
    citeulike-article-id = {5394954},
    date-added = {2009-08-07 21:29:15},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Flow Analysis of Lambda Expressions (Preliminary Version)},
    x-address = {London, UK},
    xpages = {114--128},
    year = {1981}
}

@article{dvanhorn:palsberg-toplas95,
    author = {Palsberg, Jens},
    citeulike-article-id = {5394953},
    date-added = {2009-08-07 21:29:15},
    journal = {ACM Trans.\\ Program.\\ Lang.\\ Syst.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM Press},
    title = {Closure analysis in constraint form},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {17},
    xpages = {47--62},
    year = {1995}
}

@inproceedings{dvanhorn:heintze-mcallester-pldi97,
    author = {Heintze, Nevin and Mcallester, David},
    booktitle = {PLDI '97: Proceedings of the ACM SIGPLAN 1997 conference on Programming language design and implementation},
    citeulike-article-id = {5394952},
    date-added = {2009-08-07 21:29:15},
    keywords = {file-import-09-08-07},
    location = {Las Vegas, Nevada, United States},
    priority = {2},
    publisher = {ACM Press},
    title = {Linear-time subtransitive control flow analysis},
    x-address = {New York, NY, USA},
    xpages = {261--272},
    year = {1997}
}

@inproceedings{dvanhorn:heintze-mcallester-lics97,
    author = {Heintze, Nevin and Mcallester, David},
    booktitle = {LICS '97: Proceedings of the 12th Annual IEEE Symposium on Logic in Computer Science},
    citeulike-article-id = {5394951},
    date-added = {2009-08-07 21:29:15},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {On the Cubic Bottleneck in Subtyping and Flow Analysis},
    x-address = {Washington, DC, USA},
    xpages = {342},
    year = {1997}
}

@article{dvanhorn:ladner-75,
    author = {Ladner, Richard E.},
    citeulike-article-id = {5394950},
    date-added = {2009-08-07 21:29:14},
    journal = {SIGACT News},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM Press},
    title = {The circuit value problem is log space complete for \${P}\$},
    x-address = {New York, NY, USA},
    x-number = {1},
    x-volume = {7},
    xpages = {18--20},
    year = {1975}
}

@inproceedings{dvanhorn:mairson-fsttcs02,
    author = {Mairson, Harry G.},
    booktitle = {FST TCS '02: Proceedings of the 22nd Conference Kanpur on Foundations of Software Technology and Theoretical Computer Science},
    citeulike-article-id = {5394949},
    date-added = {2009-08-07 21:29:14},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {From {H}ilbert Spaces to {D}ilbert Spaces: {C}ontext Semantics Made Simple},
    x-address = {London, UK},
    xpages = {2--17},
    year = {2002}
}

@article{dvanhorn:mairson-jfp04,
    author = {Mairson, Harry G.},
    citeulike-article-id = {5394947},
    date-added = {2009-08-07 21:29:14},
    journal = {J. Functional Program.},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Linear lambda calculus and {PTIME}-completeness},
    x-address = {New York, NY, USA},
    x-number = {6},
    x-volume = {14},
    xpages = {623--633},
    year = {2004}
}

@inproceedings{dvanhorn:henglein-mairson-popl91,
    author = {Henglein, Fritz and Mairson, Harry G.},
    booktitle = {POPL '91: Proceedings of the 18th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5394946},
    date-added = {2009-08-07 21:29:14},
    key = {POPL 1991},
    keywords = {file-import-09-08-07},
    location = {Orlando, Florida, United States},
    priority = {2},
    publisher = {ACM Press},
    title = {The complexity of type inference for higher-order lambda calculi},
    x-address = {New York, NY, USA},
    xpages = {119--130},
    year = {1991}
}

@inproceedings{dvanhorn:neergaard-mairson-icfp04,
    author = {Peter {{Mo Ller} Neergaard} and Mairson, Harry G.},
    booktitle = {ICFP '04: Proceedings of the ninth ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {5394945},
    date-added = {2009-08-07 21:29:14},
    keywords = {file-import-09-08-07},
    location = {Snow Bird, UT, USA},
    priority = {2},
    publisher = {ACM Press},
    title = {Types, potency, and idempotency: why nonlinearity and amnesia make a type system work},
    x-address = {New York, NY, USA},
    xpages = {138--149},
    year = {2004}
}

@inproceedings{dvanhorn:jagannathan-weeks-popl95,
    author = {Jagannathan, Suresh and Weeks, Stephen},
    booktitle = {POPL '95: Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5394944},
    date-added = {2009-08-07 21:29:14},
    key = {POPL 1995},
    keywords = {file-import-09-08-07},
    location = {San Francisco, California, United States},
    priority = {2},
    publisher = {ACM Press},
    title = {A unified treatment of flow analysis in higher-order languages},
    x-address = {New York, NY, USA},
    xpages = {393--407},
    year = {1995}
}

@inproceedings{dvanhorn:lawall-mairson-esop00,
    author = {Lawall, Julia L. and Mairson, Harry G.},
    booktitle = {ESOP '00: Proceedings of the 9th European Symposium on Programming Languages and Systems},
    citeulike-article-id = {5394943},
    date-added = {2009-08-07 21:29:14},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Sharing Continuations: Proofnets for Languages with Explicit Control},
    x-address = {London, UK},
    xpages = {245--259},
    year = {2000}
}

@inproceedings{dvanhorn:shivers-sigplan04,
    author = {Shivers, Olin},
    booktitle = {Best of PLDI 1988},
    citeulike-article-id = {5394942},
    date-added = {2009-08-07 21:29:14},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {ACM},
    title = {Higher-order control-flow analysis in retrospect: lessons learned, lessons abandoned},
    x-address = {New York, NY, USA},
    x-editor = {McKinley, Kathryn S.},
    x-number = {4},
    x-volume = {39},
    xpages = {257--269},
    year = {2004}
}

@phdthesis{dvanhorn:Shivers:1991:CFA,
    author = {Shivers, Olin},
    citeulike-article-id = {5394941},
    date-added = {2009-08-07 21:29:14},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Carnegie Mellon University},
    school = {Carnegie Mellon University},
    title = {Control-flow analysis of higher-order languages},
    x-address = {Pittsburgh, PA, USA},
    year = {1991}
}

@inproceedings{dvanhorn:shivers-88,
    author = {Shivers, Olin},
    booktitle = {PLDI '88: Proceedings of the ACM SIGPLAN 1988 Conference on Programming Language Design and Implementation},
    citeulike-article-id = {5394940},
    date-added = {2009-08-07 21:29:14},
    keywords = {file-import-09-08-07},
    location = {Atlanta, Georgia, United States},
    priority = {2},
    publisher = {ACM},
    title = {Control flow analysis in {S}cheme},
    x-address = {New York, NY, USA},
    x-series = {PLDI},
    xpages = {164--174},
    year = {1988}
}

@inproceedings{dvanhorn:levy-80,
    author = {L\'{e}vy, Jean J.},
    citeulike-article-id = {5394939},
    date-added = {2009-08-07 21:29:14},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Academic Press},
    title = {Optimal reductions in the lambda-calculus},
    x-address = {London},
    x-editor = {Seldin, Jonathan P. and Hindley, J. Roger},
    xpages = {159--191},
    year = {1980}
}

@phdthesis{dvanhorn:levy-phd,
    author = {L\'{e}vy, Jean J.},
    booktitle = {th\'{e}se d'Etat},
    citeulike-article-id = {5394938},
    date-added = {2009-08-07 21:29:14},
    keywords = {file-import-09-08-07},
    priority = {2},
    school = {Paris 7},
    title = {R\'{e}ductions correctes et optimales dans le lambda-calcul},
    x-month = jan,
    year = {1978}
}

@inproceedings{dvanhorn:gonthier-abadi-levy-popl92,
    author = {Gonthier, Georges and Abadi, Mart\'{\i}n and L\'{e}vy, Jean J.},
    booktitle = {POPL '92: Proceedings of the 19th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {5394937},
    date-added = {2009-08-07 21:29:14},
    keywords = {file-import-09-08-07},
    location = {Albuquerque, New Mexico, United States},
    priority = {2},
    publisher = {ACM Press},
    title = {The geometry of optimal lambda reduction},
    x-address = {New York, NY, USA},
    xpages = {15--26},
    year = {1992}
}

@article{dvanhorn:mairson92,
    author = {Mairson, Harry G.},
    citeulike-article-id = {5394936},
    date-added = {2009-08-07 21:29:14},
    journal = {Theoretical Computer Science},
    keywords = {file-import-09-08-07},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {A simple proof of a theorem of {Statman}},
    x-address = {Essex, UK},
    x-number = {2},
    x-volume = {103},
    xpages = {387--394},
    year = {1992}
}

@inproceedings{dvanhorn:asperti-mairson,
    author = {Asperti, Andrea and Mairson, Harry G.},
    booktitle = {POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, San Diego, CA, USA, January 19--21, 1998},
    citeulike-article-id = {5394935},
    date-added = {2009-08-07 21:29:14},
    key = {POPL 1998},
    keywords = {file-import-09-08-07},
    location = {San Diego, California, United States},
    priority = {2},
    publisher = {ACM Press},
    title = {Parallel beta reduction is not elementary recursive},
    x-address = {New York, NY, USA},
    x-editor = {Macqueen, David B. and Cardelli, Luca},
    xpages = {303--315},
    year = {1998}
}

@article{dvanhorn:statman79,
    author = {Statman, Richard},
    citeulike-article-id = {5394934},
    date-added = {2009-08-07 21:29:14},
    journal = {Theor.\\ Comput.\\ Sci.},
    keywords = {file-import-09-08-07},
    priority = {2},
    title = {The typed \$\\lambda\$-calculus is not elementary recursive},
    x-volume = {9},
    xpages = {73--81},
    year = {1979}
}

@proceedings{dvanhorn:icfp07,
    citeulike-article-id = {5394932},
    date-added = {2009-08-07 21:29:13},
    key = {ICFP'07},
    keywords = {file-import-09-08-07},
    location = {Freiburg, Germany},
    priority = {2},
    publisher = {ACM},
    title = {Proceedings of the 2007 {ACM} {SIGPLAN} International Conference on Functional Programming, Freiburg, Germany, October 1--3},
    x-address = {New York, NY, USA},
    year = {2007}
}

@inproceedings{dvanhorn:vanhorn-mairson-icfp07,
    author = {{Horn}, David {.} and Mairson, Harry G.},
    citeulike-article-id = {5394930},
    date-added = {2009-08-07 21:29:13},
    key = {ICFP'07},
    keywords = {file-import-09-08-07},
    location = {Freiburg, Germany},
    priority = {2},
    publisher = {ACM},
    title = {Relating complexity and precision in control flow analysis},
    x-address = {New York, NY, USA},
    xpages = {85--96},
    year = {2007}
}

@inproceedings{dvanhorn:VanHorn-Mairson:ICFP08,
    author = {Van Horn, David and Mairson, Harry G.},
    booktitle = {ICFP '08: Proceeding of the 13th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {5152280},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1411243},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1411204.1411243},
    date-added = {2009-08-07 21:02:02},
    location = {Victoria, BC, Canada},
    priority = {0},
    publisher = {ACM},
    title = {Deciding \(k\){CFA} is complete for {EXPTIME}},
    x-abstract = {We give an exact characterization of the computational complexity of the  \({k\)CFA} hierarchy. For any  \(k  > 0\), we prove that the control flow decision problem is complete for deterministic exponential time. This theorem validates empirical observations that such control flow analysis is intractable. It also provides more general insight into the complexity of abstract interpretation.},
    x-address = {New York, NY, USA},
    x-doi = {10.1145/1411204.1411243},
    x-isbn = {978-1-59593-919-7},
    x-url = {http://dx.doi.org/10.1145/1411204.1411243},
    xpages = {275--282},
    year = {2008}
}

